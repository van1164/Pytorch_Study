{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsB/UJEPxlYM4xT+bYti9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/van1164/Pytorch_Study/blob/main/LabPP03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1\n",
        ". [\n",
        "Exercise\n",
        "7\n",
        "-\n",
        "1]\n",
        "Diabets data\n",
        "의\n",
        "loss\n",
        "를\n",
        "아\n",
        "래\n",
        "의\n",
        "조\n",
        "건\n",
        "에서\n",
        "최\n",
        "소\n",
        "화\n",
        "하\n",
        "고\n",
        ",\n",
        "소\n",
        "스\n",
        "코드\n",
        "및\n",
        "결\n",
        "과\n",
        "를\n",
        "제\n",
        "출\n",
        "하\n",
        "시오\n"
      ],
      "metadata": {
        "id": "wHDoUvZjeE-7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) 10\n",
        "개\n",
        "이\n",
        "상\n",
        "의\n",
        "layer\n",
        "를\n",
        "쌓\n",
        "아서\n",
        "학\n",
        "습\n",
        "을\n",
        "수\n",
        "행\n",
        "하\n",
        "시오"
      ],
      "metadata": {
        "id": "7IDTMjaNeCpn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7zPC5PJKeO7",
        "outputId": "e9d28eed-654f-4b82-98fd-889d48d9a45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "X's shape: torch.Size([759, 8]) | Y's shape: torch.Size([759, 1])\n"
          ]
        }
      ],
      "source": [
        "from torch import nn, optim, from_numpy,cuda\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "xy = np.loadtxt('/content/gdrive/My Drive/Colab Notebooks/data/diabetes.csv.gz',delimiter=',', dtype=np.float32)\n",
        "x_data = from_numpy(xy[:,0:-1])\n",
        "y_data = from_numpy(xy[:,[-1]])\n",
        "print(f'X\\'s shape: {x_data.shape} | Y\\'s shape: {y_data.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model,self).__init__()\n",
        "    self.l1 = nn.Linear(8,10)\n",
        "    self.l2 = nn.Linear(10,9)\n",
        "    self.l3 = nn.Linear(9,8)\n",
        "    self.l4 = nn.Linear(8,7)\n",
        "    self.l5 = nn.Linear(7,6)\n",
        "    self.l6 = nn.Linear(6,5)\n",
        "    self.l7 = nn.Linear(5,4)\n",
        "    self.l8 = nn.Linear(4,3)\n",
        "    self.l9 = nn.Linear(3,2)\n",
        "    self.l10 = nn.Linear(2,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.sigmoid(self.l1(x))\n",
        "    out2 = self.sigmoid(self.l2(out1))\n",
        "    out3 = self.sigmoid(self.l3(out2))\n",
        "    out4 = self.sigmoid(self.l4(out3))\n",
        "    out5 = self.sigmoid(self.l5(out4))\n",
        "    out6 = self.sigmoid(self.l6(out5))\n",
        "    out7 = self.sigmoid(self.l7(out6))\n",
        "    out8 = self.sigmoid(self.l8(out7))\n",
        "    out9 = self.sigmoid(self.l9(out8))\n",
        "    y_pred = self.sigmoid(self.l10(out9))\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "1ydFirl1LFzd"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "criterion = nn.BCELoss(reduction = 'mean')\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.1)"
      ],
      "metadata": {
        "id": "Wkp5c8y6MdLD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  y_pred = model(x_data)\n",
        "  loss = criterion(y_pred, y_data)\n",
        "  print(f'Epoch: {epoch+1}/100 | Loss: {loss.item():.4f}')\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zw5G_YTXMm2V",
        "outputId": "855c92e1-ef96-484a-a203-a79a7cd82132"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/100 | Loss: 0.6939\n",
            "Epoch: 2/100 | Loss: 0.6896\n",
            "Epoch: 3/100 | Loss: 0.6856\n",
            "Epoch: 4/100 | Loss: 0.6820\n",
            "Epoch: 5/100 | Loss: 0.6787\n",
            "Epoch: 6/100 | Loss: 0.6757\n",
            "Epoch: 7/100 | Loss: 0.6730\n",
            "Epoch: 8/100 | Loss: 0.6705\n",
            "Epoch: 9/100 | Loss: 0.6682\n",
            "Epoch: 10/100 | Loss: 0.6662\n",
            "Epoch: 11/100 | Loss: 0.6643\n",
            "Epoch: 12/100 | Loss: 0.6626\n",
            "Epoch: 13/100 | Loss: 0.6611\n",
            "Epoch: 14/100 | Loss: 0.6597\n",
            "Epoch: 15/100 | Loss: 0.6584\n",
            "Epoch: 16/100 | Loss: 0.6572\n",
            "Epoch: 17/100 | Loss: 0.6562\n",
            "Epoch: 18/100 | Loss: 0.6552\n",
            "Epoch: 19/100 | Loss: 0.6543\n",
            "Epoch: 20/100 | Loss: 0.6535\n",
            "Epoch: 21/100 | Loss: 0.6528\n",
            "Epoch: 22/100 | Loss: 0.6521\n",
            "Epoch: 23/100 | Loss: 0.6515\n",
            "Epoch: 24/100 | Loss: 0.6510\n",
            "Epoch: 25/100 | Loss: 0.6505\n",
            "Epoch: 26/100 | Loss: 0.6500\n",
            "Epoch: 27/100 | Loss: 0.6496\n",
            "Epoch: 28/100 | Loss: 0.6492\n",
            "Epoch: 29/100 | Loss: 0.6489\n",
            "Epoch: 30/100 | Loss: 0.6485\n",
            "Epoch: 31/100 | Loss: 0.6483\n",
            "Epoch: 32/100 | Loss: 0.6480\n",
            "Epoch: 33/100 | Loss: 0.6478\n",
            "Epoch: 34/100 | Loss: 0.6475\n",
            "Epoch: 35/100 | Loss: 0.6473\n",
            "Epoch: 36/100 | Loss: 0.6472\n",
            "Epoch: 37/100 | Loss: 0.6470\n",
            "Epoch: 38/100 | Loss: 0.6468\n",
            "Epoch: 39/100 | Loss: 0.6467\n",
            "Epoch: 40/100 | Loss: 0.6466\n",
            "Epoch: 41/100 | Loss: 0.6465\n",
            "Epoch: 42/100 | Loss: 0.6464\n",
            "Epoch: 43/100 | Loss: 0.6463\n",
            "Epoch: 44/100 | Loss: 0.6462\n",
            "Epoch: 45/100 | Loss: 0.6461\n",
            "Epoch: 46/100 | Loss: 0.6460\n",
            "Epoch: 47/100 | Loss: 0.6460\n",
            "Epoch: 48/100 | Loss: 0.6459\n",
            "Epoch: 49/100 | Loss: 0.6458\n",
            "Epoch: 50/100 | Loss: 0.6458\n",
            "Epoch: 51/100 | Loss: 0.6457\n",
            "Epoch: 52/100 | Loss: 0.6457\n",
            "Epoch: 53/100 | Loss: 0.6457\n",
            "Epoch: 54/100 | Loss: 0.6456\n",
            "Epoch: 55/100 | Loss: 0.6456\n",
            "Epoch: 56/100 | Loss: 0.6456\n",
            "Epoch: 57/100 | Loss: 0.6455\n",
            "Epoch: 58/100 | Loss: 0.6455\n",
            "Epoch: 59/100 | Loss: 0.6455\n",
            "Epoch: 60/100 | Loss: 0.6455\n",
            "Epoch: 61/100 | Loss: 0.6455\n",
            "Epoch: 62/100 | Loss: 0.6454\n",
            "Epoch: 63/100 | Loss: 0.6454\n",
            "Epoch: 64/100 | Loss: 0.6454\n",
            "Epoch: 65/100 | Loss: 0.6454\n",
            "Epoch: 66/100 | Loss: 0.6454\n",
            "Epoch: 67/100 | Loss: 0.6454\n",
            "Epoch: 68/100 | Loss: 0.6454\n",
            "Epoch: 69/100 | Loss: 0.6454\n",
            "Epoch: 70/100 | Loss: 0.6453\n",
            "Epoch: 71/100 | Loss: 0.6453\n",
            "Epoch: 72/100 | Loss: 0.6453\n",
            "Epoch: 73/100 | Loss: 0.6453\n",
            "Epoch: 74/100 | Loss: 0.6453\n",
            "Epoch: 75/100 | Loss: 0.6453\n",
            "Epoch: 76/100 | Loss: 0.6453\n",
            "Epoch: 77/100 | Loss: 0.6453\n",
            "Epoch: 78/100 | Loss: 0.6453\n",
            "Epoch: 79/100 | Loss: 0.6453\n",
            "Epoch: 80/100 | Loss: 0.6453\n",
            "Epoch: 81/100 | Loss: 0.6453\n",
            "Epoch: 82/100 | Loss: 0.6453\n",
            "Epoch: 83/100 | Loss: 0.6453\n",
            "Epoch: 84/100 | Loss: 0.6453\n",
            "Epoch: 85/100 | Loss: 0.6453\n",
            "Epoch: 86/100 | Loss: 0.6453\n",
            "Epoch: 87/100 | Loss: 0.6453\n",
            "Epoch: 88/100 | Loss: 0.6453\n",
            "Epoch: 89/100 | Loss: 0.6453\n",
            "Epoch: 90/100 | Loss: 0.6453\n",
            "Epoch: 91/100 | Loss: 0.6453\n",
            "Epoch: 92/100 | Loss: 0.6453\n",
            "Epoch: 93/100 | Loss: 0.6453\n",
            "Epoch: 94/100 | Loss: 0.6453\n",
            "Epoch: 95/100 | Loss: 0.6453\n",
            "Epoch: 96/100 | Loss: 0.6453\n",
            "Epoch: 97/100 | Loss: 0.6453\n",
            "Epoch: 98/100 | Loss: 0.6453\n",
            "Epoch: 99/100 | Loss: 0.6453\n",
            "Epoch: 100/100 | Loss: 0.6453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Sigmoid\n",
        "외에\n",
        "다\n",
        "른\n",
        "activation\n",
        "함\n",
        "수\n",
        "를\n",
        "사\n",
        "용\n",
        "하\n",
        "시오"
      ],
      "metadata": {
        "id": "Y-1XfyPheQVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model_2,self).__init__()\n",
        "    self.l1 = nn.Linear(8,10)\n",
        "    self.l2 = nn.Linear(10,9)\n",
        "    self.l3 = nn.Linear(9,8)\n",
        "    self.l4 = nn.Linear(8,7)\n",
        "    self.l5 = nn.Linear(7,6)\n",
        "    self.l6 = nn.Linear(6,5)\n",
        "    self.l7 = nn.Linear(5,4)\n",
        "    self.l8 = nn.Linear(4,3)\n",
        "    self.l9 = nn.Linear(3,2)\n",
        "    self.l10 = nn.Linear(2,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    out3 = self.relu(self.l3(out2))\n",
        "    out4 = self.relu(self.l4(out3))\n",
        "    out5 = self.relu(self.l5(out4))\n",
        "    out6 = self.relu(self.l6(out5))\n",
        "    out7 = self.relu(self.l7(out6))\n",
        "    out8 = self.relu(self.l8(out7))\n",
        "    out9 = self.relu(self.l9(out8))\n",
        "    y_pred = self.sigmoid(self.l10(out9))\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "wVcx-50-efnr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = Model_2()\n",
        "criterion = nn.BCELoss(reduction = 'mean')\n",
        "optimizer = optim.SGD(model2.parameters(),lr=0.1)"
      ],
      "metadata": {
        "id": "R9vmNkjmerEe"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(100):\n",
        "  y_pred = model(x_data)\n",
        "  loss = criterion(y_pred, y_data)\n",
        "  print(f'Epoch: {epoch+1}/100 | Loss: {loss.item():.4f}')\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiGzg40GetIi",
        "outputId": "23b8bd1b-bdf3-4013-a395-1b5df31fbac2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/100 | Loss: 0.6453\n",
            "Epoch: 2/100 | Loss: 0.6453\n",
            "Epoch: 3/100 | Loss: 0.6453\n",
            "Epoch: 4/100 | Loss: 0.6453\n",
            "Epoch: 5/100 | Loss: 0.6453\n",
            "Epoch: 6/100 | Loss: 0.6453\n",
            "Epoch: 7/100 | Loss: 0.6453\n",
            "Epoch: 8/100 | Loss: 0.6453\n",
            "Epoch: 9/100 | Loss: 0.6453\n",
            "Epoch: 10/100 | Loss: 0.6453\n",
            "Epoch: 11/100 | Loss: 0.6453\n",
            "Epoch: 12/100 | Loss: 0.6453\n",
            "Epoch: 13/100 | Loss: 0.6453\n",
            "Epoch: 14/100 | Loss: 0.6453\n",
            "Epoch: 15/100 | Loss: 0.6453\n",
            "Epoch: 16/100 | Loss: 0.6453\n",
            "Epoch: 17/100 | Loss: 0.6453\n",
            "Epoch: 18/100 | Loss: 0.6453\n",
            "Epoch: 19/100 | Loss: 0.6453\n",
            "Epoch: 20/100 | Loss: 0.6453\n",
            "Epoch: 21/100 | Loss: 0.6453\n",
            "Epoch: 22/100 | Loss: 0.6453\n",
            "Epoch: 23/100 | Loss: 0.6453\n",
            "Epoch: 24/100 | Loss: 0.6453\n",
            "Epoch: 25/100 | Loss: 0.6453\n",
            "Epoch: 26/100 | Loss: 0.6453\n",
            "Epoch: 27/100 | Loss: 0.6453\n",
            "Epoch: 28/100 | Loss: 0.6453\n",
            "Epoch: 29/100 | Loss: 0.6453\n",
            "Epoch: 30/100 | Loss: 0.6453\n",
            "Epoch: 31/100 | Loss: 0.6453\n",
            "Epoch: 32/100 | Loss: 0.6453\n",
            "Epoch: 33/100 | Loss: 0.6453\n",
            "Epoch: 34/100 | Loss: 0.6453\n",
            "Epoch: 35/100 | Loss: 0.6453\n",
            "Epoch: 36/100 | Loss: 0.6453\n",
            "Epoch: 37/100 | Loss: 0.6453\n",
            "Epoch: 38/100 | Loss: 0.6453\n",
            "Epoch: 39/100 | Loss: 0.6453\n",
            "Epoch: 40/100 | Loss: 0.6453\n",
            "Epoch: 41/100 | Loss: 0.6453\n",
            "Epoch: 42/100 | Loss: 0.6453\n",
            "Epoch: 43/100 | Loss: 0.6453\n",
            "Epoch: 44/100 | Loss: 0.6453\n",
            "Epoch: 45/100 | Loss: 0.6453\n",
            "Epoch: 46/100 | Loss: 0.6453\n",
            "Epoch: 47/100 | Loss: 0.6453\n",
            "Epoch: 48/100 | Loss: 0.6453\n",
            "Epoch: 49/100 | Loss: 0.6453\n",
            "Epoch: 50/100 | Loss: 0.6453\n",
            "Epoch: 51/100 | Loss: 0.6453\n",
            "Epoch: 52/100 | Loss: 0.6453\n",
            "Epoch: 53/100 | Loss: 0.6453\n",
            "Epoch: 54/100 | Loss: 0.6453\n",
            "Epoch: 55/100 | Loss: 0.6453\n",
            "Epoch: 56/100 | Loss: 0.6453\n",
            "Epoch: 57/100 | Loss: 0.6453\n",
            "Epoch: 58/100 | Loss: 0.6453\n",
            "Epoch: 59/100 | Loss: 0.6453\n",
            "Epoch: 60/100 | Loss: 0.6453\n",
            "Epoch: 61/100 | Loss: 0.6453\n",
            "Epoch: 62/100 | Loss: 0.6453\n",
            "Epoch: 63/100 | Loss: 0.6453\n",
            "Epoch: 64/100 | Loss: 0.6453\n",
            "Epoch: 65/100 | Loss: 0.6453\n",
            "Epoch: 66/100 | Loss: 0.6453\n",
            "Epoch: 67/100 | Loss: 0.6453\n",
            "Epoch: 68/100 | Loss: 0.6453\n",
            "Epoch: 69/100 | Loss: 0.6453\n",
            "Epoch: 70/100 | Loss: 0.6453\n",
            "Epoch: 71/100 | Loss: 0.6453\n",
            "Epoch: 72/100 | Loss: 0.6453\n",
            "Epoch: 73/100 | Loss: 0.6453\n",
            "Epoch: 74/100 | Loss: 0.6453\n",
            "Epoch: 75/100 | Loss: 0.6453\n",
            "Epoch: 76/100 | Loss: 0.6453\n",
            "Epoch: 77/100 | Loss: 0.6453\n",
            "Epoch: 78/100 | Loss: 0.6453\n",
            "Epoch: 79/100 | Loss: 0.6453\n",
            "Epoch: 80/100 | Loss: 0.6453\n",
            "Epoch: 81/100 | Loss: 0.6453\n",
            "Epoch: 82/100 | Loss: 0.6453\n",
            "Epoch: 83/100 | Loss: 0.6453\n",
            "Epoch: 84/100 | Loss: 0.6453\n",
            "Epoch: 85/100 | Loss: 0.6453\n",
            "Epoch: 86/100 | Loss: 0.6453\n",
            "Epoch: 87/100 | Loss: 0.6453\n",
            "Epoch: 88/100 | Loss: 0.6453\n",
            "Epoch: 89/100 | Loss: 0.6453\n",
            "Epoch: 90/100 | Loss: 0.6453\n",
            "Epoch: 91/100 | Loss: 0.6453\n",
            "Epoch: 92/100 | Loss: 0.6453\n",
            "Epoch: 93/100 | Loss: 0.6453\n",
            "Epoch: 94/100 | Loss: 0.6453\n",
            "Epoch: 95/100 | Loss: 0.6453\n",
            "Epoch: 96/100 | Loss: 0.6453\n",
            "Epoch: 97/100 | Loss: 0.6453\n",
            "Epoch: 98/100 | Loss: 0.6453\n",
            "Epoch: 99/100 | Loss: 0.6453\n",
            "Epoch: 100/100 | Loss: 0.6453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) layer\n",
        "의\n",
        "개\n",
        "수\n",
        ",\n",
        "node\n",
        "의\n",
        "개수\n",
        ",\n",
        "activation\n",
        "의\n",
        "종\n",
        "류\n",
        "를\n",
        "변\n",
        "화\n",
        "시\n",
        "켜\n",
        "가며\n",
        "성\n",
        "능\n",
        "이\n",
        "최\n",
        "대\n",
        "화\n",
        "되\n",
        "는\n",
        "관\n",
        "점\n",
        "에서\n",
        "최\n",
        "적\n",
        "모\n",
        "델\n",
        "을\n",
        "찾\n",
        "고\n",
        "그\n",
        "결\n",
        "과\n",
        "를\n",
        "분\n",
        "석\n",
        "하\n",
        "시오\n"
      ],
      "metadata": {
        "id": "49pyGx-FfCkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer별 비교"
      ],
      "metadata": {
        "id": "NWE7lsHdiGRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer_Model_1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Layer_Model_1,self).__init__()\n",
        "    self.l4 = nn.Linear(8,7)\n",
        "    self.l5 = nn.Linear(7,3)\n",
        "    self.l9 = nn.Linear(3,2)\n",
        "    self.l10 = nn.Linear(2,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out4 = self.relu(self.l4(x))\n",
        "    out5 = self.relu(self.l5(out4))\n",
        "    out9 = self.relu(self.l9(out5))\n",
        "    y_pred = self.sigmoid(self.l10(out9))\n",
        "    return y_pred\n",
        "class Layer_Model_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Layer_Model_2,self).__init__()\n",
        "    self.l4 = nn.Linear(8,7)\n",
        "    self.l5 = nn.Linear(7,5)\n",
        "    self.l6 = nn.Linear(5,3)\n",
        "    self.l9 = nn.Linear(3,2)\n",
        "    self.l10 = nn.Linear(2,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out4 = self.relu(self.l4(x))\n",
        "    out5 = self.relu(self.l5(out4))\n",
        "    out6 = self.relu(self.l6(out5))\n",
        "    out9 = self.relu(self.l9(out6))\n",
        "    y_pred = self.sigmoid(self.l10(out9))\n",
        "    return y_pred\n",
        "\n",
        "class Layer_Model_3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Layer_Model_3,self).__init__()\n",
        "    self.l1 = nn.Linear(8,5)\n",
        "    self.l2 = nn.Linear(5,3)\n",
        "    self.l3 = nn.Linear(3,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "yY-TQfqafLSe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lmodel1 = Layer_Model_1()\n",
        "criterion1 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer1 = optim.SGD(lmodel1.parameters(),lr=0.1)\n",
        "\n",
        "lmodel2 = Layer_Model_2()\n",
        "criterion2 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer2 = optim.SGD(lmodel2.parameters(),lr=0.1)\n",
        "\n",
        "lmodel3 = Layer_Model_3()\n",
        "criterion3 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer3 = optim.SGD(lmodel3.parameters(),lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "  y_pred1 = lmodel1(x_data)\n",
        "  y_pred2 = lmodel2(x_data)\n",
        "  y_pred3 = lmodel3(x_data)\n",
        "  loss1 = criterion1(y_pred1, y_data)\n",
        "  loss2 = criterion2(y_pred2, y_data)\n",
        "  loss3 = criterion3(y_pred3, y_data)\n",
        "  optimizer1.zero_grad()\n",
        "  loss1.backward()\n",
        "  optimizer1.step()\n",
        "  optimizer2.zero_grad()\n",
        "  loss2.backward()\n",
        "  optimizer2.step()\n",
        "  optimizer3.zero_grad()\n",
        "  loss3.backward()\n",
        "  optimizer3.step()\n",
        "print(epoch+1,\"epoch 완료\")\n",
        "print(\"---------------------------------\")\n",
        "print(f'Layer3개{loss3.item():.4f}')\n",
        "print(f'Layer4개{loss1.item():.4f}')\n",
        "print(f'Layer5개{loss2.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaKaE6F7gTjZ",
        "outputId": "ffacff47-f355-408b-c17d-133352b9a64e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 epoch 완료\n",
            "---------------------------------\n",
            "Layer3개0.6317\n",
            "Layer4개0.6459\n",
            "Layer5개0.6453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "node 개수별 비교"
      ],
      "metadata": {
        "id": "wpdfIqytibFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node_Model_1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Node_Model_1,self).__init__()\n",
        "    self.l1 = nn.Linear(8,7)\n",
        "    self.l2 = nn.Linear(7,6)\n",
        "    self.l3 = nn.Linear(6,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "class Node_Model_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Node_Model_2,self).__init__()\n",
        "    self.l1 = nn.Linear(8,5)\n",
        "    self.l2 = nn.Linear(5,3)\n",
        "    self.l3 = nn.Linear(3,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred\n",
        "\n",
        "class Node_Model_3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Node_Model_3,self).__init__()\n",
        "    self.l1 = nn.Linear(8,3)\n",
        "    self.l2 = nn.Linear(3,2)\n",
        "    self.l3 = nn.Linear(2,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "MXNLoY9wiWmg"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lmodel1 = Node_Model_1()\n",
        "criterion1 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer1 = optim.SGD(lmodel1.parameters(),lr=0.1)\n",
        "\n",
        "lmodel2 = Node_Model_2()\n",
        "criterion2 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer2 = optim.SGD(lmodel2.parameters(),lr=0.1)\n",
        "\n",
        "lmodel3 = Node_Model_3()\n",
        "criterion3 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer3 = optim.SGD(lmodel3.parameters(),lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "  y_pred1 = lmodel1(x_data)\n",
        "  y_pred2 = lmodel2(x_data)\n",
        "  y_pred3 = lmodel3(x_data)\n",
        "  loss1 = criterion1(y_pred1, y_data)\n",
        "  loss2 = criterion2(y_pred2, y_data)\n",
        "  loss3 = criterion3(y_pred3, y_data)\n",
        "  optimizer1.zero_grad()\n",
        "  loss1.backward()\n",
        "  optimizer1.step()\n",
        "  optimizer2.zero_grad()\n",
        "  loss2.backward()\n",
        "  optimizer2.step()\n",
        "  optimizer3.zero_grad()\n",
        "  loss3.backward()\n",
        "  optimizer3.step()\n",
        "print(epoch+1,\"epoch 완료\")\n",
        "print(\"---------------------------------\")\n",
        "print(f'Node개수 상:{loss1.item():.4f}')\n",
        "print(f'Node개수 중:{loss2.item():.4f}')\n",
        "print(f'Node개수 하:{loss3.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5eSbkyBjFgn",
        "outputId": "6713ff00-9b2f-4b8c-b5a4-6cec22f9f25c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 epoch 완료\n",
            "---------------------------------\n",
            "Node개수 상:0.5995\n",
            "Node개수 중:0.6209\n",
            "Node개수 하:0.6467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "activation fucntion 별 비교"
      ],
      "metadata": {
        "id": "gsFIA1ZCjlzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ac_Model_1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Ac_Model_1,self).__init__()\n",
        "    self.l1 = nn.Linear(8,5)\n",
        "    self.l2 = nn.Linear(5,3)\n",
        "    self.l3 = nn.Linear(3,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.relu(self.l1(x))\n",
        "    out2 = self.relu(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "class Ac_Model_2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Ac_Model_2,self).__init__()\n",
        "    self.l1 = nn.Linear(8,5)\n",
        "    self.l2 = nn.Linear(5,3)\n",
        "    self.l3 = nn.Linear(3,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    out1 = self.sigmoid(self.l1(x))\n",
        "    out2 = self.sigmoid(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "\n",
        "class Ac_Model_3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Ac_Model_3,self).__init__()\n",
        "    self.l1 = nn.Linear(8,5)\n",
        "    self.l2 = nn.Linear(5,3)\n",
        "    self.l3 = nn.Linear(3,1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.ht = nn.Hardtanh()\n",
        "  def forward(self,x):\n",
        "    out1 = self.ht(self.l1(x))\n",
        "    out2 = self.ht(self.l2(out1))\n",
        "    y_pred = self.sigmoid(self.l3(out2))\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "w4oG3-r8jonN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lmodel1 = Ac_Model_1()\n",
        "criterion1 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer1 = optim.SGD(lmodel1.parameters(),lr=0.1)\n",
        "\n",
        "lmodel2 = Ac_Model_2()\n",
        "criterion2 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer2 = optim.SGD(lmodel2.parameters(),lr=0.1)\n",
        "\n",
        "lmodel3 = Ac_Model_3()\n",
        "criterion3 = nn.BCELoss(reduction = 'mean')\n",
        "optimizer3 = optim.SGD(lmodel3.parameters(),lr=0.1)\n",
        "\n",
        "for epoch in range(100):\n",
        "  y_pred1 = lmodel1(x_data)\n",
        "  y_pred2 = lmodel2(x_data)\n",
        "  y_pred3 = lmodel3(x_data)\n",
        "  loss1 = criterion1(y_pred1, y_data)\n",
        "  loss2 = criterion2(y_pred2, y_data)\n",
        "  loss3 = criterion3(y_pred3, y_data)\n",
        "  optimizer1.zero_grad()\n",
        "  loss1.backward()\n",
        "  optimizer1.step()\n",
        "  optimizer2.zero_grad()\n",
        "  loss2.backward()\n",
        "  optimizer2.step()\n",
        "  optimizer3.zero_grad()\n",
        "  loss3.backward()\n",
        "  optimizer3.step()\n",
        "print(epoch+1,\"epoch 완료\")\n",
        "print(\"---------------------------------\")\n",
        "print(f'ReLU 사용:{loss1.item():.4f}')\n",
        "print(f'Sigmoid 사용:{loss2.item():.4f}')\n",
        "print(f'Hardtanh 사용:{loss3.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11qt7LnskVgP",
        "outputId": "4cc3f2c9-22ba-4915-d043-8a85fca87b97"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 epoch 완료\n",
            "---------------------------------\n",
            "ReLU 사용:0.6445\n",
            "Sigmoid 사용:0.6455\n",
            "Hardtanh 사용:0.6084\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4\n",
        ")\n",
        "Diabets dataset\n",
        "외에\n",
        "다\n",
        "른\n",
        "classification dataset\n",
        "을\n",
        "인\n",
        "터\n",
        "넷\n",
        "에서\n",
        "찾\n",
        "은\n",
        "다\n",
        "음\n",
        ",\n",
        "적\n",
        "절\n",
        "한\n",
        "딥\n",
        "러\n",
        "닝\n",
        "모\n",
        "델\n",
        "을\n",
        "만\n",
        "들고\n",
        "학\n",
        "습\n",
        "을\n",
        "수\n",
        "행\n",
        "하\n",
        "시오\n",
        "."
      ],
      "metadata": {
        "id": "kfNf3c92ktBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris['data']\n",
        "y = iris['target']\n",
        "names = iris['target_names']\n",
        "feature_names = iris['feature_names']\n",
        "\n",
        "\n",
        "# Scale data to have mean 0 and variance 1 \n",
        "# which is importance for convergence of the neural network\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "\n",
        "# Split the data set into training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=2)\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.layer1 = nn.Linear(input_dim, 50)\n",
        "        self.layer2 = nn.Linear(50, 50)\n",
        "        self.layer3 = nn.Linear(50, 3)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        x = F.softmax(self.layer3(x), dim=1)\n",
        "        return x\n",
        "\n",
        "\n",
        "model     = Model(X_train.shape[1])\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn   = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "EPOCHS  = 100\n",
        "X_train = Variable(torch.from_numpy(X_train)).float()\n",
        "y_train = Variable(torch.from_numpy(y_train)).long()\n",
        "X_test  = Variable(torch.from_numpy(X_test)).float()\n",
        "y_test  = Variable(torch.from_numpy(y_test)).long()\n",
        "\n",
        "\n",
        "loss_list     = np.zeros((EPOCHS,))\n",
        "accuracy_list = np.zeros((EPOCHS,))\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    y_pred = model(X_train)\n",
        "    loss = loss_fn(y_pred, y_train)\n",
        "    loss_list[epoch] = loss.item()\n",
        "    \n",
        "    # Zero gradients\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f'Epochs: {epoch+1} | loss: {loss.item() : .4f}')\n"
      ],
      "metadata": {
        "id": "fcxaM_CLU-W4",
        "outputId": "ccc55ec0-16ff-4092-fc22-6f7c92f27299",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 1 | loss:  1.0882\n",
            "Epochs: 2 | loss:  1.0830\n",
            "Epochs: 3 | loss:  1.0779\n",
            "Epochs: 4 | loss:  1.0726\n",
            "Epochs: 5 | loss:  1.0673\n",
            "Epochs: 6 | loss:  1.0620\n",
            "Epochs: 7 | loss:  1.0565\n",
            "Epochs: 8 | loss:  1.0510\n",
            "Epochs: 9 | loss:  1.0453\n",
            "Epochs: 10 | loss:  1.0396\n",
            "Epochs: 11 | loss:  1.0338\n",
            "Epochs: 12 | loss:  1.0280\n",
            "Epochs: 13 | loss:  1.0221\n",
            "Epochs: 14 | loss:  1.0161\n",
            "Epochs: 15 | loss:  1.0100\n",
            "Epochs: 16 | loss:  1.0038\n",
            "Epochs: 17 | loss:  0.9974\n",
            "Epochs: 18 | loss:  0.9910\n",
            "Epochs: 19 | loss:  0.9846\n",
            "Epochs: 20 | loss:  0.9781\n",
            "Epochs: 21 | loss:  0.9715\n",
            "Epochs: 22 | loss:  0.9648\n",
            "Epochs: 23 | loss:  0.9581\n",
            "Epochs: 24 | loss:  0.9513\n",
            "Epochs: 25 | loss:  0.9445\n",
            "Epochs: 26 | loss:  0.9377\n",
            "Epochs: 27 | loss:  0.9309\n",
            "Epochs: 28 | loss:  0.9241\n",
            "Epochs: 29 | loss:  0.9174\n",
            "Epochs: 30 | loss:  0.9107\n",
            "Epochs: 31 | loss:  0.9040\n",
            "Epochs: 32 | loss:  0.8973\n",
            "Epochs: 33 | loss:  0.8907\n",
            "Epochs: 34 | loss:  0.8842\n",
            "Epochs: 35 | loss:  0.8778\n",
            "Epochs: 36 | loss:  0.8714\n",
            "Epochs: 37 | loss:  0.8652\n",
            "Epochs: 38 | loss:  0.8591\n",
            "Epochs: 39 | loss:  0.8531\n",
            "Epochs: 40 | loss:  0.8473\n",
            "Epochs: 41 | loss:  0.8416\n",
            "Epochs: 42 | loss:  0.8361\n",
            "Epochs: 43 | loss:  0.8307\n",
            "Epochs: 44 | loss:  0.8253\n",
            "Epochs: 45 | loss:  0.8202\n",
            "Epochs: 46 | loss:  0.8151\n",
            "Epochs: 47 | loss:  0.8102\n",
            "Epochs: 48 | loss:  0.8054\n",
            "Epochs: 49 | loss:  0.8007\n",
            "Epochs: 50 | loss:  0.7962\n",
            "Epochs: 51 | loss:  0.7917\n",
            "Epochs: 52 | loss:  0.7874\n",
            "Epochs: 53 | loss:  0.7832\n",
            "Epochs: 54 | loss:  0.7792\n",
            "Epochs: 55 | loss:  0.7752\n",
            "Epochs: 56 | loss:  0.7714\n",
            "Epochs: 57 | loss:  0.7677\n",
            "Epochs: 58 | loss:  0.7641\n",
            "Epochs: 59 | loss:  0.7606\n",
            "Epochs: 60 | loss:  0.7572\n",
            "Epochs: 61 | loss:  0.7538\n",
            "Epochs: 62 | loss:  0.7506\n",
            "Epochs: 63 | loss:  0.7475\n",
            "Epochs: 64 | loss:  0.7444\n",
            "Epochs: 65 | loss:  0.7414\n",
            "Epochs: 66 | loss:  0.7385\n",
            "Epochs: 67 | loss:  0.7357\n",
            "Epochs: 68 | loss:  0.7329\n",
            "Epochs: 69 | loss:  0.7302\n",
            "Epochs: 70 | loss:  0.7275\n",
            "Epochs: 71 | loss:  0.7249\n",
            "Epochs: 72 | loss:  0.7223\n",
            "Epochs: 73 | loss:  0.7198\n",
            "Epochs: 74 | loss:  0.7173\n",
            "Epochs: 75 | loss:  0.7148\n",
            "Epochs: 76 | loss:  0.7124\n",
            "Epochs: 77 | loss:  0.7100\n",
            "Epochs: 78 | loss:  0.7076\n",
            "Epochs: 79 | loss:  0.7052\n",
            "Epochs: 80 | loss:  0.7029\n",
            "Epochs: 81 | loss:  0.7005\n",
            "Epochs: 82 | loss:  0.6982\n",
            "Epochs: 83 | loss:  0.6959\n",
            "Epochs: 84 | loss:  0.6936\n",
            "Epochs: 85 | loss:  0.6913\n",
            "Epochs: 86 | loss:  0.6890\n",
            "Epochs: 87 | loss:  0.6866\n",
            "Epochs: 88 | loss:  0.6843\n",
            "Epochs: 89 | loss:  0.6820\n",
            "Epochs: 90 | loss:  0.6796\n",
            "Epochs: 91 | loss:  0.6773\n",
            "Epochs: 92 | loss:  0.6749\n",
            "Epochs: 93 | loss:  0.6726\n",
            "Epochs: 94 | loss:  0.6703\n",
            "Epochs: 95 | loss:  0.6680\n",
            "Epochs: 96 | loss:  0.6657\n",
            "Epochs: 97 | loss:  0.6634\n",
            "Epochs: 98 | loss:  0.6611\n",
            "Epochs: 99 | loss:  0.6588\n",
            "Epochs: 100 | loss:  0.6565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torch.utils import data\n",
        "batch_size = 64\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "train_dataset = torchvision.datasets.MNIST(root='./mnist_data/',train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./mnist_data/',train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
        "train_loader = data.DataLoader(dataset = train_dataset, batch_size = batch_size,shuffle = True)\n",
        "test_loader = data.DataLoader(dataset=test_dataset,batch_size = batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "3h5vZ3O6lHxm"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.l1 = nn.Linear(784,520)\n",
        "    self.l2 = nn.Linear(520,320)\n",
        "    self.l3 = nn.Linear(320,240)\n",
        "    self.l4 = nn.Linear(240,120)\n",
        "    self.l5 = nn.Linear(120,1)\n",
        "  \n",
        "  def forward(self,x):\n",
        "    x = x.view(-1,784)\n",
        "    x= F.relu(self.l1(x))\n",
        "    x = F.relu(self.l2(x))\n",
        "    x= F.relu(self.l3(x))\n",
        "    x= F.relu(self.l4(x))\n",
        "    return self.l5(x)"
      ],
      "metadata": {
        "id": "jKCR2KbllOOI"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss(reduction = 'mean')\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.1,momentum = 0.5)\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for i, data in enumerate(train_loader):\n",
        "    inputs, lables = data\n",
        "    y_pred = model(inputs)\n",
        "    loss = criterion(y_pred, lables)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%10 == 0:\n",
        "        print('Epoch: {} | Batch : {}/{} ({:f}%) Loss: {loss.item():.6f}'.format(epoch,i*len(data),len(train_loader.dataset),100*i/len(train_loader)))"
      ],
      "metadata": {
        "id": "7hlarBvFlaMF"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch import tensor\n",
        "class New_dataset(Dataset):\n",
        "\n",
        "  def __init__(self):\n",
        "    xy = np.loadtxt('/content/gdrive/My Drive/Colab Notebooks/data/diabetes.csv.gz',delimiter=',', dtype=np.float32)\n",
        "    self.len = xy.shape[0]\n",
        "    self.x_data = from_numpy(xy[:,0:-1])\n",
        "    self.y_data = from_numpy(xy[:,[-1]])\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.x_data[index],self.y_data[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len\n",
        "\n",
        "dataset = New_dataset()\n",
        "train_loader = DataLoader(dataset = dataset, batch_size = 32, shuffle= True, num_workers=2)"
      ],
      "metadata": {
        "id": "3HQbXYCRNEkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. [Exercise 8-1] 아래 웹사이트에서 Titanic dataset 을 다운받고, 해당 dataset 에 대한 data loader 및 classifier 를 만들어 학습을 수행하시오.(소스코드 및 학습 결과를 첨부할 것)"
      ],
      "metadata": {
        "id": "Jp_uJUH9VVXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim, from_numpy\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.f1 = nn.Linear(6,4)\n",
        "        self.f2 = nn.Linear(4,4)\n",
        "        self.f3 = nn.Linear(4,2)\n",
        "        self.f4 = nn.Linear(2,2)\n",
        "        self.f5 = nn.Linear(2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        out1 = self.relu(self.f1(x))\n",
        "        out2 = self.relu(self.f2(out1))\n",
        "        out3 = self.relu(self.f3(out2))\n",
        "        out4 = self.relu(self.f4(out3))\n",
        "        out5 = self.relu(self.f5(out4))\n",
        "        y_pred = self.sigmoid(out5)\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "class Titanic(Dataset):\n",
        "    def __init__(self):\n",
        "        self.dataset_train = pd.read_csv('/content/gdrive/ My Drive/Colab Notebooks/data/train.csv')      \n",
        "        self.dataset_train = self.dataset_train.drop(columns=\"Name\")\n",
        "        self.dataset_train = self.dataset_train.drop(columns=\"Ticket\")\n",
        "        self.dataset_train = self.dataset_train.dropna()\n",
        "        self.dataset_train['Passengers'] = self.dataset_train['Parch'] + self.dataset_train['SibSp'] + 1\n",
        "        self.dataset_train = self.dataset_train.drop(['SibSp', 'Parch'], axis=1)\n",
        "        self.dataset_train = self.dataset_train.drop(columns=\"Cabin\")\n",
        "        \n",
        "        self.dataset_train_y = self.dataset_train['Survived']\n",
        "        self.dataset_train.drop(columns=\"Survived\", inplace=True)\n",
        "        self.dataset_train.drop(columns=\"PassengerId\", inplace=True)\n",
        "        self.dataset_train = pd.DataFrame(data = self.dataset_train).reset_index(drop=True)\n",
        "        self.dataset_train_y = self.dataset_train_y.reset_index(drop=True)\n",
        "        \n",
        "        \n",
        "        labelencoder_X_1 = LabelEncoder()\n",
        "        self.dataset_train['Sex'] = labelencoder_X_1.fit_transform(self.dataset_train[\"Sex\"])\n",
        "        self.dataset_train['Embarked'] = labelencoder_X_1.fit_transform(self.dataset_train[\"Embarked\"])\n",
        "\n",
        "\n",
        "        self.dataset_train = self.dataset_train.values.astype(np.float32)\n",
        "        self.len = self.dataset_train.shape[0]\n",
        "    def __getitem__(self, index):\n",
        "        return self.dataset_train[index], self.dataset_train_y[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "dataset = Titanic()\n",
        "train_loader = DataLoader(dataset = dataset,\n",
        "                          batch_size= 20,\n",
        "                          shuffle = True\n",
        "                          )\n",
        "\n",
        "\n",
        "model = Model()\n",
        "\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(reduction = 'mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "loss = float()\n",
        "\n",
        "\n",
        "for epoch in range(100):\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "\n",
        "        y_pred = model(inputs)\n",
        "        y_pred = y_pred.flatten()\n",
        "        loss = criterion(y_pred, labels.float())\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f'Epoch{epoch + 1} | Loss: {loss.item() : .4f} ')"
      ],
      "metadata": {
        "id": "HXwz-O8HR4UF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59364e51-3168-4e6e-9983-7696cec9fc43"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch1 | Loss:  0.6301 \n",
            "Epoch2 | Loss:  0.8110 \n",
            "Epoch3 | Loss:  0.6194 \n",
            "Epoch4 | Loss:  0.6141 \n",
            "Epoch5 | Loss:  0.4436 \n",
            "Epoch6 | Loss:  0.8815 \n",
            "Epoch7 | Loss:  0.4397 \n",
            "Epoch8 | Loss:  0.5678 \n",
            "Epoch9 | Loss:  0.8615 \n",
            "Epoch10 | Loss:  0.3542 \n",
            "Epoch11 | Loss:  0.5569 \n",
            "Epoch12 | Loss:  0.8562 \n",
            "Epoch13 | Loss:  0.6330 \n",
            "Epoch14 | Loss:  0.5895 \n",
            "Epoch15 | Loss:  0.8928 \n",
            "Epoch16 | Loss:  0.6303 \n",
            "Epoch17 | Loss:  0.6598 \n",
            "Epoch18 | Loss:  0.7720 \n",
            "Epoch19 | Loss:  0.6307 \n",
            "Epoch20 | Loss:  0.8690 \n",
            "Epoch21 | Loss:  0.9473 \n",
            "Epoch22 | Loss:  0.9121 \n",
            "Epoch23 | Loss:  0.5544 \n",
            "Epoch24 | Loss:  0.6415 \n",
            "Epoch25 | Loss:  0.6988 \n",
            "Epoch26 | Loss:  0.9162 \n",
            "Epoch27 | Loss:  0.6459 \n",
            "Epoch28 | Loss:  0.5951 \n",
            "Epoch29 | Loss:  0.5336 \n",
            "Epoch30 | Loss:  0.5384 \n",
            "Epoch31 | Loss:  0.6470 \n",
            "Epoch32 | Loss:  0.3447 \n",
            "Epoch33 | Loss:  0.3414 \n",
            "Epoch34 | Loss:  0.3334 \n",
            "Epoch35 | Loss:  0.6693 \n",
            "Epoch36 | Loss:  0.6464 \n",
            "Epoch37 | Loss:  0.4216 \n",
            "Epoch38 | Loss:  0.7004 \n",
            "Epoch39 | Loss:  0.3633 \n",
            "Epoch40 | Loss:  0.3714 \n",
            "Epoch41 | Loss:  0.7410 \n",
            "Epoch42 | Loss:  0.5872 \n",
            "Epoch43 | Loss:  0.6465 \n",
            "Epoch44 | Loss:  0.3684 \n",
            "Epoch45 | Loss:  0.3854 \n",
            "Epoch46 | Loss:  0.6055 \n",
            "Epoch47 | Loss:  0.3228 \n",
            "Epoch48 | Loss:  0.3708 \n",
            "Epoch49 | Loss:  0.8669 \n",
            "Epoch50 | Loss:  0.5350 \n",
            "Epoch51 | Loss:  0.6469 \n",
            "Epoch52 | Loss:  0.3177 \n",
            "Epoch53 | Loss:  0.4205 \n",
            "Epoch54 | Loss:  0.6407 \n",
            "Epoch55 | Loss:  0.4206 \n",
            "Epoch56 | Loss:  0.5872 \n",
            "Epoch57 | Loss:  0.3134 \n",
            "Epoch58 | Loss:  0.3177 \n",
            "Epoch59 | Loss:  0.5878 \n",
            "Epoch60 | Loss:  0.3155 \n",
            "Epoch61 | Loss:  0.6466 \n",
            "Epoch62 | Loss:  0.5340 \n",
            "Epoch63 | Loss:  0.5335 \n",
            "Epoch64 | Loss:  0.3669 \n",
            "Epoch65 | Loss:  0.3170 \n",
            "Epoch66 | Loss:  1.0250 \n",
            "Epoch67 | Loss:  0.3868 \n",
            "Epoch68 | Loss:  0.9205 \n",
            "Epoch69 | Loss:  0.7010 \n",
            "Epoch70 | Loss:  0.8074 \n",
            "Epoch71 | Loss:  0.9402 \n",
            "Epoch72 | Loss:  0.5819 \n",
            "Epoch73 | Loss:  0.5350 \n",
            "Epoch74 | Loss:  0.8074 \n",
            "Epoch75 | Loss:  0.7612 \n",
            "Epoch76 | Loss:  0.5886 \n",
            "Epoch77 | Loss:  0.6846 \n",
            "Epoch78 | Loss:  0.7543 \n",
            "Epoch79 | Loss:  0.5871 \n",
            "Epoch80 | Loss:  0.5338 \n",
            "Epoch81 | Loss:  0.3669 \n",
            "Epoch82 | Loss:  0.6466 \n",
            "Epoch83 | Loss:  0.6865 \n",
            "Epoch84 | Loss:  0.8782 \n",
            "Epoch85 | Loss:  0.7002 \n",
            "Epoch86 | Loss:  0.3669 \n",
            "Epoch87 | Loss:  0.3723 \n",
            "Epoch88 | Loss:  0.8931 \n",
            "Epoch89 | Loss:  0.7238 \n",
            "Epoch90 | Loss:  0.5871 \n",
            "Epoch91 | Loss:  0.5347 \n",
            "Epoch92 | Loss:  1.0871 \n",
            "Epoch93 | Loss:  0.8669 \n",
            "Epoch94 | Loss:  0.3133 \n",
            "Epoch95 | Loss:  0.6466 \n",
            "Epoch96 | Loss:  0.6998 \n",
            "Epoch97 | Loss:  1.0871 \n",
            "Epoch98 | Loss:  0.8669 \n",
            "Epoch99 | Loss:  0.9715 \n",
            "Epoch100 | Loss:  0.7002 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn, optim, from_numpy\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.autograd import Variable\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model,self).__init__()\n",
        "        self.l1 = nn.Linear(93, 46)\n",
        "        self.l2 = nn.Linear(46,18)\n",
        "        self.l3 = nn.Linear(18,9)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.leakyrelu = nn.LeakyReLU()\n",
        "    def forward(self,x):\n",
        "        x1 = self.relu(self.l1(x))\n",
        "        x2 = self.relu(self.l2(x1))\n",
        "        y_pred = self.relu((self.l3(x2)))\n",
        "        return self.leakyrelu(y_pred)\n",
        "\n",
        "\n",
        "class OttoDataset(Dataset):\n",
        "    def __init__(self):\n",
        "        xy = np.loadtxt('/content/gdrive/ My Drive/Colab Notebooks/data/otto/train.csv',delimiter=',',skiprows = 1, usecols = np.arange(1,94), dtype=np.float32)\n",
        "        df = pd.read_csv('/content/gdrive/ My Drive/Colab Notebooks/data/otto/train.csv', sep = ',')\n",
        "        df['target'] =  df['target'].map({'Class_1': 1, 'Class_2': 2,\n",
        "                                          'Class_3': 3, 'Class_4': 4,\n",
        "                                          'Class_5': 5, 'Class_6': 6,\n",
        "                                          'Class_7': 7, 'Class_8': 8,\n",
        "                                          'Class_9': 9})\n",
        "        df['target'] = df['target'].astype(np.float32)\n",
        "        self.len = xy.shape[0]\n",
        "        self.x_data = torch.from_numpy(xy[:,:])\n",
        "        self.y_data = torch.tensor(df['target'].values)\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "\n",
        "dataset = OttoDataset()\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          shuffle=True,\n",
        "                          batch_size=32,\n",
        "                          num_workers=2)\n",
        "\n",
        "\n",
        "model = Model()\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(reduction = 'mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
        "loss = 1\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for batch_idx, (data,target) in enumerate(train_loader):\n",
        "        data, target = Variable(data).float(),Variable(target).type(torch.LongTensor)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target-1)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f'Epoch{epoch + 1} | Loss: {loss.item() : .4f} ')\n"
      ],
      "metadata": {
        "id": "LDsuyFNsS5sh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63e07796-3fa2-4446-cceb-7c763191d009"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch8 | Loss:  0.4934 \n",
            "Epoch8 | Loss:  0.4513 \n",
            "Epoch8 | Loss:  0.4218 \n",
            "Epoch8 | Loss:  0.6514 \n",
            "Epoch8 | Loss:  0.6087 \n",
            "Epoch8 | Loss:  0.6563 \n",
            "Epoch8 | Loss:  0.4889 \n",
            "Epoch8 | Loss:  0.5083 \n",
            "Epoch8 | Loss:  0.2502 \n",
            "Epoch8 | Loss:  0.4213 \n",
            "Epoch8 | Loss:  0.6497 \n",
            "Epoch8 | Loss:  0.6233 \n",
            "Epoch8 | Loss:  0.5434 \n",
            "Epoch8 | Loss:  0.5032 \n",
            "Epoch8 | Loss:  0.4852 \n",
            "Epoch8 | Loss:  0.4111 \n",
            "Epoch8 | Loss:  0.8119 \n",
            "Epoch8 | Loss:  0.4416 \n",
            "Epoch8 | Loss:  0.5718 \n",
            "Epoch8 | Loss:  0.3830 \n",
            "Epoch8 | Loss:  0.3628 \n",
            "Epoch8 | Loss:  0.4309 \n",
            "Epoch8 | Loss:  0.5002 \n",
            "Epoch8 | Loss:  0.3669 \n",
            "Epoch8 | Loss:  0.7879 \n",
            "Epoch8 | Loss:  0.5752 \n",
            "Epoch8 | Loss:  0.8732 \n",
            "Epoch8 | Loss:  0.5590 \n",
            "Epoch8 | Loss:  0.6580 \n",
            "Epoch8 | Loss:  1.0539 \n",
            "Epoch8 | Loss:  0.3591 \n",
            "Epoch8 | Loss:  0.4349 \n",
            "Epoch8 | Loss:  0.3372 \n",
            "Epoch8 | Loss:  0.1697 \n",
            "Epoch8 | Loss:  0.4468 \n",
            "Epoch8 | Loss:  0.4663 \n",
            "Epoch8 | Loss:  0.4061 \n",
            "Epoch8 | Loss:  0.4945 \n",
            "Epoch8 | Loss:  0.4198 \n",
            "Epoch8 | Loss:  0.2960 \n",
            "Epoch8 | Loss:  0.5935 \n",
            "Epoch8 | Loss:  0.4084 \n",
            "Epoch8 | Loss:  0.5590 \n",
            "Epoch8 | Loss:  0.4714 \n",
            "Epoch8 | Loss:  0.2352 \n",
            "Epoch8 | Loss:  0.4752 \n",
            "Epoch8 | Loss:  0.6407 \n",
            "Epoch8 | Loss:  0.3991 \n",
            "Epoch8 | Loss:  0.6632 \n",
            "Epoch8 | Loss:  0.6316 \n",
            "Epoch8 | Loss:  0.4490 \n",
            "Epoch8 | Loss:  0.6581 \n",
            "Epoch8 | Loss:  0.4881 \n",
            "Epoch8 | Loss:  0.5118 \n",
            "Epoch8 | Loss:  0.6067 \n",
            "Epoch8 | Loss:  0.5080 \n",
            "Epoch8 | Loss:  0.2248 \n",
            "Epoch8 | Loss:  0.2858 \n",
            "Epoch8 | Loss:  0.6690 \n",
            "Epoch8 | Loss:  0.2625 \n",
            "Epoch8 | Loss:  0.4435 \n",
            "Epoch8 | Loss:  0.6143 \n",
            "Epoch8 | Loss:  0.4644 \n",
            "Epoch8 | Loss:  0.5686 \n",
            "Epoch8 | Loss:  0.5733 \n",
            "Epoch8 | Loss:  0.4159 \n",
            "Epoch8 | Loss:  0.3694 \n",
            "Epoch8 | Loss:  0.6735 \n",
            "Epoch8 | Loss:  0.5220 \n",
            "Epoch8 | Loss:  0.7489 \n",
            "Epoch8 | Loss:  0.5911 \n",
            "Epoch8 | Loss:  0.6469 \n",
            "Epoch8 | Loss:  0.5912 \n",
            "Epoch8 | Loss:  0.6133 \n",
            "Epoch8 | Loss:  0.4236 \n",
            "Epoch8 | Loss:  0.4211 \n",
            "Epoch8 | Loss:  0.1783 \n",
            "Epoch8 | Loss:  0.4889 \n",
            "Epoch8 | Loss:  0.3664 \n",
            "Epoch8 | Loss:  0.3727 \n",
            "Epoch8 | Loss:  0.4273 \n",
            "Epoch8 | Loss:  0.6065 \n",
            "Epoch8 | Loss:  0.7385 \n",
            "Epoch8 | Loss:  0.7246 \n",
            "Epoch8 | Loss:  0.6269 \n",
            "Epoch8 | Loss:  0.3625 \n",
            "Epoch8 | Loss:  0.2254 \n",
            "Epoch8 | Loss:  0.4353 \n",
            "Epoch8 | Loss:  0.3958 \n",
            "Epoch8 | Loss:  0.4861 \n",
            "Epoch8 | Loss:  0.4957 \n",
            "Epoch8 | Loss:  0.3980 \n",
            "Epoch8 | Loss:  0.3111 \n",
            "Epoch8 | Loss:  0.8171 \n",
            "Epoch8 | Loss:  0.4855 \n",
            "Epoch8 | Loss:  0.5612 \n",
            "Epoch8 | Loss:  0.6617 \n",
            "Epoch8 | Loss:  0.4613 \n",
            "Epoch8 | Loss:  0.4596 \n",
            "Epoch8 | Loss:  0.5019 \n",
            "Epoch8 | Loss:  0.5935 \n",
            "Epoch8 | Loss:  0.6966 \n",
            "Epoch8 | Loss:  0.7589 \n",
            "Epoch8 | Loss:  0.5437 \n",
            "Epoch8 | Loss:  0.5429 \n",
            "Epoch8 | Loss:  0.7692 \n",
            "Epoch8 | Loss:  0.6074 \n",
            "Epoch8 | Loss:  1.0527 \n",
            "Epoch8 | Loss:  0.3711 \n",
            "Epoch8 | Loss:  0.6128 \n",
            "Epoch8 | Loss:  0.5944 \n",
            "Epoch8 | Loss:  0.5751 \n",
            "Epoch8 | Loss:  0.6765 \n",
            "Epoch8 | Loss:  0.5501 \n",
            "Epoch8 | Loss:  0.4779 \n",
            "Epoch8 | Loss:  0.5439 \n",
            "Epoch8 | Loss:  0.5371 \n",
            "Epoch8 | Loss:  0.4336 \n",
            "Epoch8 | Loss:  0.2737 \n",
            "Epoch8 | Loss:  0.6319 \n",
            "Epoch8 | Loss:  0.4329 \n",
            "Epoch8 | Loss:  0.6788 \n",
            "Epoch8 | Loss:  0.5731 \n",
            "Epoch8 | Loss:  0.8840 \n",
            "Epoch8 | Loss:  0.4628 \n",
            "Epoch8 | Loss:  0.5493 \n",
            "Epoch8 | Loss:  0.6602 \n",
            "Epoch8 | Loss:  0.6239 \n",
            "Epoch8 | Loss:  0.5009 \n",
            "Epoch8 | Loss:  0.5657 \n",
            "Epoch8 | Loss:  0.5378 \n",
            "Epoch8 | Loss:  0.6468 \n",
            "Epoch8 | Loss:  0.7620 \n",
            "Epoch8 | Loss:  0.5402 \n",
            "Epoch8 | Loss:  0.4610 \n",
            "Epoch8 | Loss:  0.5830 \n",
            "Epoch8 | Loss:  0.4880 \n",
            "Epoch8 | Loss:  0.7719 \n",
            "Epoch8 | Loss:  0.5507 \n",
            "Epoch8 | Loss:  0.6129 \n",
            "Epoch8 | Loss:  0.3808 \n",
            "Epoch8 | Loss:  0.3702 \n",
            "Epoch8 | Loss:  0.3565 \n",
            "Epoch8 | Loss:  0.3899 \n",
            "Epoch8 | Loss:  0.2916 \n",
            "Epoch8 | Loss:  0.6793 \n",
            "Epoch8 | Loss:  0.4577 \n",
            "Epoch8 | Loss:  0.4883 \n",
            "Epoch8 | Loss:  0.4007 \n",
            "Epoch8 | Loss:  0.5433 \n",
            "Epoch8 | Loss:  0.5937 \n",
            "Epoch8 | Loss:  0.4221 \n",
            "Epoch8 | Loss:  0.7785 \n",
            "Epoch8 | Loss:  0.3563 \n",
            "Epoch8 | Loss:  0.3687 \n",
            "Epoch8 | Loss:  0.6464 \n",
            "Epoch8 | Loss:  0.6975 \n",
            "Epoch8 | Loss:  0.3402 \n",
            "Epoch8 | Loss:  0.4310 \n",
            "Epoch8 | Loss:  0.4510 \n",
            "Epoch8 | Loss:  0.5559 \n",
            "Epoch8 | Loss:  0.5132 \n",
            "Epoch8 | Loss:  0.5096 \n",
            "Epoch8 | Loss:  0.3752 \n",
            "Epoch8 | Loss:  0.4759 \n",
            "Epoch8 | Loss:  0.5785 \n",
            "Epoch8 | Loss:  0.9654 \n",
            "Epoch8 | Loss:  0.4638 \n",
            "Epoch8 | Loss:  0.3086 \n",
            "Epoch8 | Loss:  0.6617 \n",
            "Epoch8 | Loss:  0.5687 \n",
            "Epoch8 | Loss:  0.5890 \n",
            "Epoch8 | Loss:  0.2466 \n",
            "Epoch8 | Loss:  0.4977 \n",
            "Epoch8 | Loss:  0.3734 \n",
            "Epoch8 | Loss:  0.4963 \n",
            "Epoch8 | Loss:  0.3439 \n",
            "Epoch8 | Loss:  0.6921 \n",
            "Epoch8 | Loss:  0.4096 \n",
            "Epoch8 | Loss:  0.3346 \n",
            "Epoch8 | Loss:  0.4056 \n",
            "Epoch8 | Loss:  0.3899 \n",
            "Epoch8 | Loss:  0.5733 \n",
            "Epoch8 | Loss:  0.3233 \n",
            "Epoch8 | Loss:  0.8957 \n",
            "Epoch8 | Loss:  0.3694 \n",
            "Epoch8 | Loss:  0.4408 \n",
            "Epoch8 | Loss:  0.5244 \n",
            "Epoch8 | Loss:  0.7942 \n",
            "Epoch8 | Loss:  0.6218 \n",
            "Epoch8 | Loss:  0.6730 \n",
            "Epoch8 | Loss:  0.4054 \n",
            "Epoch8 | Loss:  0.7000 \n",
            "Epoch8 | Loss:  0.6770 \n",
            "Epoch8 | Loss:  0.5775 \n",
            "Epoch8 | Loss:  0.3248 \n",
            "Epoch8 | Loss:  0.3948 \n",
            "Epoch8 | Loss:  0.7088 \n",
            "Epoch8 | Loss:  0.4081 \n",
            "Epoch8 | Loss:  0.4659 \n",
            "Epoch8 | Loss:  0.5162 \n",
            "Epoch8 | Loss:  0.6603 \n",
            "Epoch8 | Loss:  0.5789 \n",
            "Epoch8 | Loss:  0.4760 \n",
            "Epoch8 | Loss:  0.7184 \n",
            "Epoch8 | Loss:  1.0656 \n",
            "Epoch8 | Loss:  0.4652 \n",
            "Epoch8 | Loss:  0.5212 \n",
            "Epoch8 | Loss:  0.4693 \n",
            "Epoch8 | Loss:  0.5738 \n",
            "Epoch8 | Loss:  0.6081 \n",
            "Epoch8 | Loss:  0.5944 \n",
            "Epoch8 | Loss:  0.5222 \n",
            "Epoch8 | Loss:  0.9383 \n",
            "Epoch8 | Loss:  0.4903 \n",
            "Epoch8 | Loss:  0.5143 \n",
            "Epoch8 | Loss:  0.3803 \n",
            "Epoch8 | Loss:  0.4384 \n",
            "Epoch8 | Loss:  0.6460 \n",
            "Epoch8 | Loss:  0.5643 \n",
            "Epoch8 | Loss:  0.3399 \n",
            "Epoch8 | Loss:  0.5381 \n",
            "Epoch8 | Loss:  0.2456 \n",
            "Epoch8 | Loss:  0.5602 \n",
            "Epoch8 | Loss:  0.4459 \n",
            "Epoch8 | Loss:  0.8952 \n",
            "Epoch8 | Loss:  0.4181 \n",
            "Epoch8 | Loss:  0.4018 \n",
            "Epoch8 | Loss:  0.6197 \n",
            "Epoch8 | Loss:  0.7723 \n",
            "Epoch8 | Loss:  0.4974 \n",
            "Epoch8 | Loss:  0.4707 \n",
            "Epoch8 | Loss:  0.5536 \n",
            "Epoch8 | Loss:  0.2765 \n",
            "Epoch8 | Loss:  0.3581 \n",
            "Epoch8 | Loss:  0.3885 \n",
            "Epoch8 | Loss:  0.6545 \n",
            "Epoch8 | Loss:  0.5102 \n",
            "Epoch8 | Loss:  0.5354 \n",
            "Epoch8 | Loss:  0.4369 \n",
            "Epoch8 | Loss:  0.4787 \n",
            "Epoch8 | Loss:  0.3545 \n",
            "Epoch8 | Loss:  0.4537 \n",
            "Epoch8 | Loss:  0.5722 \n",
            "Epoch8 | Loss:  0.5908 \n",
            "Epoch8 | Loss:  0.5335 \n",
            "Epoch8 | Loss:  0.5657 \n",
            "Epoch8 | Loss:  0.5817 \n",
            "Epoch8 | Loss:  0.4958 \n",
            "Epoch8 | Loss:  0.5406 \n",
            "Epoch8 | Loss:  0.4905 \n",
            "Epoch8 | Loss:  0.6509 \n",
            "Epoch8 | Loss:  0.5072 \n",
            "Epoch8 | Loss:  0.7047 \n",
            "Epoch8 | Loss:  0.4448 \n",
            "Epoch8 | Loss:  0.5068 \n",
            "Epoch8 | Loss:  0.5678 \n",
            "Epoch8 | Loss:  0.7630 \n",
            "Epoch8 | Loss:  0.4241 \n",
            "Epoch8 | Loss:  0.4851 \n",
            "Epoch8 | Loss:  0.5472 \n",
            "Epoch8 | Loss:  0.5148 \n",
            "Epoch8 | Loss:  0.3709 \n",
            "Epoch8 | Loss:  0.1707 \n",
            "Epoch8 | Loss:  0.5123 \n",
            "Epoch8 | Loss:  0.3973 \n",
            "Epoch8 | Loss:  1.0180 \n",
            "Epoch8 | Loss:  0.3735 \n",
            "Epoch8 | Loss:  0.5276 \n",
            "Epoch8 | Loss:  0.4999 \n",
            "Epoch8 | Loss:  0.4741 \n",
            "Epoch8 | Loss:  0.6682 \n",
            "Epoch8 | Loss:  0.6292 \n",
            "Epoch8 | Loss:  1.0093 \n",
            "Epoch8 | Loss:  0.6147 \n",
            "Epoch8 | Loss:  0.7313 \n",
            "Epoch8 | Loss:  0.5110 \n",
            "Epoch8 | Loss:  0.8109 \n",
            "Epoch8 | Loss:  0.6197 \n",
            "Epoch8 | Loss:  0.4748 \n",
            "Epoch8 | Loss:  0.6807 \n",
            "Epoch8 | Loss:  0.7363 \n",
            "Epoch8 | Loss:  0.6313 \n",
            "Epoch8 | Loss:  0.4340 \n",
            "Epoch8 | Loss:  0.4558 \n",
            "Epoch8 | Loss:  0.4571 \n",
            "Epoch8 | Loss:  0.6116 \n",
            "Epoch8 | Loss:  0.3757 \n",
            "Epoch8 | Loss:  0.6021 \n",
            "Epoch8 | Loss:  0.5131 \n",
            "Epoch8 | Loss:  0.4390 \n",
            "Epoch8 | Loss:  0.4620 \n",
            "Epoch8 | Loss:  0.4413 \n",
            "Epoch8 | Loss:  0.4988 \n",
            "Epoch8 | Loss:  0.6087 \n",
            "Epoch8 | Loss:  0.4730 \n",
            "Epoch8 | Loss:  0.3383 \n",
            "Epoch8 | Loss:  0.4834 \n",
            "Epoch8 | Loss:  0.5489 \n",
            "Epoch8 | Loss:  0.3487 \n",
            "Epoch8 | Loss:  0.6466 \n",
            "Epoch8 | Loss:  0.5216 \n",
            "Epoch8 | Loss:  0.4249 \n",
            "Epoch8 | Loss:  0.4654 \n",
            "Epoch8 | Loss:  0.3851 \n",
            "Epoch8 | Loss:  0.3545 \n",
            "Epoch8 | Loss:  0.6352 \n",
            "Epoch8 | Loss:  0.3305 \n",
            "Epoch8 | Loss:  0.5601 \n",
            "Epoch8 | Loss:  0.6304 \n",
            "Epoch8 | Loss:  0.5560 \n",
            "Epoch8 | Loss:  0.3438 \n",
            "Epoch8 | Loss:  0.8525 \n",
            "Epoch8 | Loss:  0.6010 \n",
            "Epoch8 | Loss:  0.4877 \n",
            "Epoch8 | Loss:  0.4564 \n",
            "Epoch8 | Loss:  0.3044 \n",
            "Epoch8 | Loss:  0.4038 \n",
            "Epoch8 | Loss:  1.0980 \n",
            "Epoch8 | Loss:  0.4289 \n",
            "Epoch8 | Loss:  0.5558 \n",
            "Epoch8 | Loss:  0.3511 \n",
            "Epoch8 | Loss:  0.7602 \n",
            "Epoch8 | Loss:  0.4858 \n",
            "Epoch8 | Loss:  0.6313 \n",
            "Epoch8 | Loss:  0.5728 \n",
            "Epoch8 | Loss:  0.4593 \n",
            "Epoch8 | Loss:  0.6954 \n",
            "Epoch8 | Loss:  0.4192 \n",
            "Epoch8 | Loss:  0.5684 \n",
            "Epoch8 | Loss:  0.5307 \n",
            "Epoch8 | Loss:  0.4437 \n",
            "Epoch8 | Loss:  0.6274 \n",
            "Epoch8 | Loss:  0.5462 \n",
            "Epoch8 | Loss:  0.4397 \n",
            "Epoch8 | Loss:  0.4885 \n",
            "Epoch8 | Loss:  0.5363 \n",
            "Epoch8 | Loss:  0.4563 \n",
            "Epoch8 | Loss:  0.5475 \n",
            "Epoch8 | Loss:  0.5399 \n",
            "Epoch8 | Loss:  0.7911 \n",
            "Epoch8 | Loss:  1.0920 \n",
            "Epoch8 | Loss:  0.5756 \n",
            "Epoch8 | Loss:  0.6300 \n",
            "Epoch8 | Loss:  0.7893 \n",
            "Epoch8 | Loss:  0.2931 \n",
            "Epoch8 | Loss:  0.6115 \n",
            "Epoch8 | Loss:  0.4364 \n",
            "Epoch8 | Loss:  0.3920 \n",
            "Epoch8 | Loss:  0.4190 \n",
            "Epoch8 | Loss:  0.7320 \n",
            "Epoch8 | Loss:  0.3401 \n",
            "Epoch8 | Loss:  0.3598 \n",
            "Epoch8 | Loss:  0.4368 \n",
            "Epoch8 | Loss:  0.4392 \n",
            "Epoch8 | Loss:  0.5202 \n",
            "Epoch8 | Loss:  0.3282 \n",
            "Epoch8 | Loss:  0.5174 \n",
            "Epoch8 | Loss:  0.6307 \n",
            "Epoch8 | Loss:  0.3861 \n",
            "Epoch8 | Loss:  0.3713 \n",
            "Epoch8 | Loss:  0.7091 \n",
            "Epoch8 | Loss:  0.6156 \n",
            "Epoch8 | Loss:  0.8335 \n",
            "Epoch8 | Loss:  0.4995 \n",
            "Epoch8 | Loss:  0.8274 \n",
            "Epoch8 | Loss:  0.4128 \n",
            "Epoch8 | Loss:  0.5913 \n",
            "Epoch8 | Loss:  0.9047 \n",
            "Epoch8 | Loss:  0.3795 \n",
            "Epoch8 | Loss:  0.5618 \n",
            "Epoch8 | Loss:  0.5855 \n",
            "Epoch8 | Loss:  0.4991 \n",
            "Epoch8 | Loss:  0.5623 \n",
            "Epoch8 | Loss:  0.3628 \n",
            "Epoch8 | Loss:  0.4686 \n",
            "Epoch8 | Loss:  0.3829 \n",
            "Epoch8 | Loss:  0.3716 \n",
            "Epoch8 | Loss:  0.6022 \n",
            "Epoch8 | Loss:  0.6707 \n",
            "Epoch8 | Loss:  0.5396 \n",
            "Epoch8 | Loss:  0.5446 \n",
            "Epoch8 | Loss:  0.2964 \n",
            "Epoch8 | Loss:  0.4450 \n",
            "Epoch8 | Loss:  0.6434 \n",
            "Epoch8 | Loss:  0.4592 \n",
            "Epoch8 | Loss:  0.7380 \n",
            "Epoch8 | Loss:  0.3586 \n",
            "Epoch8 | Loss:  0.4378 \n",
            "Epoch8 | Loss:  0.5833 \n",
            "Epoch8 | Loss:  0.6235 \n",
            "Epoch8 | Loss:  0.3233 \n",
            "Epoch8 | Loss:  0.6637 \n",
            "Epoch8 | Loss:  0.7923 \n",
            "Epoch8 | Loss:  0.6020 \n",
            "Epoch8 | Loss:  0.5053 \n",
            "Epoch8 | Loss:  0.4907 \n",
            "Epoch8 | Loss:  0.5472 \n",
            "Epoch8 | Loss:  0.3598 \n",
            "Epoch8 | Loss:  0.3012 \n",
            "Epoch8 | Loss:  0.7281 \n",
            "Epoch8 | Loss:  0.4918 \n",
            "Epoch8 | Loss:  0.6635 \n",
            "Epoch8 | Loss:  0.4847 \n",
            "Epoch8 | Loss:  0.3770 \n",
            "Epoch8 | Loss:  0.4505 \n",
            "Epoch8 | Loss:  0.8180 \n",
            "Epoch8 | Loss:  0.4738 \n",
            "Epoch8 | Loss:  0.7051 \n",
            "Epoch8 | Loss:  0.5281 \n",
            "Epoch8 | Loss:  0.4056 \n",
            "Epoch8 | Loss:  0.6972 \n",
            "Epoch8 | Loss:  0.3476 \n",
            "Epoch8 | Loss:  0.5366 \n",
            "Epoch8 | Loss:  0.5916 \n",
            "Epoch8 | Loss:  0.4430 \n",
            "Epoch8 | Loss:  0.7567 \n",
            "Epoch8 | Loss:  0.4793 \n",
            "Epoch8 | Loss:  0.5634 \n",
            "Epoch8 | Loss:  0.4746 \n",
            "Epoch8 | Loss:  0.7890 \n",
            "Epoch8 | Loss:  0.2643 \n",
            "Epoch8 | Loss:  0.4955 \n",
            "Epoch8 | Loss:  0.3207 \n",
            "Epoch8 | Loss:  0.3305 \n",
            "Epoch8 | Loss:  0.3305 \n",
            "Epoch8 | Loss:  0.6906 \n",
            "Epoch8 | Loss:  0.4015 \n",
            "Epoch8 | Loss:  0.4438 \n",
            "Epoch8 | Loss:  0.3765 \n",
            "Epoch8 | Loss:  0.5036 \n",
            "Epoch8 | Loss:  0.5913 \n",
            "Epoch8 | Loss:  0.7336 \n",
            "Epoch8 | Loss:  0.4833 \n",
            "Epoch8 | Loss:  0.2836 \n",
            "Epoch8 | Loss:  0.6082 \n",
            "Epoch8 | Loss:  0.7997 \n",
            "Epoch8 | Loss:  0.3185 \n",
            "Epoch8 | Loss:  0.8579 \n",
            "Epoch8 | Loss:  0.3726 \n",
            "Epoch8 | Loss:  0.3499 \n",
            "Epoch8 | Loss:  0.5563 \n",
            "Epoch8 | Loss:  0.4839 \n",
            "Epoch8 | Loss:  0.6298 \n",
            "Epoch8 | Loss:  0.8375 \n",
            "Epoch8 | Loss:  0.6178 \n",
            "Epoch8 | Loss:  0.4671 \n",
            "Epoch8 | Loss:  0.4007 \n",
            "Epoch8 | Loss:  0.3767 \n",
            "Epoch8 | Loss:  0.4902 \n",
            "Epoch8 | Loss:  0.5741 \n",
            "Epoch8 | Loss:  0.4498 \n",
            "Epoch8 | Loss:  0.4861 \n",
            "Epoch8 | Loss:  0.6880 \n",
            "Epoch8 | Loss:  0.6580 \n",
            "Epoch8 | Loss:  0.5661 \n",
            "Epoch8 | Loss:  0.7520 \n",
            "Epoch8 | Loss:  0.4443 \n",
            "Epoch8 | Loss:  0.5757 \n",
            "Epoch8 | Loss:  0.4457 \n",
            "Epoch8 | Loss:  0.5055 \n",
            "Epoch8 | Loss:  1.0049 \n",
            "Epoch8 | Loss:  0.4412 \n",
            "Epoch8 | Loss:  0.5840 \n",
            "Epoch8 | Loss:  0.6398 \n",
            "Epoch8 | Loss:  0.4699 \n",
            "Epoch8 | Loss:  0.4254 \n",
            "Epoch8 | Loss:  0.3490 \n",
            "Epoch8 | Loss:  0.6568 \n",
            "Epoch8 | Loss:  0.4398 \n",
            "Epoch8 | Loss:  0.5228 \n",
            "Epoch8 | Loss:  0.8270 \n",
            "Epoch8 | Loss:  0.6452 \n",
            "Epoch8 | Loss:  0.4666 \n",
            "Epoch8 | Loss:  0.4287 \n",
            "Epoch8 | Loss:  0.5004 \n",
            "Epoch8 | Loss:  1.0559 \n",
            "Epoch8 | Loss:  0.4647 \n",
            "Epoch8 | Loss:  0.4980 \n",
            "Epoch8 | Loss:  0.7032 \n",
            "Epoch8 | Loss:  0.4968 \n",
            "Epoch8 | Loss:  0.3962 \n",
            "Epoch8 | Loss:  0.4827 \n",
            "Epoch8 | Loss:  0.5361 \n",
            "Epoch8 | Loss:  0.6294 \n",
            "Epoch8 | Loss:  0.4375 \n",
            "Epoch8 | Loss:  0.4237 \n",
            "Epoch8 | Loss:  0.4499 \n",
            "Epoch8 | Loss:  0.7695 \n",
            "Epoch8 | Loss:  0.4085 \n",
            "Epoch8 | Loss:  0.4230 \n",
            "Epoch8 | Loss:  0.4851 \n",
            "Epoch8 | Loss:  0.6486 \n",
            "Epoch8 | Loss:  0.4349 \n",
            "Epoch8 | Loss:  0.8908 \n",
            "Epoch8 | Loss:  0.7469 \n",
            "Epoch8 | Loss:  0.6931 \n",
            "Epoch8 | Loss:  0.5865 \n",
            "Epoch8 | Loss:  0.5593 \n",
            "Epoch8 | Loss:  0.7068 \n",
            "Epoch8 | Loss:  0.2475 \n",
            "Epoch8 | Loss:  0.6142 \n",
            "Epoch8 | Loss:  0.3723 \n",
            "Epoch8 | Loss:  0.6593 \n",
            "Epoch8 | Loss:  0.4693 \n",
            "Epoch8 | Loss:  0.5888 \n",
            "Epoch8 | Loss:  0.8155 \n",
            "Epoch8 | Loss:  0.8582 \n",
            "Epoch8 | Loss:  0.6701 \n",
            "Epoch8 | Loss:  0.6388 \n",
            "Epoch8 | Loss:  0.6333 \n",
            "Epoch8 | Loss:  0.5323 \n",
            "Epoch8 | Loss:  0.3568 \n",
            "Epoch8 | Loss:  0.4119 \n",
            "Epoch8 | Loss:  0.6013 \n",
            "Epoch8 | Loss:  0.5292 \n",
            "Epoch8 | Loss:  0.7118 \n",
            "Epoch8 | Loss:  0.3801 \n",
            "Epoch8 | Loss:  0.2251 \n",
            "Epoch8 | Loss:  0.4324 \n",
            "Epoch8 | Loss:  0.5830 \n",
            "Epoch8 | Loss:  0.3573 \n",
            "Epoch8 | Loss:  0.6877 \n",
            "Epoch8 | Loss:  0.5568 \n",
            "Epoch8 | Loss:  0.3885 \n",
            "Epoch8 | Loss:  0.4980 \n",
            "Epoch8 | Loss:  0.4347 \n",
            "Epoch8 | Loss:  0.4279 \n",
            "Epoch8 | Loss:  0.4166 \n",
            "Epoch8 | Loss:  0.5147 \n",
            "Epoch8 | Loss:  0.4276 \n",
            "Epoch8 | Loss:  0.8897 \n",
            "Epoch8 | Loss:  0.5242 \n",
            "Epoch8 | Loss:  0.3788 \n",
            "Epoch8 | Loss:  0.4479 \n",
            "Epoch8 | Loss:  0.3974 \n",
            "Epoch8 | Loss:  0.4791 \n",
            "Epoch8 | Loss:  0.2927 \n",
            "Epoch8 | Loss:  0.6669 \n",
            "Epoch8 | Loss:  0.3798 \n",
            "Epoch8 | Loss:  0.4153 \n",
            "Epoch8 | Loss:  0.4906 \n",
            "Epoch8 | Loss:  0.5224 \n",
            "Epoch8 | Loss:  0.5940 \n",
            "Epoch8 | Loss:  0.3713 \n",
            "Epoch8 | Loss:  0.6259 \n",
            "Epoch8 | Loss:  0.6194 \n",
            "Epoch8 | Loss:  0.5402 \n",
            "Epoch8 | Loss:  0.5171 \n",
            "Epoch8 | Loss:  0.4638 \n",
            "Epoch8 | Loss:  0.8509 \n",
            "Epoch8 | Loss:  0.3288 \n",
            "Epoch8 | Loss:  0.3806 \n",
            "Epoch8 | Loss:  0.3958 \n",
            "Epoch8 | Loss:  0.5348 \n",
            "Epoch8 | Loss:  0.3319 \n",
            "Epoch8 | Loss:  0.9398 \n",
            "Epoch8 | Loss:  0.5805 \n",
            "Epoch8 | Loss:  0.5314 \n",
            "Epoch8 | Loss:  0.4578 \n",
            "Epoch8 | Loss:  0.6140 \n",
            "Epoch8 | Loss:  0.4485 \n",
            "Epoch8 | Loss:  0.6719 \n",
            "Epoch8 | Loss:  0.2686 \n",
            "Epoch8 | Loss:  0.8087 \n",
            "Epoch8 | Loss:  0.5686 \n",
            "Epoch8 | Loss:  0.6511 \n",
            "Epoch8 | Loss:  0.7456 \n",
            "Epoch8 | Loss:  0.4300 \n",
            "Epoch8 | Loss:  0.5602 \n",
            "Epoch8 | Loss:  0.2906 \n",
            "Epoch8 | Loss:  0.4021 \n",
            "Epoch8 | Loss:  0.4039 \n",
            "Epoch8 | Loss:  0.5046 \n",
            "Epoch8 | Loss:  0.6779 \n",
            "Epoch8 | Loss:  0.2084 \n",
            "Epoch8 | Loss:  0.4558 \n",
            "Epoch8 | Loss:  0.7146 \n",
            "Epoch8 | Loss:  0.5260 \n",
            "Epoch8 | Loss:  0.6984 \n",
            "Epoch8 | Loss:  0.6890 \n",
            "Epoch8 | Loss:  0.8425 \n",
            "Epoch8 | Loss:  0.3937 \n",
            "Epoch8 | Loss:  0.9387 \n",
            "Epoch8 | Loss:  0.3938 \n",
            "Epoch8 | Loss:  0.6825 \n",
            "Epoch8 | Loss:  0.4851 \n",
            "Epoch8 | Loss:  0.9405 \n",
            "Epoch8 | Loss:  0.4802 \n",
            "Epoch8 | Loss:  0.6820 \n",
            "Epoch8 | Loss:  0.4162 \n",
            "Epoch8 | Loss:  0.4685 \n",
            "Epoch8 | Loss:  0.5842 \n",
            "Epoch8 | Loss:  0.4327 \n",
            "Epoch8 | Loss:  0.3609 \n",
            "Epoch8 | Loss:  0.5806 \n",
            "Epoch8 | Loss:  0.4988 \n",
            "Epoch8 | Loss:  0.3465 \n",
            "Epoch8 | Loss:  0.6846 \n",
            "Epoch8 | Loss:  0.2336 \n",
            "Epoch8 | Loss:  0.8853 \n",
            "Epoch8 | Loss:  0.5761 \n",
            "Epoch8 | Loss:  0.5456 \n",
            "Epoch8 | Loss:  0.2888 \n",
            "Epoch8 | Loss:  0.4300 \n",
            "Epoch8 | Loss:  0.4836 \n",
            "Epoch8 | Loss:  0.4259 \n",
            "Epoch8 | Loss:  0.4169 \n",
            "Epoch8 | Loss:  0.6020 \n",
            "Epoch8 | Loss:  0.4431 \n",
            "Epoch8 | Loss:  0.5042 \n",
            "Epoch8 | Loss:  0.4418 \n",
            "Epoch8 | Loss:  0.6474 \n",
            "Epoch8 | Loss:  0.8054 \n",
            "Epoch8 | Loss:  0.6023 \n",
            "Epoch8 | Loss:  0.3652 \n",
            "Epoch8 | Loss:  0.4641 \n",
            "Epoch8 | Loss:  0.6120 \n",
            "Epoch8 | Loss:  0.4454 \n",
            "Epoch8 | Loss:  0.6322 \n",
            "Epoch8 | Loss:  0.6578 \n",
            "Epoch8 | Loss:  0.6067 \n",
            "Epoch8 | Loss:  0.3559 \n",
            "Epoch8 | Loss:  0.6636 \n",
            "Epoch8 | Loss:  0.2716 \n",
            "Epoch8 | Loss:  0.7298 \n",
            "Epoch8 | Loss:  0.6925 \n",
            "Epoch8 | Loss:  0.5293 \n",
            "Epoch8 | Loss:  0.4922 \n",
            "Epoch8 | Loss:  0.6520 \n",
            "Epoch8 | Loss:  0.6559 \n",
            "Epoch8 | Loss:  0.6414 \n",
            "Epoch8 | Loss:  0.5424 \n",
            "Epoch8 | Loss:  0.3762 \n",
            "Epoch8 | Loss:  0.3612 \n",
            "Epoch8 | Loss:  0.4990 \n",
            "Epoch8 | Loss:  0.3238 \n",
            "Epoch8 | Loss:  0.5848 \n",
            "Epoch8 | Loss:  0.5846 \n",
            "Epoch8 | Loss:  0.4914 \n",
            "Epoch8 | Loss:  0.5845 \n",
            "Epoch8 | Loss:  0.4377 \n",
            "Epoch8 | Loss:  0.7112 \n",
            "Epoch8 | Loss:  0.6117 \n",
            "Epoch8 | Loss:  0.2047 \n",
            "Epoch8 | Loss:  0.5482 \n",
            "Epoch8 | Loss:  0.6516 \n",
            "Epoch8 | Loss:  0.4067 \n",
            "Epoch8 | Loss:  0.6898 \n",
            "Epoch8 | Loss:  0.4832 \n",
            "Epoch8 | Loss:  0.6830 \n",
            "Epoch8 | Loss:  0.3917 \n",
            "Epoch8 | Loss:  0.5226 \n",
            "Epoch8 | Loss:  0.7316 \n",
            "Epoch8 | Loss:  0.5218 \n",
            "Epoch8 | Loss:  0.6753 \n",
            "Epoch8 | Loss:  0.3863 \n",
            "Epoch8 | Loss:  0.3748 \n",
            "Epoch8 | Loss:  0.3963 \n",
            "Epoch8 | Loss:  0.5352 \n",
            "Epoch8 | Loss:  0.5381 \n",
            "Epoch8 | Loss:  0.2693 \n",
            "Epoch8 | Loss:  0.3392 \n",
            "Epoch8 | Loss:  0.3310 \n",
            "Epoch8 | Loss:  0.4556 \n",
            "Epoch8 | Loss:  0.8828 \n",
            "Epoch8 | Loss:  0.7236 \n",
            "Epoch8 | Loss:  0.2830 \n",
            "Epoch8 | Loss:  0.4883 \n",
            "Epoch8 | Loss:  0.7813 \n",
            "Epoch8 | Loss:  0.5461 \n",
            "Epoch8 | Loss:  0.6837 \n",
            "Epoch8 | Loss:  0.3301 \n",
            "Epoch8 | Loss:  0.7117 \n",
            "Epoch8 | Loss:  0.4751 \n",
            "Epoch8 | Loss:  0.7318 \n",
            "Epoch8 | Loss:  0.6455 \n",
            "Epoch8 | Loss:  0.6073 \n",
            "Epoch8 | Loss:  0.5993 \n",
            "Epoch8 | Loss:  0.3877 \n",
            "Epoch8 | Loss:  0.6462 \n",
            "Epoch8 | Loss:  0.3514 \n",
            "Epoch8 | Loss:  0.5423 \n",
            "Epoch8 | Loss:  0.4002 \n",
            "Epoch8 | Loss:  0.3716 \n",
            "Epoch8 | Loss:  0.5896 \n",
            "Epoch8 | Loss:  0.5845 \n",
            "Epoch8 | Loss:  0.5134 \n",
            "Epoch8 | Loss:  0.5732 \n",
            "Epoch8 | Loss:  0.6027 \n",
            "Epoch8 | Loss:  0.5584 \n",
            "Epoch8 | Loss:  0.5744 \n",
            "Epoch8 | Loss:  0.4245 \n",
            "Epoch8 | Loss:  0.5601 \n",
            "Epoch8 | Loss:  0.5148 \n",
            "Epoch8 | Loss:  0.3855 \n",
            "Epoch8 | Loss:  0.3530 \n",
            "Epoch8 | Loss:  0.5746 \n",
            "Epoch8 | Loss:  0.7094 \n",
            "Epoch8 | Loss:  0.3109 \n",
            "Epoch8 | Loss:  0.2635 \n",
            "Epoch8 | Loss:  0.7512 \n",
            "Epoch8 | Loss:  0.5077 \n",
            "Epoch8 | Loss:  0.5917 \n",
            "Epoch8 | Loss:  0.5102 \n",
            "Epoch8 | Loss:  0.3428 \n",
            "Epoch8 | Loss:  0.6754 \n",
            "Epoch8 | Loss:  0.8279 \n",
            "Epoch8 | Loss:  0.4963 \n",
            "Epoch8 | Loss:  0.5717 \n",
            "Epoch8 | Loss:  0.5032 \n",
            "Epoch8 | Loss:  0.4132 \n",
            "Epoch8 | Loss:  0.6796 \n",
            "Epoch8 | Loss:  0.3326 \n",
            "Epoch8 | Loss:  0.6535 \n",
            "Epoch8 | Loss:  0.5304 \n",
            "Epoch8 | Loss:  0.5450 \n",
            "Epoch8 | Loss:  0.5153 \n",
            "Epoch8 | Loss:  0.5701 \n",
            "Epoch8 | Loss:  0.4996 \n",
            "Epoch8 | Loss:  0.5545 \n",
            "Epoch8 | Loss:  0.3244 \n",
            "Epoch8 | Loss:  0.7177 \n",
            "Epoch8 | Loss:  0.7075 \n",
            "Epoch8 | Loss:  0.6513 \n",
            "Epoch8 | Loss:  0.6349 \n",
            "Epoch8 | Loss:  0.3497 \n",
            "Epoch8 | Loss:  0.7358 \n",
            "Epoch8 | Loss:  0.5281 \n",
            "Epoch8 | Loss:  0.5475 \n",
            "Epoch8 | Loss:  0.6010 \n",
            "Epoch8 | Loss:  0.5529 \n",
            "Epoch8 | Loss:  0.5932 \n",
            "Epoch8 | Loss:  0.6875 \n",
            "Epoch8 | Loss:  0.5646 \n",
            "Epoch8 | Loss:  0.6192 \n",
            "Epoch8 | Loss:  0.5803 \n",
            "Epoch8 | Loss:  0.6068 \n",
            "Epoch8 | Loss:  0.3280 \n",
            "Epoch8 | Loss:  0.3899 \n",
            "Epoch8 | Loss:  0.4081 \n",
            "Epoch8 | Loss:  0.3810 \n",
            "Epoch8 | Loss:  0.3333 \n",
            "Epoch8 | Loss:  0.4200 \n",
            "Epoch8 | Loss:  0.3350 \n",
            "Epoch8 | Loss:  0.5175 \n",
            "Epoch8 | Loss:  0.5787 \n",
            "Epoch8 | Loss:  0.1898 \n",
            "Epoch8 | Loss:  0.6114 \n",
            "Epoch8 | Loss:  0.6231 \n",
            "Epoch8 | Loss:  0.6340 \n",
            "Epoch8 | Loss:  0.5217 \n",
            "Epoch8 | Loss:  0.5103 \n",
            "Epoch8 | Loss:  0.5140 \n",
            "Epoch8 | Loss:  0.4383 \n",
            "Epoch8 | Loss:  1.0009 \n",
            "Epoch8 | Loss:  0.4528 \n",
            "Epoch8 | Loss:  0.5843 \n",
            "Epoch8 | Loss:  0.8338 \n",
            "Epoch8 | Loss:  0.5563 \n",
            "Epoch8 | Loss:  0.3793 \n",
            "Epoch8 | Loss:  0.6157 \n",
            "Epoch8 | Loss:  0.4959 \n",
            "Epoch8 | Loss:  0.3094 \n",
            "Epoch8 | Loss:  0.4856 \n",
            "Epoch8 | Loss:  0.3908 \n",
            "Epoch8 | Loss:  0.5889 \n",
            "Epoch8 | Loss:  0.6112 \n",
            "Epoch8 | Loss:  0.6499 \n",
            "Epoch8 | Loss:  0.7208 \n",
            "Epoch8 | Loss:  0.4857 \n",
            "Epoch8 | Loss:  0.4932 \n",
            "Epoch8 | Loss:  0.9798 \n",
            "Epoch8 | Loss:  0.5583 \n",
            "Epoch8 | Loss:  0.7730 \n",
            "Epoch8 | Loss:  0.9293 \n",
            "Epoch8 | Loss:  0.3913 \n",
            "Epoch8 | Loss:  0.4654 \n",
            "Epoch8 | Loss:  0.6310 \n",
            "Epoch8 | Loss:  0.5808 \n",
            "Epoch8 | Loss:  0.6903 \n",
            "Epoch8 | Loss:  0.5584 \n",
            "Epoch8 | Loss:  0.4314 \n",
            "Epoch8 | Loss:  0.5184 \n",
            "Epoch8 | Loss:  0.6035 \n",
            "Epoch8 | Loss:  0.5043 \n",
            "Epoch8 | Loss:  0.4894 \n",
            "Epoch8 | Loss:  0.6041 \n",
            "Epoch8 | Loss:  0.6407 \n",
            "Epoch8 | Loss:  0.4308 \n",
            "Epoch8 | Loss:  0.4628 \n",
            "Epoch8 | Loss:  0.6587 \n",
            "Epoch8 | Loss:  0.6048 \n",
            "Epoch8 | Loss:  0.3589 \n",
            "Epoch8 | Loss:  0.6655 \n",
            "Epoch8 | Loss:  0.5840 \n",
            "Epoch8 | Loss:  0.4298 \n",
            "Epoch8 | Loss:  0.2538 \n",
            "Epoch8 | Loss:  0.7712 \n",
            "Epoch8 | Loss:  0.5604 \n",
            "Epoch8 | Loss:  0.6437 \n",
            "Epoch8 | Loss:  0.3552 \n",
            "Epoch8 | Loss:  0.4499 \n",
            "Epoch8 | Loss:  0.4661 \n",
            "Epoch8 | Loss:  0.6237 \n",
            "Epoch8 | Loss:  0.3645 \n",
            "Epoch8 | Loss:  0.4080 \n",
            "Epoch8 | Loss:  0.7766 \n",
            "Epoch8 | Loss:  0.3564 \n",
            "Epoch8 | Loss:  0.6696 \n",
            "Epoch8 | Loss:  0.7069 \n",
            "Epoch8 | Loss:  0.3772 \n",
            "Epoch8 | Loss:  0.7267 \n",
            "Epoch8 | Loss:  0.6021 \n",
            "Epoch8 | Loss:  0.6114 \n",
            "Epoch8 | Loss:  0.4061 \n",
            "Epoch8 | Loss:  0.3833 \n",
            "Epoch8 | Loss:  0.6382 \n",
            "Epoch8 | Loss:  0.8745 \n",
            "Epoch8 | Loss:  0.5917 \n",
            "Epoch8 | Loss:  1.1517 \n",
            "Epoch8 | Loss:  0.8701 \n",
            "Epoch8 | Loss:  0.7744 \n",
            "Epoch8 | Loss:  0.4193 \n",
            "Epoch8 | Loss:  0.6358 \n",
            "Epoch8 | Loss:  0.5577 \n",
            "Epoch8 | Loss:  0.5050 \n",
            "Epoch8 | Loss:  0.6444 \n",
            "Epoch8 | Loss:  0.7370 \n",
            "Epoch8 | Loss:  0.7258 \n",
            "Epoch8 | Loss:  0.5683 \n",
            "Epoch8 | Loss:  0.8832 \n",
            "Epoch8 | Loss:  0.7157 \n",
            "Epoch8 | Loss:  0.5765 \n",
            "Epoch8 | Loss:  0.4962 \n",
            "Epoch8 | Loss:  0.3278 \n",
            "Epoch8 | Loss:  0.4409 \n",
            "Epoch8 | Loss:  0.4945 \n",
            "Epoch8 | Loss:  0.5495 \n",
            "Epoch8 | Loss:  0.7405 \n",
            "Epoch8 | Loss:  0.3257 \n",
            "Epoch8 | Loss:  0.6762 \n",
            "Epoch8 | Loss:  0.7672 \n",
            "Epoch8 | Loss:  0.5603 \n",
            "Epoch8 | Loss:  0.5719 \n",
            "Epoch8 | Loss:  0.6072 \n",
            "Epoch8 | Loss:  0.4376 \n",
            "Epoch8 | Loss:  0.7329 \n",
            "Epoch8 | Loss:  0.5665 \n",
            "Epoch8 | Loss:  0.5055 \n",
            "Epoch8 | Loss:  0.2611 \n",
            "Epoch8 | Loss:  0.5886 \n",
            "Epoch8 | Loss:  0.4437 \n",
            "Epoch8 | Loss:  0.3266 \n",
            "Epoch8 | Loss:  0.5136 \n",
            "Epoch8 | Loss:  0.5510 \n",
            "Epoch8 | Loss:  0.2900 \n",
            "Epoch8 | Loss:  0.5985 \n",
            "Epoch8 | Loss:  0.5896 \n",
            "Epoch8 | Loss:  0.3326 \n",
            "Epoch8 | Loss:  0.6715 \n",
            "Epoch8 | Loss:  1.0168 \n",
            "Epoch8 | Loss:  0.5068 \n",
            "Epoch8 | Loss:  0.5427 \n",
            "Epoch8 | Loss:  0.4466 \n",
            "Epoch8 | Loss:  0.6786 \n",
            "Epoch8 | Loss:  0.4402 \n",
            "Epoch8 | Loss:  0.3620 \n",
            "Epoch8 | Loss:  0.6044 \n",
            "Epoch8 | Loss:  0.6001 \n",
            "Epoch8 | Loss:  0.6146 \n",
            "Epoch8 | Loss:  0.7122 \n",
            "Epoch8 | Loss:  0.4555 \n",
            "Epoch8 | Loss:  0.3812 \n",
            "Epoch8 | Loss:  0.4485 \n",
            "Epoch8 | Loss:  0.5830 \n",
            "Epoch8 | Loss:  0.4011 \n",
            "Epoch8 | Loss:  0.7580 \n",
            "Epoch8 | Loss:  0.6557 \n",
            "Epoch8 | Loss:  0.5774 \n",
            "Epoch8 | Loss:  0.4547 \n",
            "Epoch8 | Loss:  0.4613 \n",
            "Epoch8 | Loss:  0.3968 \n",
            "Epoch8 | Loss:  0.5140 \n",
            "Epoch8 | Loss:  0.4723 \n",
            "Epoch8 | Loss:  0.8291 \n",
            "Epoch8 | Loss:  0.6443 \n",
            "Epoch8 | Loss:  0.4465 \n",
            "Epoch8 | Loss:  0.8327 \n",
            "Epoch8 | Loss:  0.3150 \n",
            "Epoch8 | Loss:  0.7561 \n",
            "Epoch8 | Loss:  0.5103 \n",
            "Epoch8 | Loss:  0.4892 \n",
            "Epoch8 | Loss:  0.3592 \n",
            "Epoch8 | Loss:  0.3978 \n",
            "Epoch8 | Loss:  0.5632 \n",
            "Epoch8 | Loss:  0.4396 \n",
            "Epoch8 | Loss:  0.6494 \n",
            "Epoch8 | Loss:  0.4330 \n",
            "Epoch8 | Loss:  0.5727 \n",
            "Epoch8 | Loss:  0.6813 \n",
            "Epoch8 | Loss:  0.6624 \n",
            "Epoch8 | Loss:  0.3744 \n",
            "Epoch8 | Loss:  0.7441 \n",
            "Epoch8 | Loss:  0.4373 \n",
            "Epoch8 | Loss:  0.6734 \n",
            "Epoch8 | Loss:  0.7207 \n",
            "Epoch8 | Loss:  0.7541 \n",
            "Epoch8 | Loss:  0.3239 \n",
            "Epoch8 | Loss:  0.4684 \n",
            "Epoch8 | Loss:  0.3871 \n",
            "Epoch8 | Loss:  0.4412 \n",
            "Epoch8 | Loss:  0.5466 \n",
            "Epoch8 | Loss:  0.5420 \n",
            "Epoch8 | Loss:  0.6331 \n",
            "Epoch8 | Loss:  0.5435 \n",
            "Epoch8 | Loss:  0.7081 \n",
            "Epoch8 | Loss:  0.5639 \n",
            "Epoch8 | Loss:  0.6420 \n",
            "Epoch8 | Loss:  0.4862 \n",
            "Epoch8 | Loss:  0.6689 \n",
            "Epoch8 | Loss:  0.7614 \n",
            "Epoch8 | Loss:  0.4775 \n",
            "Epoch8 | Loss:  0.6621 \n",
            "Epoch8 | Loss:  0.5168 \n",
            "Epoch8 | Loss:  0.8983 \n",
            "Epoch8 | Loss:  0.6265 \n",
            "Epoch8 | Loss:  0.3263 \n",
            "Epoch8 | Loss:  0.6691 \n",
            "Epoch8 | Loss:  0.6040 \n",
            "Epoch8 | Loss:  0.6775 \n",
            "Epoch8 | Loss:  0.4391 \n",
            "Epoch8 | Loss:  0.6221 \n",
            "Epoch8 | Loss:  0.3936 \n",
            "Epoch8 | Loss:  0.6941 \n",
            "Epoch8 | Loss:  0.6650 \n",
            "Epoch8 | Loss:  0.4698 \n",
            "Epoch8 | Loss:  0.5830 \n",
            "Epoch8 | Loss:  0.4652 \n",
            "Epoch8 | Loss:  0.4365 \n",
            "Epoch8 | Loss:  0.7353 \n",
            "Epoch8 | Loss:  0.4252 \n",
            "Epoch8 | Loss:  0.4239 \n",
            "Epoch8 | Loss:  0.5565 \n",
            "Epoch8 | Loss:  0.7049 \n",
            "Epoch8 | Loss:  0.4208 \n",
            "Epoch8 | Loss:  0.8623 \n",
            "Epoch8 | Loss:  0.6946 \n",
            "Epoch8 | Loss:  0.4731 \n",
            "Epoch8 | Loss:  0.5507 \n",
            "Epoch8 | Loss:  0.4145 \n",
            "Epoch8 | Loss:  0.7090 \n",
            "Epoch8 | Loss:  0.7011 \n",
            "Epoch8 | Loss:  0.4486 \n",
            "Epoch8 | Loss:  0.5519 \n",
            "Epoch8 | Loss:  0.7234 \n",
            "Epoch8 | Loss:  0.4950 \n",
            "Epoch8 | Loss:  0.4336 \n",
            "Epoch8 | Loss:  0.7233 \n",
            "Epoch8 | Loss:  0.4691 \n",
            "Epoch8 | Loss:  0.5074 \n",
            "Epoch8 | Loss:  0.5579 \n",
            "Epoch8 | Loss:  0.4562 \n",
            "Epoch8 | Loss:  0.5076 \n",
            "Epoch8 | Loss:  0.6074 \n",
            "Epoch8 | Loss:  0.3730 \n",
            "Epoch8 | Loss:  0.4498 \n",
            "Epoch8 | Loss:  0.4940 \n",
            "Epoch8 | Loss:  0.5931 \n",
            "Epoch8 | Loss:  0.6451 \n",
            "Epoch8 | Loss:  0.3875 \n",
            "Epoch8 | Loss:  0.8641 \n",
            "Epoch8 | Loss:  0.5768 \n",
            "Epoch8 | Loss:  0.5411 \n",
            "Epoch8 | Loss:  0.6186 \n",
            "Epoch8 | Loss:  0.3904 \n",
            "Epoch8 | Loss:  0.3891 \n",
            "Epoch8 | Loss:  0.2430 \n",
            "Epoch8 | Loss:  0.6256 \n",
            "Epoch8 | Loss:  0.4957 \n",
            "Epoch8 | Loss:  0.7391 \n",
            "Epoch8 | Loss:  0.2901 \n",
            "Epoch8 | Loss:  0.4943 \n",
            "Epoch8 | Loss:  0.6398 \n",
            "Epoch8 | Loss:  0.4851 \n",
            "Epoch8 | Loss:  0.3759 \n",
            "Epoch8 | Loss:  0.5870 \n",
            "Epoch8 | Loss:  0.4982 \n",
            "Epoch8 | Loss:  0.4033 \n",
            "Epoch8 | Loss:  0.5270 \n",
            "Epoch8 | Loss:  0.5681 \n",
            "Epoch8 | Loss:  0.6146 \n",
            "Epoch8 | Loss:  0.4964 \n",
            "Epoch8 | Loss:  0.4516 \n",
            "Epoch8 | Loss:  0.6855 \n",
            "Epoch8 | Loss:  0.6378 \n",
            "Epoch8 | Loss:  0.5791 \n",
            "Epoch8 | Loss:  0.6194 \n",
            "Epoch8 | Loss:  0.4787 \n",
            "Epoch8 | Loss:  0.4739 \n",
            "Epoch8 | Loss:  0.7976 \n",
            "Epoch8 | Loss:  0.5992 \n",
            "Epoch8 | Loss:  0.3519 \n",
            "Epoch8 | Loss:  0.6597 \n",
            "Epoch8 | Loss:  0.7817 \n",
            "Epoch8 | Loss:  0.5661 \n",
            "Epoch8 | Loss:  0.9110 \n",
            "Epoch8 | Loss:  0.5048 \n",
            "Epoch8 | Loss:  0.4914 \n",
            "Epoch8 | Loss:  0.3109 \n",
            "Epoch8 | Loss:  0.4359 \n",
            "Epoch8 | Loss:  0.4060 \n",
            "Epoch8 | Loss:  0.4520 \n",
            "Epoch8 | Loss:  0.4382 \n",
            "Epoch8 | Loss:  0.4560 \n",
            "Epoch8 | Loss:  0.2145 \n",
            "Epoch8 | Loss:  0.4162 \n",
            "Epoch8 | Loss:  0.3864 \n",
            "Epoch8 | Loss:  0.4046 \n",
            "Epoch8 | Loss:  0.7351 \n",
            "Epoch8 | Loss:  0.3579 \n",
            "Epoch8 | Loss:  0.3511 \n",
            "Epoch8 | Loss:  0.4659 \n",
            "Epoch8 | Loss:  0.8141 \n",
            "Epoch8 | Loss:  0.6082 \n",
            "Epoch8 | Loss:  0.2981 \n",
            "Epoch8 | Loss:  0.6511 \n",
            "Epoch8 | Loss:  0.4813 \n",
            "Epoch8 | Loss:  0.6110 \n",
            "Epoch8 | Loss:  0.9243 \n",
            "Epoch8 | Loss:  0.5322 \n",
            "Epoch8 | Loss:  0.4983 \n",
            "Epoch8 | Loss:  0.6605 \n",
            "Epoch8 | Loss:  0.1639 \n",
            "Epoch8 | Loss:  0.3784 \n",
            "Epoch8 | Loss:  0.5616 \n",
            "Epoch8 | Loss:  0.6747 \n",
            "Epoch8 | Loss:  0.5834 \n",
            "Epoch8 | Loss:  0.2138 \n",
            "Epoch8 | Loss:  0.7339 \n",
            "Epoch8 | Loss:  0.5503 \n",
            "Epoch8 | Loss:  0.3780 \n",
            "Epoch8 | Loss:  0.6009 \n",
            "Epoch8 | Loss:  0.3831 \n",
            "Epoch8 | Loss:  0.6317 \n",
            "Epoch8 | Loss:  0.3062 \n",
            "Epoch8 | Loss:  0.5368 \n",
            "Epoch8 | Loss:  0.3605 \n",
            "Epoch8 | Loss:  0.4684 \n",
            "Epoch8 | Loss:  0.7470 \n",
            "Epoch8 | Loss:  0.4086 \n",
            "Epoch8 | Loss:  0.5149 \n",
            "Epoch8 | Loss:  0.5587 \n",
            "Epoch8 | Loss:  0.6993 \n",
            "Epoch8 | Loss:  0.3848 \n",
            "Epoch8 | Loss:  0.4087 \n",
            "Epoch8 | Loss:  0.6263 \n",
            "Epoch8 | Loss:  0.3696 \n",
            "Epoch8 | Loss:  0.6950 \n",
            "Epoch8 | Loss:  0.7040 \n",
            "Epoch8 | Loss:  0.6655 \n",
            "Epoch8 | Loss:  1.1523 \n",
            "Epoch8 | Loss:  0.4343 \n",
            "Epoch8 | Loss:  0.3421 \n",
            "Epoch8 | Loss:  0.6377 \n",
            "Epoch8 | Loss:  0.6797 \n",
            "Epoch8 | Loss:  0.3427 \n",
            "Epoch8 | Loss:  0.7086 \n",
            "Epoch8 | Loss:  0.2140 \n",
            "Epoch8 | Loss:  0.5159 \n",
            "Epoch8 | Loss:  0.4445 \n",
            "Epoch8 | Loss:  0.5926 \n",
            "Epoch8 | Loss:  0.5442 \n",
            "Epoch8 | Loss:  0.2075 \n",
            "Epoch8 | Loss:  0.4515 \n",
            "Epoch8 | Loss:  0.3460 \n",
            "Epoch8 | Loss:  0.3242 \n",
            "Epoch8 | Loss:  0.5585 \n",
            "Epoch8 | Loss:  0.3882 \n",
            "Epoch8 | Loss:  0.4172 \n",
            "Epoch8 | Loss:  0.6082 \n",
            "Epoch8 | Loss:  0.5835 \n",
            "Epoch8 | Loss:  0.5934 \n",
            "Epoch8 | Loss:  0.9427 \n",
            "Epoch8 | Loss:  0.4342 \n",
            "Epoch8 | Loss:  0.4952 \n",
            "Epoch8 | Loss:  0.3375 \n",
            "Epoch8 | Loss:  0.4607 \n",
            "Epoch8 | Loss:  0.3933 \n",
            "Epoch8 | Loss:  0.6639 \n",
            "Epoch8 | Loss:  0.5765 \n",
            "Epoch8 | Loss:  0.5100 \n",
            "Epoch8 | Loss:  0.3396 \n",
            "Epoch8 | Loss:  0.6525 \n",
            "Epoch8 | Loss:  0.4265 \n",
            "Epoch8 | Loss:  0.6350 \n",
            "Epoch8 | Loss:  0.5079 \n",
            "Epoch8 | Loss:  0.7012 \n",
            "Epoch8 | Loss:  0.6741 \n",
            "Epoch8 | Loss:  0.7478 \n",
            "Epoch8 | Loss:  0.5046 \n",
            "Epoch8 | Loss:  0.4040 \n",
            "Epoch8 | Loss:  0.4934 \n",
            "Epoch8 | Loss:  0.4393 \n",
            "Epoch8 | Loss:  0.3462 \n",
            "Epoch8 | Loss:  0.4869 \n",
            "Epoch8 | Loss:  0.5317 \n",
            "Epoch8 | Loss:  0.2820 \n",
            "Epoch8 | Loss:  0.5323 \n",
            "Epoch8 | Loss:  0.4388 \n",
            "Epoch8 | Loss:  0.3582 \n",
            "Epoch8 | Loss:  0.4617 \n",
            "Epoch8 | Loss:  0.9410 \n",
            "Epoch8 | Loss:  0.4734 \n",
            "Epoch8 | Loss:  0.5778 \n",
            "Epoch8 | Loss:  0.4530 \n",
            "Epoch8 | Loss:  0.5364 \n",
            "Epoch8 | Loss:  0.3947 \n",
            "Epoch8 | Loss:  0.6195 \n",
            "Epoch8 | Loss:  0.4908 \n",
            "Epoch8 | Loss:  0.6117 \n",
            "Epoch8 | Loss:  0.2100 \n",
            "Epoch8 | Loss:  0.3701 \n",
            "Epoch8 | Loss:  0.5311 \n",
            "Epoch8 | Loss:  0.8470 \n",
            "Epoch8 | Loss:  0.3514 \n",
            "Epoch8 | Loss:  0.3058 \n",
            "Epoch8 | Loss:  0.3700 \n",
            "Epoch8 | Loss:  0.5661 \n",
            "Epoch8 | Loss:  0.4355 \n",
            "Epoch8 | Loss:  0.4228 \n",
            "Epoch8 | Loss:  0.2960 \n",
            "Epoch9 | Loss:  0.5133 \n",
            "Epoch9 | Loss:  0.7176 \n",
            "Epoch9 | Loss:  0.4382 \n",
            "Epoch9 | Loss:  0.4359 \n",
            "Epoch9 | Loss:  0.4810 \n",
            "Epoch9 | Loss:  0.6041 \n",
            "Epoch9 | Loss:  0.4286 \n",
            "Epoch9 | Loss:  0.6060 \n",
            "Epoch9 | Loss:  0.5793 \n",
            "Epoch9 | Loss:  0.5709 \n",
            "Epoch9 | Loss:  0.3380 \n",
            "Epoch9 | Loss:  0.5543 \n",
            "Epoch9 | Loss:  0.5942 \n",
            "Epoch9 | Loss:  0.5731 \n",
            "Epoch9 | Loss:  0.4699 \n",
            "Epoch9 | Loss:  0.6224 \n",
            "Epoch9 | Loss:  0.3195 \n",
            "Epoch9 | Loss:  0.4379 \n",
            "Epoch9 | Loss:  0.5144 \n",
            "Epoch9 | Loss:  0.4465 \n",
            "Epoch9 | Loss:  0.4395 \n",
            "Epoch9 | Loss:  0.4066 \n",
            "Epoch9 | Loss:  0.5353 \n",
            "Epoch9 | Loss:  0.4778 \n",
            "Epoch9 | Loss:  0.7420 \n",
            "Epoch9 | Loss:  0.4635 \n",
            "Epoch9 | Loss:  0.7034 \n",
            "Epoch9 | Loss:  0.6780 \n",
            "Epoch9 | Loss:  0.4368 \n",
            "Epoch9 | Loss:  0.3800 \n",
            "Epoch9 | Loss:  0.3355 \n",
            "Epoch9 | Loss:  0.5134 \n",
            "Epoch9 | Loss:  0.6163 \n",
            "Epoch9 | Loss:  0.2189 \n",
            "Epoch9 | Loss:  0.3906 \n",
            "Epoch9 | Loss:  0.6126 \n",
            "Epoch9 | Loss:  0.3704 \n",
            "Epoch9 | Loss:  0.5958 \n",
            "Epoch9 | Loss:  0.4057 \n",
            "Epoch9 | Loss:  0.5313 \n",
            "Epoch9 | Loss:  0.3949 \n",
            "Epoch9 | Loss:  0.7766 \n",
            "Epoch9 | Loss:  0.6059 \n",
            "Epoch9 | Loss:  0.6421 \n",
            "Epoch9 | Loss:  0.4513 \n",
            "Epoch9 | Loss:  0.3352 \n",
            "Epoch9 | Loss:  0.5739 \n",
            "Epoch9 | Loss:  0.3163 \n",
            "Epoch9 | Loss:  0.5996 \n",
            "Epoch9 | Loss:  0.5521 \n",
            "Epoch9 | Loss:  0.3732 \n",
            "Epoch9 | Loss:  0.8905 \n",
            "Epoch9 | Loss:  0.3285 \n",
            "Epoch9 | Loss:  0.6879 \n",
            "Epoch9 | Loss:  0.4192 \n",
            "Epoch9 | Loss:  0.6518 \n",
            "Epoch9 | Loss:  0.5385 \n",
            "Epoch9 | Loss:  0.7610 \n",
            "Epoch9 | Loss:  0.5015 \n",
            "Epoch9 | Loss:  0.3583 \n",
            "Epoch9 | Loss:  0.4914 \n",
            "Epoch9 | Loss:  0.5354 \n",
            "Epoch9 | Loss:  0.3907 \n",
            "Epoch9 | Loss:  0.6927 \n",
            "Epoch9 | Loss:  0.5095 \n",
            "Epoch9 | Loss:  0.3628 \n",
            "Epoch9 | Loss:  0.4794 \n",
            "Epoch9 | Loss:  0.3779 \n",
            "Epoch9 | Loss:  0.4038 \n",
            "Epoch9 | Loss:  0.5557 \n",
            "Epoch9 | Loss:  0.6195 \n",
            "Epoch9 | Loss:  0.4004 \n",
            "Epoch9 | Loss:  0.3214 \n",
            "Epoch9 | Loss:  0.4826 \n",
            "Epoch9 | Loss:  0.6311 \n",
            "Epoch9 | Loss:  0.6225 \n",
            "Epoch9 | Loss:  0.5078 \n",
            "Epoch9 | Loss:  0.1973 \n",
            "Epoch9 | Loss:  0.3661 \n",
            "Epoch9 | Loss:  0.2722 \n",
            "Epoch9 | Loss:  0.5266 \n",
            "Epoch9 | Loss:  0.2320 \n",
            "Epoch9 | Loss:  0.5138 \n",
            "Epoch9 | Loss:  0.3812 \n",
            "Epoch9 | Loss:  0.7304 \n",
            "Epoch9 | Loss:  0.6145 \n",
            "Epoch9 | Loss:  0.6858 \n",
            "Epoch9 | Loss:  0.6654 \n",
            "Epoch9 | Loss:  0.3079 \n",
            "Epoch9 | Loss:  0.5757 \n",
            "Epoch9 | Loss:  0.6632 \n",
            "Epoch9 | Loss:  0.7653 \n",
            "Epoch9 | Loss:  0.6776 \n",
            "Epoch9 | Loss:  0.3828 \n",
            "Epoch9 | Loss:  0.9796 \n",
            "Epoch9 | Loss:  0.7689 \n",
            "Epoch9 | Loss:  0.4411 \n",
            "Epoch9 | Loss:  0.6267 \n",
            "Epoch9 | Loss:  0.7014 \n",
            "Epoch9 | Loss:  0.5478 \n",
            "Epoch9 | Loss:  0.4426 \n",
            "Epoch9 | Loss:  0.6362 \n",
            "Epoch9 | Loss:  1.0774 \n",
            "Epoch9 | Loss:  0.4058 \n",
            "Epoch9 | Loss:  0.4543 \n",
            "Epoch9 | Loss:  0.6189 \n",
            "Epoch9 | Loss:  0.6475 \n",
            "Epoch9 | Loss:  1.0362 \n",
            "Epoch9 | Loss:  0.3646 \n",
            "Epoch9 | Loss:  0.6979 \n",
            "Epoch9 | Loss:  0.4954 \n",
            "Epoch9 | Loss:  0.5824 \n",
            "Epoch9 | Loss:  0.5690 \n",
            "Epoch9 | Loss:  0.5039 \n",
            "Epoch9 | Loss:  0.4882 \n",
            "Epoch9 | Loss:  0.5719 \n",
            "Epoch9 | Loss:  0.4830 \n",
            "Epoch9 | Loss:  0.5916 \n",
            "Epoch9 | Loss:  0.2812 \n",
            "Epoch9 | Loss:  0.4752 \n",
            "Epoch9 | Loss:  0.3100 \n",
            "Epoch9 | Loss:  0.7849 \n",
            "Epoch9 | Loss:  0.4664 \n",
            "Epoch9 | Loss:  0.7061 \n",
            "Epoch9 | Loss:  0.4793 \n",
            "Epoch9 | Loss:  0.5306 \n",
            "Epoch9 | Loss:  0.5718 \n",
            "Epoch9 | Loss:  0.4797 \n",
            "Epoch9 | Loss:  0.5028 \n",
            "Epoch9 | Loss:  0.4508 \n",
            "Epoch9 | Loss:  0.6685 \n",
            "Epoch9 | Loss:  0.7240 \n",
            "Epoch9 | Loss:  0.3685 \n",
            "Epoch9 | Loss:  0.5910 \n",
            "Epoch9 | Loss:  0.4349 \n",
            "Epoch9 | Loss:  0.2835 \n",
            "Epoch9 | Loss:  0.3919 \n",
            "Epoch9 | Loss:  0.4033 \n",
            "Epoch9 | Loss:  0.3829 \n",
            "Epoch9 | Loss:  0.7621 \n",
            "Epoch9 | Loss:  0.5047 \n",
            "Epoch9 | Loss:  0.4418 \n",
            "Epoch9 | Loss:  0.4718 \n",
            "Epoch9 | Loss:  0.3031 \n",
            "Epoch9 | Loss:  0.4874 \n",
            "Epoch9 | Loss:  0.3442 \n",
            "Epoch9 | Loss:  0.7684 \n",
            "Epoch9 | Loss:  0.4285 \n",
            "Epoch9 | Loss:  0.6844 \n",
            "Epoch9 | Loss:  0.7096 \n",
            "Epoch9 | Loss:  0.3221 \n",
            "Epoch9 | Loss:  0.5068 \n",
            "Epoch9 | Loss:  0.6193 \n",
            "Epoch9 | Loss:  0.5163 \n",
            "Epoch9 | Loss:  0.4417 \n",
            "Epoch9 | Loss:  0.3766 \n",
            "Epoch9 | Loss:  0.6997 \n",
            "Epoch9 | Loss:  0.5608 \n",
            "Epoch9 | Loss:  0.5176 \n",
            "Epoch9 | Loss:  0.3316 \n",
            "Epoch9 | Loss:  0.3548 \n",
            "Epoch9 | Loss:  0.6282 \n",
            "Epoch9 | Loss:  0.4714 \n",
            "Epoch9 | Loss:  0.4411 \n",
            "Epoch9 | Loss:  0.6997 \n",
            "Epoch9 | Loss:  0.2578 \n",
            "Epoch9 | Loss:  0.5059 \n",
            "Epoch9 | Loss:  0.5086 \n",
            "Epoch9 | Loss:  0.4888 \n",
            "Epoch9 | Loss:  0.5916 \n",
            "Epoch9 | Loss:  0.7225 \n",
            "Epoch9 | Loss:  0.3198 \n",
            "Epoch9 | Loss:  0.4885 \n",
            "Epoch9 | Loss:  0.2861 \n",
            "Epoch9 | Loss:  0.4527 \n",
            "Epoch9 | Loss:  0.4956 \n",
            "Epoch9 | Loss:  0.5250 \n",
            "Epoch9 | Loss:  0.5775 \n",
            "Epoch9 | Loss:  0.4815 \n",
            "Epoch9 | Loss:  0.4757 \n",
            "Epoch9 | Loss:  0.5751 \n",
            "Epoch9 | Loss:  0.6240 \n",
            "Epoch9 | Loss:  0.4250 \n",
            "Epoch9 | Loss:  0.7828 \n",
            "Epoch9 | Loss:  0.4145 \n",
            "Epoch9 | Loss:  0.8063 \n",
            "Epoch9 | Loss:  0.5405 \n",
            "Epoch9 | Loss:  0.3032 \n",
            "Epoch9 | Loss:  0.3720 \n",
            "Epoch9 | Loss:  0.3449 \n",
            "Epoch9 | Loss:  0.8459 \n",
            "Epoch9 | Loss:  0.4771 \n",
            "Epoch9 | Loss:  0.4993 \n",
            "Epoch9 | Loss:  0.6167 \n",
            "Epoch9 | Loss:  0.4069 \n",
            "Epoch9 | Loss:  0.4468 \n",
            "Epoch9 | Loss:  0.7365 \n",
            "Epoch9 | Loss:  0.8161 \n",
            "Epoch9 | Loss:  0.6248 \n",
            "Epoch9 | Loss:  0.4669 \n",
            "Epoch9 | Loss:  0.5754 \n",
            "Epoch9 | Loss:  0.4804 \n",
            "Epoch9 | Loss:  0.6794 \n",
            "Epoch9 | Loss:  0.8111 \n",
            "Epoch9 | Loss:  0.6305 \n",
            "Epoch9 | Loss:  0.2500 \n",
            "Epoch9 | Loss:  0.4063 \n",
            "Epoch9 | Loss:  0.8071 \n",
            "Epoch9 | Loss:  0.6007 \n",
            "Epoch9 | Loss:  0.4853 \n",
            "Epoch9 | Loss:  0.4699 \n",
            "Epoch9 | Loss:  0.3412 \n",
            "Epoch9 | Loss:  0.9381 \n",
            "Epoch9 | Loss:  0.3007 \n",
            "Epoch9 | Loss:  0.4390 \n",
            "Epoch9 | Loss:  0.5976 \n",
            "Epoch9 | Loss:  0.3570 \n",
            "Epoch9 | Loss:  0.5533 \n",
            "Epoch9 | Loss:  0.2655 \n",
            "Epoch9 | Loss:  0.5710 \n",
            "Epoch9 | Loss:  0.4153 \n",
            "Epoch9 | Loss:  0.4586 \n",
            "Epoch9 | Loss:  0.4985 \n",
            "Epoch9 | Loss:  0.3855 \n",
            "Epoch9 | Loss:  0.3732 \n",
            "Epoch9 | Loss:  0.5533 \n",
            "Epoch9 | Loss:  0.5612 \n",
            "Epoch9 | Loss:  0.3085 \n",
            "Epoch9 | Loss:  0.6466 \n",
            "Epoch9 | Loss:  0.4078 \n",
            "Epoch9 | Loss:  0.3191 \n",
            "Epoch9 | Loss:  0.4331 \n",
            "Epoch9 | Loss:  0.3680 \n",
            "Epoch9 | Loss:  0.5464 \n",
            "Epoch9 | Loss:  0.4622 \n",
            "Epoch9 | Loss:  0.4239 \n",
            "Epoch9 | Loss:  0.7101 \n",
            "Epoch9 | Loss:  0.5102 \n",
            "Epoch9 | Loss:  0.6206 \n",
            "Epoch9 | Loss:  0.4389 \n",
            "Epoch9 | Loss:  0.5758 \n",
            "Epoch9 | Loss:  0.3927 \n",
            "Epoch9 | Loss:  0.5901 \n",
            "Epoch9 | Loss:  0.6351 \n",
            "Epoch9 | Loss:  0.9056 \n",
            "Epoch9 | Loss:  0.3805 \n",
            "Epoch9 | Loss:  0.4486 \n",
            "Epoch9 | Loss:  0.4414 \n",
            "Epoch9 | Loss:  0.4054 \n",
            "Epoch9 | Loss:  0.3147 \n",
            "Epoch9 | Loss:  0.4512 \n",
            "Epoch9 | Loss:  0.5962 \n",
            "Epoch9 | Loss:  0.2818 \n",
            "Epoch9 | Loss:  0.5507 \n",
            "Epoch9 | Loss:  0.3910 \n",
            "Epoch9 | Loss:  0.3696 \n",
            "Epoch9 | Loss:  0.4418 \n",
            "Epoch9 | Loss:  0.4463 \n",
            "Epoch9 | Loss:  0.5991 \n",
            "Epoch9 | Loss:  0.5612 \n",
            "Epoch9 | Loss:  0.5224 \n",
            "Epoch9 | Loss:  0.4157 \n",
            "Epoch9 | Loss:  0.4490 \n",
            "Epoch9 | Loss:  0.5757 \n",
            "Epoch9 | Loss:  0.6831 \n",
            "Epoch9 | Loss:  0.2266 \n",
            "Epoch9 | Loss:  0.4398 \n",
            "Epoch9 | Loss:  0.5303 \n",
            "Epoch9 | Loss:  0.5423 \n",
            "Epoch9 | Loss:  0.3493 \n",
            "Epoch9 | Loss:  0.4016 \n",
            "Epoch9 | Loss:  0.7718 \n",
            "Epoch9 | Loss:  0.5067 \n",
            "Epoch9 | Loss:  0.3995 \n",
            "Epoch9 | Loss:  0.5570 \n",
            "Epoch9 | Loss:  0.7491 \n",
            "Epoch9 | Loss:  0.5286 \n",
            "Epoch9 | Loss:  0.4587 \n",
            "Epoch9 | Loss:  0.4328 \n",
            "Epoch9 | Loss:  0.7950 \n",
            "Epoch9 | Loss:  0.3421 \n",
            "Epoch9 | Loss:  0.6030 \n",
            "Epoch9 | Loss:  0.2907 \n",
            "Epoch9 | Loss:  0.5237 \n",
            "Epoch9 | Loss:  0.4175 \n",
            "Epoch9 | Loss:  0.6637 \n",
            "Epoch9 | Loss:  0.7032 \n",
            "Epoch9 | Loss:  0.4050 \n",
            "Epoch9 | Loss:  0.4371 \n",
            "Epoch9 | Loss:  0.5985 \n",
            "Epoch9 | Loss:  0.7527 \n",
            "Epoch9 | Loss:  0.3429 \n",
            "Epoch9 | Loss:  0.4655 \n",
            "Epoch9 | Loss:  0.4508 \n",
            "Epoch9 | Loss:  0.2976 \n",
            "Epoch9 | Loss:  0.7109 \n",
            "Epoch9 | Loss:  0.4671 \n",
            "Epoch9 | Loss:  0.5698 \n",
            "Epoch9 | Loss:  0.3520 \n",
            "Epoch9 | Loss:  0.4602 \n",
            "Epoch9 | Loss:  0.5962 \n",
            "Epoch9 | Loss:  0.4275 \n",
            "Epoch9 | Loss:  0.3839 \n",
            "Epoch9 | Loss:  0.2546 \n",
            "Epoch9 | Loss:  0.4879 \n",
            "Epoch9 | Loss:  0.4823 \n",
            "Epoch9 | Loss:  0.5066 \n",
            "Epoch9 | Loss:  0.5042 \n",
            "Epoch9 | Loss:  0.8642 \n",
            "Epoch9 | Loss:  0.4614 \n",
            "Epoch9 | Loss:  0.5338 \n",
            "Epoch9 | Loss:  0.6265 \n",
            "Epoch9 | Loss:  0.7008 \n",
            "Epoch9 | Loss:  0.6020 \n",
            "Epoch9 | Loss:  0.4128 \n",
            "Epoch9 | Loss:  0.6255 \n",
            "Epoch9 | Loss:  0.7029 \n",
            "Epoch9 | Loss:  0.4190 \n",
            "Epoch9 | Loss:  0.4627 \n",
            "Epoch9 | Loss:  0.5411 \n",
            "Epoch9 | Loss:  0.4656 \n",
            "Epoch9 | Loss:  0.6091 \n",
            "Epoch9 | Loss:  0.6210 \n",
            "Epoch9 | Loss:  0.3813 \n",
            "Epoch9 | Loss:  0.3496 \n",
            "Epoch9 | Loss:  0.3400 \n",
            "Epoch9 | Loss:  0.3267 \n",
            "Epoch9 | Loss:  0.3180 \n",
            "Epoch9 | Loss:  0.3762 \n",
            "Epoch9 | Loss:  0.4476 \n",
            "Epoch9 | Loss:  0.6457 \n",
            "Epoch9 | Loss:  0.5056 \n",
            "Epoch9 | Loss:  0.5269 \n",
            "Epoch9 | Loss:  0.3358 \n",
            "Epoch9 | Loss:  0.6049 \n",
            "Epoch9 | Loss:  0.7192 \n",
            "Epoch9 | Loss:  0.5311 \n",
            "Epoch9 | Loss:  0.6810 \n",
            "Epoch9 | Loss:  0.9625 \n",
            "Epoch9 | Loss:  0.6437 \n",
            "Epoch9 | Loss:  0.3233 \n",
            "Epoch9 | Loss:  0.5852 \n",
            "Epoch9 | Loss:  0.4678 \n",
            "Epoch9 | Loss:  0.3892 \n",
            "Epoch9 | Loss:  0.2490 \n",
            "Epoch9 | Loss:  0.5643 \n",
            "Epoch9 | Loss:  0.7257 \n",
            "Epoch9 | Loss:  0.6438 \n",
            "Epoch9 | Loss:  0.3748 \n",
            "Epoch9 | Loss:  0.5313 \n",
            "Epoch9 | Loss:  0.7768 \n",
            "Epoch9 | Loss:  0.3832 \n",
            "Epoch9 | Loss:  0.7998 \n",
            "Epoch9 | Loss:  0.6718 \n",
            "Epoch9 | Loss:  0.5422 \n",
            "Epoch9 | Loss:  0.5060 \n",
            "Epoch9 | Loss:  0.5086 \n",
            "Epoch9 | Loss:  0.4520 \n",
            "Epoch9 | Loss:  0.3614 \n",
            "Epoch9 | Loss:  0.5994 \n",
            "Epoch9 | Loss:  0.5223 \n",
            "Epoch9 | Loss:  0.5299 \n",
            "Epoch9 | Loss:  0.4217 \n",
            "Epoch9 | Loss:  0.6424 \n",
            "Epoch9 | Loss:  0.6433 \n",
            "Epoch9 | Loss:  0.9625 \n",
            "Epoch9 | Loss:  0.4400 \n",
            "Epoch9 | Loss:  0.7872 \n",
            "Epoch9 | Loss:  0.5920 \n",
            "Epoch9 | Loss:  0.4665 \n",
            "Epoch9 | Loss:  0.5626 \n",
            "Epoch9 | Loss:  0.4266 \n",
            "Epoch9 | Loss:  0.4829 \n",
            "Epoch9 | Loss:  0.3926 \n",
            "Epoch9 | Loss:  0.5087 \n",
            "Epoch9 | Loss:  0.7145 \n",
            "Epoch9 | Loss:  0.4907 \n",
            "Epoch9 | Loss:  0.4164 \n",
            "Epoch9 | Loss:  0.4024 \n",
            "Epoch9 | Loss:  0.5094 \n",
            "Epoch9 | Loss:  0.3526 \n",
            "Epoch9 | Loss:  0.4548 \n",
            "Epoch9 | Loss:  0.7851 \n",
            "Epoch9 | Loss:  0.6006 \n",
            "Epoch9 | Loss:  0.5535 \n",
            "Epoch9 | Loss:  0.4289 \n",
            "Epoch9 | Loss:  0.5489 \n",
            "Epoch9 | Loss:  0.5611 \n",
            "Epoch9 | Loss:  0.7287 \n",
            "Epoch9 | Loss:  0.7283 \n",
            "Epoch9 | Loss:  0.5245 \n",
            "Epoch9 | Loss:  0.3866 \n",
            "Epoch9 | Loss:  0.7195 \n",
            "Epoch9 | Loss:  0.2750 \n",
            "Epoch9 | Loss:  0.3578 \n",
            "Epoch9 | Loss:  0.3740 \n",
            "Epoch9 | Loss:  0.5459 \n",
            "Epoch9 | Loss:  0.4618 \n",
            "Epoch9 | Loss:  0.3031 \n",
            "Epoch9 | Loss:  0.1695 \n",
            "Epoch9 | Loss:  0.7432 \n",
            "Epoch9 | Loss:  0.2425 \n",
            "Epoch9 | Loss:  0.2976 \n",
            "Epoch9 | Loss:  0.4788 \n",
            "Epoch9 | Loss:  0.3361 \n",
            "Epoch9 | Loss:  0.4554 \n",
            "Epoch9 | Loss:  0.2356 \n",
            "Epoch9 | Loss:  0.4404 \n",
            "Epoch9 | Loss:  0.4127 \n",
            "Epoch9 | Loss:  0.3949 \n",
            "Epoch9 | Loss:  0.4139 \n",
            "Epoch9 | Loss:  0.3031 \n",
            "Epoch9 | Loss:  0.8358 \n",
            "Epoch9 | Loss:  0.8205 \n",
            "Epoch9 | Loss:  0.4593 \n",
            "Epoch9 | Loss:  0.4424 \n",
            "Epoch9 | Loss:  0.6491 \n",
            "Epoch9 | Loss:  0.4679 \n",
            "Epoch9 | Loss:  0.5275 \n",
            "Epoch9 | Loss:  0.3365 \n",
            "Epoch9 | Loss:  0.7383 \n",
            "Epoch9 | Loss:  0.3973 \n",
            "Epoch9 | Loss:  0.6056 \n",
            "Epoch9 | Loss:  0.4223 \n",
            "Epoch9 | Loss:  0.8779 \n",
            "Epoch9 | Loss:  0.6177 \n",
            "Epoch9 | Loss:  0.6845 \n",
            "Epoch9 | Loss:  0.4962 \n",
            "Epoch9 | Loss:  0.2791 \n",
            "Epoch9 | Loss:  0.6324 \n",
            "Epoch9 | Loss:  0.5281 \n",
            "Epoch9 | Loss:  0.3865 \n",
            "Epoch9 | Loss:  0.5324 \n",
            "Epoch9 | Loss:  0.5302 \n",
            "Epoch9 | Loss:  0.4062 \n",
            "Epoch9 | Loss:  0.4656 \n",
            "Epoch9 | Loss:  0.5489 \n",
            "Epoch9 | Loss:  0.4336 \n",
            "Epoch9 | Loss:  0.3828 \n",
            "Epoch9 | Loss:  0.5408 \n",
            "Epoch9 | Loss:  0.3932 \n",
            "Epoch9 | Loss:  0.2993 \n",
            "Epoch9 | Loss:  0.5096 \n",
            "Epoch9 | Loss:  0.3038 \n",
            "Epoch9 | Loss:  0.5592 \n",
            "Epoch9 | Loss:  1.0225 \n",
            "Epoch9 | Loss:  0.5282 \n",
            "Epoch9 | Loss:  0.3225 \n",
            "Epoch9 | Loss:  0.4982 \n",
            "Epoch9 | Loss:  0.4804 \n",
            "Epoch9 | Loss:  0.3194 \n",
            "Epoch9 | Loss:  0.6152 \n",
            "Epoch9 | Loss:  0.8440 \n",
            "Epoch9 | Loss:  0.3441 \n",
            "Epoch9 | Loss:  0.5296 \n",
            "Epoch9 | Loss:  0.6228 \n",
            "Epoch9 | Loss:  0.6791 \n",
            "Epoch9 | Loss:  0.5314 \n",
            "Epoch9 | Loss:  0.7407 \n",
            "Epoch9 | Loss:  0.5627 \n",
            "Epoch9 | Loss:  0.9055 \n",
            "Epoch9 | Loss:  0.3751 \n",
            "Epoch9 | Loss:  0.3509 \n",
            "Epoch9 | Loss:  0.6526 \n",
            "Epoch9 | Loss:  0.4723 \n",
            "Epoch9 | Loss:  0.4559 \n",
            "Epoch9 | Loss:  0.4405 \n",
            "Epoch9 | Loss:  0.6424 \n",
            "Epoch9 | Loss:  0.4961 \n",
            "Epoch9 | Loss:  0.6894 \n",
            "Epoch9 | Loss:  0.3097 \n",
            "Epoch9 | Loss:  0.4790 \n",
            "Epoch9 | Loss:  0.3802 \n",
            "Epoch9 | Loss:  0.6968 \n",
            "Epoch9 | Loss:  0.5263 \n",
            "Epoch9 | Loss:  0.3444 \n",
            "Epoch9 | Loss:  0.7283 \n",
            "Epoch9 | Loss:  0.5846 \n",
            "Epoch9 | Loss:  0.2855 \n",
            "Epoch9 | Loss:  0.6558 \n",
            "Epoch9 | Loss:  0.5037 \n",
            "Epoch9 | Loss:  0.4231 \n",
            "Epoch9 | Loss:  0.6643 \n",
            "Epoch9 | Loss:  0.5638 \n",
            "Epoch9 | Loss:  0.5822 \n",
            "Epoch9 | Loss:  0.4790 \n",
            "Epoch9 | Loss:  0.2774 \n",
            "Epoch9 | Loss:  0.3873 \n",
            "Epoch9 | Loss:  0.4154 \n",
            "Epoch9 | Loss:  0.5637 \n",
            "Epoch9 | Loss:  0.6544 \n",
            "Epoch9 | Loss:  0.3257 \n",
            "Epoch9 | Loss:  0.3244 \n",
            "Epoch9 | Loss:  0.2564 \n",
            "Epoch9 | Loss:  0.5672 \n",
            "Epoch9 | Loss:  0.5074 \n",
            "Epoch9 | Loss:  0.3986 \n",
            "Epoch9 | Loss:  0.3384 \n",
            "Epoch9 | Loss:  0.4179 \n",
            "Epoch9 | Loss:  0.2450 \n",
            "Epoch9 | Loss:  0.4768 \n",
            "Epoch9 | Loss:  0.5127 \n",
            "Epoch9 | Loss:  0.5333 \n",
            "Epoch9 | Loss:  0.8766 \n",
            "Epoch9 | Loss:  0.7331 \n",
            "Epoch9 | Loss:  0.2523 \n",
            "Epoch9 | Loss:  0.4283 \n",
            "Epoch9 | Loss:  0.4705 \n",
            "Epoch9 | Loss:  0.6659 \n",
            "Epoch9 | Loss:  0.3326 \n",
            "Epoch9 | Loss:  0.3025 \n",
            "Epoch9 | Loss:  0.4718 \n",
            "Epoch9 | Loss:  0.7742 \n",
            "Epoch9 | Loss:  0.3939 \n",
            "Epoch9 | Loss:  0.5216 \n",
            "Epoch9 | Loss:  0.7476 \n",
            "Epoch9 | Loss:  0.7719 \n",
            "Epoch9 | Loss:  0.4741 \n",
            "Epoch9 | Loss:  0.7938 \n",
            "Epoch9 | Loss:  0.4396 \n",
            "Epoch9 | Loss:  0.4455 \n",
            "Epoch9 | Loss:  0.3805 \n",
            "Epoch9 | Loss:  0.5442 \n",
            "Epoch9 | Loss:  0.5071 \n",
            "Epoch9 | Loss:  0.6528 \n",
            "Epoch9 | Loss:  0.2820 \n",
            "Epoch9 | Loss:  0.4625 \n",
            "Epoch9 | Loss:  0.4722 \n",
            "Epoch9 | Loss:  0.5437 \n",
            "Epoch9 | Loss:  0.4488 \n",
            "Epoch9 | Loss:  0.4601 \n",
            "Epoch9 | Loss:  0.8260 \n",
            "Epoch9 | Loss:  0.5851 \n",
            "Epoch9 | Loss:  0.5170 \n",
            "Epoch9 | Loss:  0.3264 \n",
            "Epoch9 | Loss:  0.3733 \n",
            "Epoch9 | Loss:  0.4136 \n",
            "Epoch9 | Loss:  0.3358 \n",
            "Epoch9 | Loss:  0.5482 \n",
            "Epoch9 | Loss:  0.4377 \n",
            "Epoch9 | Loss:  0.8605 \n",
            "Epoch9 | Loss:  0.6017 \n",
            "Epoch9 | Loss:  0.4117 \n",
            "Epoch9 | Loss:  0.4867 \n",
            "Epoch9 | Loss:  0.6251 \n",
            "Epoch9 | Loss:  0.6099 \n",
            "Epoch9 | Loss:  0.6578 \n",
            "Epoch9 | Loss:  0.2901 \n",
            "Epoch9 | Loss:  0.4717 \n",
            "Epoch9 | Loss:  0.7412 \n",
            "Epoch9 | Loss:  0.5191 \n",
            "Epoch9 | Loss:  0.4346 \n",
            "Epoch9 | Loss:  0.2672 \n",
            "Epoch9 | Loss:  0.4471 \n",
            "Epoch9 | Loss:  0.5171 \n",
            "Epoch9 | Loss:  0.7120 \n",
            "Epoch9 | Loss:  0.5902 \n",
            "Epoch9 | Loss:  0.6747 \n",
            "Epoch9 | Loss:  0.4459 \n",
            "Epoch9 | Loss:  0.3358 \n",
            "Epoch9 | Loss:  0.5730 \n",
            "Epoch9 | Loss:  0.8486 \n",
            "Epoch9 | Loss:  0.2802 \n",
            "Epoch9 | Loss:  0.5218 \n",
            "Epoch9 | Loss:  0.1919 \n",
            "Epoch9 | Loss:  0.4369 \n",
            "Epoch9 | Loss:  0.5224 \n",
            "Epoch9 | Loss:  0.4693 \n",
            "Epoch9 | Loss:  0.3941 \n",
            "Epoch9 | Loss:  0.5960 \n",
            "Epoch9 | Loss:  0.4719 \n",
            "Epoch9 | Loss:  0.4994 \n",
            "Epoch9 | Loss:  0.7587 \n",
            "Epoch9 | Loss:  0.4454 \n",
            "Epoch9 | Loss:  0.4735 \n",
            "Epoch9 | Loss:  0.5672 \n",
            "Epoch9 | Loss:  0.5824 \n",
            "Epoch9 | Loss:  0.4631 \n",
            "Epoch9 | Loss:  0.3819 \n",
            "Epoch9 | Loss:  0.2957 \n",
            "Epoch9 | Loss:  1.0183 \n",
            "Epoch9 | Loss:  0.5029 \n",
            "Epoch9 | Loss:  0.5810 \n",
            "Epoch9 | Loss:  0.5919 \n",
            "Epoch9 | Loss:  0.4495 \n",
            "Epoch9 | Loss:  0.3855 \n",
            "Epoch9 | Loss:  0.6251 \n",
            "Epoch9 | Loss:  0.2811 \n",
            "Epoch9 | Loss:  0.5866 \n",
            "Epoch9 | Loss:  0.4512 \n",
            "Epoch9 | Loss:  0.7137 \n",
            "Epoch9 | Loss:  0.5736 \n",
            "Epoch9 | Loss:  0.5067 \n",
            "Epoch9 | Loss:  0.3191 \n",
            "Epoch9 | Loss:  0.5591 \n",
            "Epoch9 | Loss:  0.4581 \n",
            "Epoch9 | Loss:  0.4528 \n",
            "Epoch9 | Loss:  0.6627 \n",
            "Epoch9 | Loss:  0.3268 \n",
            "Epoch9 | Loss:  0.5385 \n",
            "Epoch9 | Loss:  0.3841 \n",
            "Epoch9 | Loss:  0.6331 \n",
            "Epoch9 | Loss:  0.5484 \n",
            "Epoch9 | Loss:  0.5757 \n",
            "Epoch9 | Loss:  0.5371 \n",
            "Epoch9 | Loss:  0.5561 \n",
            "Epoch9 | Loss:  0.3686 \n",
            "Epoch9 | Loss:  0.4933 \n",
            "Epoch9 | Loss:  0.4250 \n",
            "Epoch9 | Loss:  0.5811 \n",
            "Epoch9 | Loss:  0.9379 \n",
            "Epoch9 | Loss:  0.5063 \n",
            "Epoch9 | Loss:  0.5764 \n",
            "Epoch9 | Loss:  0.6078 \n",
            "Epoch9 | Loss:  0.3825 \n",
            "Epoch9 | Loss:  0.4996 \n",
            "Epoch9 | Loss:  0.7255 \n",
            "Epoch9 | Loss:  0.8279 \n",
            "Epoch9 | Loss:  0.6785 \n",
            "Epoch9 | Loss:  0.5251 \n",
            "Epoch9 | Loss:  0.6622 \n",
            "Epoch9 | Loss:  0.3053 \n",
            "Epoch9 | Loss:  0.7358 \n",
            "Epoch9 | Loss:  0.4505 \n",
            "Epoch9 | Loss:  0.4608 \n",
            "Epoch9 | Loss:  0.4827 \n",
            "Epoch9 | Loss:  0.5096 \n",
            "Epoch9 | Loss:  0.7951 \n",
            "Epoch9 | Loss:  0.6629 \n",
            "Epoch9 | Loss:  0.3223 \n",
            "Epoch9 | Loss:  0.4329 \n",
            "Epoch9 | Loss:  0.4169 \n",
            "Epoch9 | Loss:  0.6175 \n",
            "Epoch9 | Loss:  0.4763 \n",
            "Epoch9 | Loss:  0.7948 \n",
            "Epoch9 | Loss:  0.6666 \n",
            "Epoch9 | Loss:  0.3216 \n",
            "Epoch9 | Loss:  0.9957 \n",
            "Epoch9 | Loss:  0.6625 \n",
            "Epoch9 | Loss:  0.4061 \n",
            "Epoch9 | Loss:  0.7266 \n",
            "Epoch9 | Loss:  0.4673 \n",
            "Epoch9 | Loss:  0.5181 \n",
            "Epoch9 | Loss:  0.8122 \n",
            "Epoch9 | Loss:  0.4636 \n",
            "Epoch9 | Loss:  0.4628 \n",
            "Epoch9 | Loss:  0.5188 \n",
            "Epoch9 | Loss:  0.4278 \n",
            "Epoch9 | Loss:  0.4042 \n",
            "Epoch9 | Loss:  0.3646 \n",
            "Epoch9 | Loss:  0.5109 \n",
            "Epoch9 | Loss:  0.2932 \n",
            "Epoch9 | Loss:  0.4422 \n",
            "Epoch9 | Loss:  0.3597 \n",
            "Epoch9 | Loss:  0.4641 \n",
            "Epoch9 | Loss:  0.6397 \n",
            "Epoch9 | Loss:  0.5806 \n",
            "Epoch9 | Loss:  0.4416 \n",
            "Epoch9 | Loss:  0.2522 \n",
            "Epoch9 | Loss:  1.0234 \n",
            "Epoch9 | Loss:  0.4805 \n",
            "Epoch9 | Loss:  0.6096 \n",
            "Epoch9 | Loss:  0.6334 \n",
            "Epoch9 | Loss:  0.6433 \n",
            "Epoch9 | Loss:  0.9646 \n",
            "Epoch9 | Loss:  0.5087 \n",
            "Epoch9 | Loss:  0.6556 \n",
            "Epoch9 | Loss:  0.5418 \n",
            "Epoch9 | Loss:  0.5206 \n",
            "Epoch9 | Loss:  0.6519 \n",
            "Epoch9 | Loss:  0.4875 \n",
            "Epoch9 | Loss:  0.8396 \n",
            "Epoch9 | Loss:  0.8824 \n",
            "Epoch9 | Loss:  0.5754 \n",
            "Epoch9 | Loss:  0.5860 \n",
            "Epoch9 | Loss:  0.5694 \n",
            "Epoch9 | Loss:  0.6238 \n",
            "Epoch9 | Loss:  0.4202 \n",
            "Epoch9 | Loss:  0.5818 \n",
            "Epoch9 | Loss:  0.5310 \n",
            "Epoch9 | Loss:  0.5216 \n",
            "Epoch9 | Loss:  0.5860 \n",
            "Epoch9 | Loss:  0.4766 \n",
            "Epoch9 | Loss:  0.4616 \n",
            "Epoch9 | Loss:  0.4903 \n",
            "Epoch9 | Loss:  0.4510 \n",
            "Epoch9 | Loss:  0.5846 \n",
            "Epoch9 | Loss:  0.5839 \n",
            "Epoch9 | Loss:  0.4450 \n",
            "Epoch9 | Loss:  0.4588 \n",
            "Epoch9 | Loss:  0.8307 \n",
            "Epoch9 | Loss:  0.6019 \n",
            "Epoch9 | Loss:  0.6512 \n",
            "Epoch9 | Loss:  0.4975 \n",
            "Epoch9 | Loss:  0.4712 \n",
            "Epoch9 | Loss:  0.4388 \n",
            "Epoch9 | Loss:  0.5176 \n",
            "Epoch9 | Loss:  0.2653 \n",
            "Epoch9 | Loss:  0.2977 \n",
            "Epoch9 | Loss:  0.6748 \n",
            "Epoch9 | Loss:  0.4861 \n",
            "Epoch9 | Loss:  0.4212 \n",
            "Epoch9 | Loss:  0.3867 \n",
            "Epoch9 | Loss:  0.7333 \n",
            "Epoch9 | Loss:  0.3640 \n",
            "Epoch9 | Loss:  0.5775 \n",
            "Epoch9 | Loss:  0.6427 \n",
            "Epoch9 | Loss:  0.4524 \n",
            "Epoch9 | Loss:  0.4533 \n",
            "Epoch9 | Loss:  0.4789 \n",
            "Epoch9 | Loss:  0.4775 \n",
            "Epoch9 | Loss:  0.6157 \n",
            "Epoch9 | Loss:  0.5043 \n",
            "Epoch9 | Loss:  0.4586 \n",
            "Epoch9 | Loss:  0.6886 \n",
            "Epoch9 | Loss:  0.3716 \n",
            "Epoch9 | Loss:  0.6508 \n",
            "Epoch9 | Loss:  0.4043 \n",
            "Epoch9 | Loss:  0.7031 \n",
            "Epoch9 | Loss:  0.5348 \n",
            "Epoch9 | Loss:  0.4090 \n",
            "Epoch9 | Loss:  0.5670 \n",
            "Epoch9 | Loss:  0.7219 \n",
            "Epoch9 | Loss:  0.4037 \n",
            "Epoch9 | Loss:  0.3426 \n",
            "Epoch9 | Loss:  0.7072 \n",
            "Epoch9 | Loss:  0.3742 \n",
            "Epoch9 | Loss:  0.6968 \n",
            "Epoch9 | Loss:  0.7794 \n",
            "Epoch9 | Loss:  0.4873 \n",
            "Epoch9 | Loss:  0.2821 \n",
            "Epoch9 | Loss:  0.4259 \n",
            "Epoch9 | Loss:  0.4616 \n",
            "Epoch9 | Loss:  0.7197 \n",
            "Epoch9 | Loss:  0.5708 \n",
            "Epoch9 | Loss:  0.7618 \n",
            "Epoch9 | Loss:  0.5385 \n",
            "Epoch9 | Loss:  0.4068 \n",
            "Epoch9 | Loss:  0.5667 \n",
            "Epoch9 | Loss:  0.5926 \n",
            "Epoch9 | Loss:  0.7506 \n",
            "Epoch9 | Loss:  0.5041 \n",
            "Epoch9 | Loss:  0.6730 \n",
            "Epoch9 | Loss:  0.4416 \n",
            "Epoch9 | Loss:  0.6274 \n",
            "Epoch9 | Loss:  0.5733 \n",
            "Epoch9 | Loss:  0.4837 \n",
            "Epoch9 | Loss:  0.3351 \n",
            "Epoch9 | Loss:  0.4157 \n",
            "Epoch9 | Loss:  0.4245 \n",
            "Epoch9 | Loss:  0.7270 \n",
            "Epoch9 | Loss:  0.4864 \n",
            "Epoch9 | Loss:  0.7085 \n",
            "Epoch9 | Loss:  0.8948 \n",
            "Epoch9 | Loss:  0.6284 \n",
            "Epoch9 | Loss:  0.5776 \n",
            "Epoch9 | Loss:  0.3907 \n",
            "Epoch9 | Loss:  0.3260 \n",
            "Epoch9 | Loss:  0.4998 \n",
            "Epoch9 | Loss:  0.1997 \n",
            "Epoch9 | Loss:  0.2262 \n",
            "Epoch9 | Loss:  0.4700 \n",
            "Epoch9 | Loss:  0.2772 \n",
            "Epoch9 | Loss:  0.5868 \n",
            "Epoch9 | Loss:  0.3758 \n",
            "Epoch9 | Loss:  0.5457 \n",
            "Epoch9 | Loss:  0.3793 \n",
            "Epoch9 | Loss:  0.3315 \n",
            "Epoch9 | Loss:  0.5455 \n",
            "Epoch9 | Loss:  0.6713 \n",
            "Epoch9 | Loss:  0.6589 \n",
            "Epoch9 | Loss:  0.4700 \n",
            "Epoch9 | Loss:  0.5126 \n",
            "Epoch9 | Loss:  0.3312 \n",
            "Epoch9 | Loss:  0.6166 \n",
            "Epoch9 | Loss:  0.4824 \n",
            "Epoch9 | Loss:  0.4528 \n",
            "Epoch9 | Loss:  0.5297 \n",
            "Epoch9 | Loss:  0.6158 \n",
            "Epoch9 | Loss:  1.0276 \n",
            "Epoch9 | Loss:  0.5775 \n",
            "Epoch9 | Loss:  0.4074 \n",
            "Epoch9 | Loss:  0.5060 \n",
            "Epoch9 | Loss:  0.4322 \n",
            "Epoch9 | Loss:  0.3685 \n",
            "Epoch9 | Loss:  0.6162 \n",
            "Epoch9 | Loss:  0.5383 \n",
            "Epoch9 | Loss:  0.5826 \n",
            "Epoch9 | Loss:  0.5619 \n",
            "Epoch9 | Loss:  0.4047 \n",
            "Epoch9 | Loss:  0.7672 \n",
            "Epoch9 | Loss:  0.4736 \n",
            "Epoch9 | Loss:  0.5860 \n",
            "Epoch9 | Loss:  0.3900 \n",
            "Epoch9 | Loss:  0.7642 \n",
            "Epoch9 | Loss:  0.3421 \n",
            "Epoch9 | Loss:  0.2158 \n",
            "Epoch9 | Loss:  0.3784 \n",
            "Epoch9 | Loss:  0.6110 \n",
            "Epoch9 | Loss:  0.5798 \n",
            "Epoch9 | Loss:  0.7444 \n",
            "Epoch9 | Loss:  0.4334 \n",
            "Epoch9 | Loss:  0.6987 \n",
            "Epoch9 | Loss:  0.7068 \n",
            "Epoch9 | Loss:  0.7925 \n",
            "Epoch9 | Loss:  0.9458 \n",
            "Epoch9 | Loss:  0.3410 \n",
            "Epoch9 | Loss:  0.6019 \n",
            "Epoch9 | Loss:  0.7204 \n",
            "Epoch9 | Loss:  0.1879 \n",
            "Epoch9 | Loss:  0.4135 \n",
            "Epoch9 | Loss:  0.3979 \n",
            "Epoch9 | Loss:  0.4456 \n",
            "Epoch9 | Loss:  0.3633 \n",
            "Epoch9 | Loss:  0.6628 \n",
            "Epoch9 | Loss:  0.5273 \n",
            "Epoch9 | Loss:  0.7191 \n",
            "Epoch9 | Loss:  0.7689 \n",
            "Epoch9 | Loss:  0.5485 \n",
            "Epoch9 | Loss:  0.5456 \n",
            "Epoch9 | Loss:  0.5690 \n",
            "Epoch9 | Loss:  0.4361 \n",
            "Epoch9 | Loss:  0.4495 \n",
            "Epoch9 | Loss:  0.3220 \n",
            "Epoch9 | Loss:  0.4018 \n",
            "Epoch9 | Loss:  0.5219 \n",
            "Epoch9 | Loss:  0.4541 \n",
            "Epoch9 | Loss:  0.3554 \n",
            "Epoch9 | Loss:  0.4359 \n",
            "Epoch9 | Loss:  0.1621 \n",
            "Epoch9 | Loss:  0.4704 \n",
            "Epoch9 | Loss:  0.4098 \n",
            "Epoch9 | Loss:  0.4531 \n",
            "Epoch9 | Loss:  0.1812 \n",
            "Epoch9 | Loss:  0.4635 \n",
            "Epoch9 | Loss:  0.3299 \n",
            "Epoch9 | Loss:  0.4933 \n",
            "Epoch9 | Loss:  0.6370 \n",
            "Epoch9 | Loss:  0.3383 \n",
            "Epoch9 | Loss:  0.2551 \n",
            "Epoch9 | Loss:  0.2908 \n",
            "Epoch9 | Loss:  0.3842 \n",
            "Epoch9 | Loss:  0.7191 \n",
            "Epoch9 | Loss:  0.4991 \n",
            "Epoch9 | Loss:  0.3816 \n",
            "Epoch9 | Loss:  0.6740 \n",
            "Epoch9 | Loss:  0.6783 \n",
            "Epoch9 | Loss:  0.5201 \n",
            "Epoch9 | Loss:  0.7118 \n",
            "Epoch9 | Loss:  0.4506 \n",
            "Epoch9 | Loss:  0.4242 \n",
            "Epoch9 | Loss:  0.4164 \n",
            "Epoch9 | Loss:  0.5870 \n",
            "Epoch9 | Loss:  0.7301 \n",
            "Epoch9 | Loss:  0.4594 \n",
            "Epoch9 | Loss:  0.4982 \n",
            "Epoch9 | Loss:  0.3551 \n",
            "Epoch9 | Loss:  0.3606 \n",
            "Epoch9 | Loss:  0.2957 \n",
            "Epoch9 | Loss:  0.5936 \n",
            "Epoch9 | Loss:  0.7702 \n",
            "Epoch9 | Loss:  0.3608 \n",
            "Epoch9 | Loss:  0.5287 \n",
            "Epoch9 | Loss:  0.6602 \n",
            "Epoch9 | Loss:  0.6490 \n",
            "Epoch9 | Loss:  0.6360 \n",
            "Epoch9 | Loss:  0.5254 \n",
            "Epoch9 | Loss:  0.6415 \n",
            "Epoch9 | Loss:  0.4768 \n",
            "Epoch9 | Loss:  0.4754 \n",
            "Epoch9 | Loss:  0.8079 \n",
            "Epoch9 | Loss:  0.4998 \n",
            "Epoch9 | Loss:  0.5016 \n",
            "Epoch9 | Loss:  0.4324 \n",
            "Epoch9 | Loss:  0.2831 \n",
            "Epoch9 | Loss:  0.7953 \n",
            "Epoch9 | Loss:  0.4518 \n",
            "Epoch9 | Loss:  0.4860 \n",
            "Epoch9 | Loss:  0.4037 \n",
            "Epoch9 | Loss:  0.3400 \n",
            "Epoch9 | Loss:  0.5731 \n",
            "Epoch9 | Loss:  0.5253 \n",
            "Epoch9 | Loss:  0.4944 \n",
            "Epoch9 | Loss:  0.5307 \n",
            "Epoch9 | Loss:  0.5361 \n",
            "Epoch9 | Loss:  0.4729 \n",
            "Epoch9 | Loss:  0.9808 \n",
            "Epoch9 | Loss:  0.7129 \n",
            "Epoch9 | Loss:  0.3050 \n",
            "Epoch9 | Loss:  0.4885 \n",
            "Epoch9 | Loss:  0.4225 \n",
            "Epoch9 | Loss:  0.6401 \n",
            "Epoch9 | Loss:  0.6576 \n",
            "Epoch9 | Loss:  0.2775 \n",
            "Epoch9 | Loss:  0.5406 \n",
            "Epoch9 | Loss:  0.6285 \n",
            "Epoch9 | Loss:  0.5960 \n",
            "Epoch9 | Loss:  0.4808 \n",
            "Epoch9 | Loss:  0.7418 \n",
            "Epoch9 | Loss:  0.3543 \n",
            "Epoch9 | Loss:  0.4699 \n",
            "Epoch9 | Loss:  0.4959 \n",
            "Epoch9 | Loss:  0.6488 \n",
            "Epoch9 | Loss:  0.5727 \n",
            "Epoch9 | Loss:  0.5194 \n",
            "Epoch9 | Loss:  0.4897 \n",
            "Epoch9 | Loss:  0.5337 \n",
            "Epoch9 | Loss:  0.6206 \n",
            "Epoch9 | Loss:  0.6033 \n",
            "Epoch9 | Loss:  0.4744 \n",
            "Epoch9 | Loss:  0.4451 \n",
            "Epoch9 | Loss:  0.4343 \n",
            "Epoch9 | Loss:  0.5303 \n",
            "Epoch9 | Loss:  0.8247 \n",
            "Epoch9 | Loss:  0.5536 \n",
            "Epoch9 | Loss:  0.6010 \n",
            "Epoch9 | Loss:  0.3018 \n",
            "Epoch9 | Loss:  0.7153 \n",
            "Epoch9 | Loss:  0.6618 \n",
            "Epoch9 | Loss:  0.9639 \n",
            "Epoch9 | Loss:  0.4018 \n",
            "Epoch9 | Loss:  0.7963 \n",
            "Epoch9 | Loss:  0.6197 \n",
            "Epoch9 | Loss:  0.4765 \n",
            "Epoch9 | Loss:  0.4153 \n",
            "Epoch9 | Loss:  0.5215 \n",
            "Epoch9 | Loss:  0.3876 \n",
            "Epoch9 | Loss:  0.7991 \n",
            "Epoch9 | Loss:  0.6655 \n",
            "Epoch9 | Loss:  0.8073 \n",
            "Epoch9 | Loss:  0.5932 \n",
            "Epoch9 | Loss:  0.3794 \n",
            "Epoch9 | Loss:  0.7925 \n",
            "Epoch9 | Loss:  0.3444 \n",
            "Epoch9 | Loss:  0.8024 \n",
            "Epoch9 | Loss:  0.6025 \n",
            "Epoch9 | Loss:  0.6267 \n",
            "Epoch9 | Loss:  0.2384 \n",
            "Epoch9 | Loss:  0.5047 \n",
            "Epoch9 | Loss:  0.8224 \n",
            "Epoch9 | Loss:  0.5302 \n",
            "Epoch9 | Loss:  0.3783 \n",
            "Epoch9 | Loss:  0.3750 \n",
            "Epoch9 | Loss:  0.6937 \n",
            "Epoch9 | Loss:  0.8335 \n",
            "Epoch9 | Loss:  0.4856 \n",
            "Epoch9 | Loss:  0.3365 \n",
            "Epoch9 | Loss:  0.5534 \n",
            "Epoch9 | Loss:  0.6250 \n",
            "Epoch9 | Loss:  0.5144 \n",
            "Epoch9 | Loss:  0.5484 \n",
            "Epoch9 | Loss:  0.4283 \n",
            "Epoch9 | Loss:  0.4087 \n",
            "Epoch9 | Loss:  0.5535 \n",
            "Epoch9 | Loss:  0.2715 \n",
            "Epoch9 | Loss:  0.3973 \n",
            "Epoch9 | Loss:  0.7344 \n",
            "Epoch9 | Loss:  0.5570 \n",
            "Epoch9 | Loss:  0.5730 \n",
            "Epoch9 | Loss:  0.4701 \n",
            "Epoch9 | Loss:  0.6262 \n",
            "Epoch9 | Loss:  0.2633 \n",
            "Epoch9 | Loss:  0.3297 \n",
            "Epoch9 | Loss:  0.5077 \n",
            "Epoch9 | Loss:  0.5294 \n",
            "Epoch9 | Loss:  0.3721 \n",
            "Epoch9 | Loss:  0.6720 \n",
            "Epoch9 | Loss:  0.3384 \n",
            "Epoch9 | Loss:  0.8476 \n",
            "Epoch9 | Loss:  0.6135 \n",
            "Epoch9 | Loss:  0.6071 \n",
            "Epoch9 | Loss:  0.4228 \n",
            "Epoch9 | Loss:  0.6070 \n",
            "Epoch9 | Loss:  0.4117 \n",
            "Epoch9 | Loss:  0.4330 \n",
            "Epoch9 | Loss:  0.6833 \n",
            "Epoch9 | Loss:  0.2424 \n",
            "Epoch9 | Loss:  0.4536 \n",
            "Epoch9 | Loss:  0.6118 \n",
            "Epoch9 | Loss:  0.4409 \n",
            "Epoch9 | Loss:  0.3773 \n",
            "Epoch9 | Loss:  0.5211 \n",
            "Epoch9 | Loss:  0.3964 \n",
            "Epoch9 | Loss:  0.5975 \n",
            "Epoch9 | Loss:  0.5363 \n",
            "Epoch9 | Loss:  0.8257 \n",
            "Epoch9 | Loss:  0.5260 \n",
            "Epoch9 | Loss:  0.4829 \n",
            "Epoch9 | Loss:  0.9700 \n",
            "Epoch9 | Loss:  0.6787 \n",
            "Epoch9 | Loss:  0.7275 \n",
            "Epoch9 | Loss:  0.2791 \n",
            "Epoch9 | Loss:  0.5853 \n",
            "Epoch9 | Loss:  0.7100 \n",
            "Epoch9 | Loss:  0.3719 \n",
            "Epoch9 | Loss:  0.5065 \n",
            "Epoch9 | Loss:  0.5211 \n",
            "Epoch9 | Loss:  0.4752 \n",
            "Epoch9 | Loss:  0.6018 \n",
            "Epoch9 | Loss:  0.6213 \n",
            "Epoch9 | Loss:  0.8708 \n",
            "Epoch9 | Loss:  0.8488 \n",
            "Epoch9 | Loss:  0.4254 \n",
            "Epoch9 | Loss:  0.5447 \n",
            "Epoch9 | Loss:  0.4742 \n",
            "Epoch9 | Loss:  0.5414 \n",
            "Epoch9 | Loss:  0.5800 \n",
            "Epoch9 | Loss:  0.5692 \n",
            "Epoch9 | Loss:  0.5039 \n",
            "Epoch9 | Loss:  0.4981 \n",
            "Epoch9 | Loss:  0.7557 \n",
            "Epoch9 | Loss:  0.5253 \n",
            "Epoch9 | Loss:  0.6186 \n",
            "Epoch9 | Loss:  0.8142 \n",
            "Epoch9 | Loss:  0.4744 \n",
            "Epoch9 | Loss:  0.6769 \n",
            "Epoch9 | Loss:  0.5538 \n",
            "Epoch9 | Loss:  0.6753 \n",
            "Epoch9 | Loss:  0.6100 \n",
            "Epoch9 | Loss:  0.7265 \n",
            "Epoch9 | Loss:  0.4128 \n",
            "Epoch9 | Loss:  0.3579 \n",
            "Epoch9 | Loss:  0.9984 \n",
            "Epoch9 | Loss:  0.6294 \n",
            "Epoch9 | Loss:  0.3820 \n",
            "Epoch9 | Loss:  0.5573 \n",
            "Epoch9 | Loss:  0.4094 \n",
            "Epoch9 | Loss:  0.5328 \n",
            "Epoch9 | Loss:  0.4675 \n",
            "Epoch9 | Loss:  0.7280 \n",
            "Epoch9 | Loss:  0.4143 \n",
            "Epoch9 | Loss:  0.3539 \n",
            "Epoch9 | Loss:  0.4065 \n",
            "Epoch9 | Loss:  0.4191 \n",
            "Epoch9 | Loss:  0.3820 \n",
            "Epoch9 | Loss:  0.5758 \n",
            "Epoch9 | Loss:  0.8930 \n",
            "Epoch9 | Loss:  0.5075 \n",
            "Epoch9 | Loss:  0.3802 \n",
            "Epoch9 | Loss:  0.6083 \n",
            "Epoch9 | Loss:  0.5274 \n",
            "Epoch9 | Loss:  0.6647 \n",
            "Epoch9 | Loss:  1.0408 \n",
            "Epoch9 | Loss:  0.6103 \n",
            "Epoch9 | Loss:  0.5238 \n",
            "Epoch9 | Loss:  0.2059 \n",
            "Epoch9 | Loss:  0.6894 \n",
            "Epoch9 | Loss:  0.8455 \n",
            "Epoch9 | Loss:  0.4562 \n",
            "Epoch9 | Loss:  0.5441 \n",
            "Epoch9 | Loss:  0.6804 \n",
            "Epoch9 | Loss:  0.2328 \n",
            "Epoch9 | Loss:  0.4327 \n",
            "Epoch9 | Loss:  0.6154 \n",
            "Epoch9 | Loss:  0.4660 \n",
            "Epoch9 | Loss:  0.4054 \n",
            "Epoch9 | Loss:  0.5247 \n",
            "Epoch9 | Loss:  0.6036 \n",
            "Epoch9 | Loss:  0.3190 \n",
            "Epoch9 | Loss:  0.7036 \n",
            "Epoch9 | Loss:  0.3436 \n",
            "Epoch9 | Loss:  0.4664 \n",
            "Epoch9 | Loss:  0.4631 \n",
            "Epoch9 | Loss:  0.8588 \n",
            "Epoch9 | Loss:  0.7751 \n",
            "Epoch9 | Loss:  0.4433 \n",
            "Epoch9 | Loss:  0.3446 \n",
            "Epoch9 | Loss:  0.2129 \n",
            "Epoch9 | Loss:  0.5198 \n",
            "Epoch9 | Loss:  0.8586 \n",
            "Epoch9 | Loss:  0.5655 \n",
            "Epoch9 | Loss:  0.4795 \n",
            "Epoch9 | Loss:  0.3430 \n",
            "Epoch9 | Loss:  0.4113 \n",
            "Epoch9 | Loss:  0.2654 \n",
            "Epoch9 | Loss:  0.4904 \n",
            "Epoch9 | Loss:  0.5235 \n",
            "Epoch9 | Loss:  0.4511 \n",
            "Epoch9 | Loss:  0.4712 \n",
            "Epoch9 | Loss:  0.4908 \n",
            "Epoch9 | Loss:  0.2725 \n",
            "Epoch9 | Loss:  0.5867 \n",
            "Epoch9 | Loss:  0.9763 \n",
            "Epoch9 | Loss:  0.4171 \n",
            "Epoch9 | Loss:  0.5170 \n",
            "Epoch9 | Loss:  0.6357 \n",
            "Epoch9 | Loss:  0.7658 \n",
            "Epoch9 | Loss:  0.4109 \n",
            "Epoch9 | Loss:  0.4183 \n",
            "Epoch9 | Loss:  0.8623 \n",
            "Epoch9 | Loss:  0.4788 \n",
            "Epoch9 | Loss:  0.4230 \n",
            "Epoch9 | Loss:  0.5638 \n",
            "Epoch9 | Loss:  0.3478 \n",
            "Epoch9 | Loss:  0.2919 \n",
            "Epoch9 | Loss:  0.4590 \n",
            "Epoch9 | Loss:  0.3955 \n",
            "Epoch9 | Loss:  0.5551 \n",
            "Epoch9 | Loss:  0.5585 \n",
            "Epoch9 | Loss:  0.7644 \n",
            "Epoch9 | Loss:  0.2808 \n",
            "Epoch9 | Loss:  0.6535 \n",
            "Epoch9 | Loss:  0.6548 \n",
            "Epoch9 | Loss:  0.6265 \n",
            "Epoch9 | Loss:  0.7657 \n",
            "Epoch9 | Loss:  0.3887 \n",
            "Epoch9 | Loss:  0.7173 \n",
            "Epoch9 | Loss:  0.3059 \n",
            "Epoch9 | Loss:  0.6145 \n",
            "Epoch9 | Loss:  0.7196 \n",
            "Epoch9 | Loss:  0.7155 \n",
            "Epoch9 | Loss:  0.6193 \n",
            "Epoch9 | Loss:  0.4681 \n",
            "Epoch9 | Loss:  0.7629 \n",
            "Epoch9 | Loss:  0.3917 \n",
            "Epoch9 | Loss:  0.7083 \n",
            "Epoch9 | Loss:  0.4752 \n",
            "Epoch9 | Loss:  0.4358 \n",
            "Epoch9 | Loss:  0.4274 \n",
            "Epoch9 | Loss:  0.5057 \n",
            "Epoch9 | Loss:  0.4074 \n",
            "Epoch9 | Loss:  0.4818 \n",
            "Epoch9 | Loss:  0.5805 \n",
            "Epoch9 | Loss:  0.7424 \n",
            "Epoch9 | Loss:  0.8323 \n",
            "Epoch9 | Loss:  0.4338 \n",
            "Epoch9 | Loss:  0.5915 \n",
            "Epoch9 | Loss:  0.5783 \n",
            "Epoch9 | Loss:  0.3787 \n",
            "Epoch9 | Loss:  0.5061 \n",
            "Epoch9 | Loss:  0.3942 \n",
            "Epoch9 | Loss:  0.5796 \n",
            "Epoch9 | Loss:  0.3770 \n",
            "Epoch9 | Loss:  0.5106 \n",
            "Epoch9 | Loss:  0.6315 \n",
            "Epoch9 | Loss:  0.5096 \n",
            "Epoch9 | Loss:  0.3227 \n",
            "Epoch9 | Loss:  0.4949 \n",
            "Epoch9 | Loss:  0.5099 \n",
            "Epoch9 | Loss:  0.8394 \n",
            "Epoch9 | Loss:  0.5121 \n",
            "Epoch9 | Loss:  0.5243 \n",
            "Epoch9 | Loss:  0.4549 \n",
            "Epoch9 | Loss:  0.5829 \n",
            "Epoch9 | Loss:  0.5430 \n",
            "Epoch9 | Loss:  0.4436 \n",
            "Epoch9 | Loss:  1.0787 \n",
            "Epoch9 | Loss:  0.4451 \n",
            "Epoch9 | Loss:  0.2880 \n",
            "Epoch9 | Loss:  0.4047 \n",
            "Epoch9 | Loss:  0.4491 \n",
            "Epoch9 | Loss:  0.5901 \n",
            "Epoch9 | Loss:  0.3620 \n",
            "Epoch9 | Loss:  0.3526 \n",
            "Epoch9 | Loss:  0.5699 \n",
            "Epoch9 | Loss:  0.2770 \n",
            "Epoch9 | Loss:  0.5712 \n",
            "Epoch9 | Loss:  0.4585 \n",
            "Epoch9 | Loss:  0.5182 \n",
            "Epoch9 | Loss:  0.2741 \n",
            "Epoch9 | Loss:  0.3689 \n",
            "Epoch9 | Loss:  0.5082 \n",
            "Epoch9 | Loss:  0.5469 \n",
            "Epoch9 | Loss:  0.6159 \n",
            "Epoch9 | Loss:  0.5410 \n",
            "Epoch9 | Loss:  0.3933 \n",
            "Epoch9 | Loss:  0.6190 \n",
            "Epoch9 | Loss:  0.4028 \n",
            "Epoch9 | Loss:  0.3331 \n",
            "Epoch9 | Loss:  0.8086 \n",
            "Epoch9 | Loss:  0.8360 \n",
            "Epoch9 | Loss:  0.6685 \n",
            "Epoch9 | Loss:  0.5977 \n",
            "Epoch9 | Loss:  0.4547 \n",
            "Epoch9 | Loss:  0.3909 \n",
            "Epoch9 | Loss:  0.6739 \n",
            "Epoch9 | Loss:  0.3967 \n",
            "Epoch9 | Loss:  0.5905 \n",
            "Epoch9 | Loss:  0.5433 \n",
            "Epoch9 | Loss:  0.5198 \n",
            "Epoch9 | Loss:  0.3305 \n",
            "Epoch9 | Loss:  0.5267 \n",
            "Epoch9 | Loss:  0.6160 \n",
            "Epoch9 | Loss:  0.5302 \n",
            "Epoch9 | Loss:  0.9038 \n",
            "Epoch9 | Loss:  0.7022 \n",
            "Epoch9 | Loss:  0.7782 \n",
            "Epoch9 | Loss:  0.7558 \n",
            "Epoch9 | Loss:  0.3744 \n",
            "Epoch9 | Loss:  0.9747 \n",
            "Epoch9 | Loss:  0.5422 \n",
            "Epoch9 | Loss:  0.2698 \n",
            "Epoch9 | Loss:  0.6582 \n",
            "Epoch9 | Loss:  0.4572 \n",
            "Epoch9 | Loss:  0.4835 \n",
            "Epoch9 | Loss:  0.5099 \n",
            "Epoch9 | Loss:  0.8154 \n",
            "Epoch9 | Loss:  0.3758 \n",
            "Epoch9 | Loss:  0.7536 \n",
            "Epoch9 | Loss:  0.5122 \n",
            "Epoch9 | Loss:  0.4419 \n",
            "Epoch9 | Loss:  0.7007 \n",
            "Epoch9 | Loss:  0.5884 \n",
            "Epoch9 | Loss:  0.5345 \n",
            "Epoch9 | Loss:  0.9638 \n",
            "Epoch9 | Loss:  0.5763 \n",
            "Epoch9 | Loss:  0.5787 \n",
            "Epoch9 | Loss:  0.7731 \n",
            "Epoch9 | Loss:  0.4035 \n",
            "Epoch9 | Loss:  0.4872 \n",
            "Epoch9 | Loss:  0.3274 \n",
            "Epoch9 | Loss:  0.4681 \n",
            "Epoch9 | Loss:  0.6065 \n",
            "Epoch9 | Loss:  0.5680 \n",
            "Epoch9 | Loss:  0.4094 \n",
            "Epoch9 | Loss:  0.4790 \n",
            "Epoch9 | Loss:  0.5994 \n",
            "Epoch9 | Loss:  0.5565 \n",
            "Epoch9 | Loss:  0.5743 \n",
            "Epoch9 | Loss:  0.5142 \n",
            "Epoch9 | Loss:  0.5706 \n",
            "Epoch9 | Loss:  0.5112 \n",
            "Epoch9 | Loss:  0.4424 \n",
            "Epoch9 | Loss:  0.4655 \n",
            "Epoch9 | Loss:  0.4983 \n",
            "Epoch9 | Loss:  0.4228 \n",
            "Epoch9 | Loss:  0.4571 \n",
            "Epoch9 | Loss:  0.4221 \n",
            "Epoch9 | Loss:  0.3529 \n",
            "Epoch9 | Loss:  0.4098 \n",
            "Epoch9 | Loss:  0.3527 \n",
            "Epoch9 | Loss:  0.5014 \n",
            "Epoch9 | Loss:  0.7095 \n",
            "Epoch9 | Loss:  0.8909 \n",
            "Epoch9 | Loss:  0.4782 \n",
            "Epoch9 | Loss:  0.5978 \n",
            "Epoch9 | Loss:  0.4947 \n",
            "Epoch9 | Loss:  0.3826 \n",
            "Epoch9 | Loss:  0.6546 \n",
            "Epoch9 | Loss:  0.2907 \n",
            "Epoch9 | Loss:  0.5968 \n",
            "Epoch9 | Loss:  0.4008 \n",
            "Epoch9 | Loss:  0.7865 \n",
            "Epoch9 | Loss:  0.4455 \n",
            "Epoch9 | Loss:  0.7510 \n",
            "Epoch9 | Loss:  0.4581 \n",
            "Epoch9 | Loss:  0.4008 \n",
            "Epoch9 | Loss:  0.5813 \n",
            "Epoch9 | Loss:  0.5283 \n",
            "Epoch9 | Loss:  0.4657 \n",
            "Epoch9 | Loss:  0.6583 \n",
            "Epoch9 | Loss:  0.7201 \n",
            "Epoch9 | Loss:  0.5134 \n",
            "Epoch9 | Loss:  0.3285 \n",
            "Epoch9 | Loss:  0.3893 \n",
            "Epoch9 | Loss:  0.3021 \n",
            "Epoch9 | Loss:  0.5097 \n",
            "Epoch9 | Loss:  0.6824 \n",
            "Epoch9 | Loss:  0.4496 \n",
            "Epoch9 | Loss:  0.5059 \n",
            "Epoch9 | Loss:  0.4444 \n",
            "Epoch9 | Loss:  0.4344 \n",
            "Epoch9 | Loss:  0.5116 \n",
            "Epoch9 | Loss:  0.5582 \n",
            "Epoch9 | Loss:  0.3604 \n",
            "Epoch9 | Loss:  0.4998 \n",
            "Epoch9 | Loss:  0.5476 \n",
            "Epoch9 | Loss:  0.3570 \n",
            "Epoch9 | Loss:  0.4627 \n",
            "Epoch9 | Loss:  0.4001 \n",
            "Epoch9 | Loss:  0.4337 \n",
            "Epoch9 | Loss:  0.7842 \n",
            "Epoch9 | Loss:  0.6114 \n",
            "Epoch9 | Loss:  0.4017 \n",
            "Epoch9 | Loss:  0.4414 \n",
            "Epoch9 | Loss:  0.5333 \n",
            "Epoch9 | Loss:  0.3986 \n",
            "Epoch9 | Loss:  0.3005 \n",
            "Epoch9 | Loss:  0.3723 \n",
            "Epoch9 | Loss:  0.6013 \n",
            "Epoch9 | Loss:  0.4364 \n",
            "Epoch9 | Loss:  0.4978 \n",
            "Epoch9 | Loss:  0.3049 \n",
            "Epoch9 | Loss:  0.3841 \n",
            "Epoch9 | Loss:  0.6497 \n",
            "Epoch9 | Loss:  0.6568 \n",
            "Epoch9 | Loss:  0.4305 \n",
            "Epoch9 | Loss:  0.5432 \n",
            "Epoch9 | Loss:  0.5698 \n",
            "Epoch9 | Loss:  0.4835 \n",
            "Epoch9 | Loss:  0.8717 \n",
            "Epoch9 | Loss:  0.4723 \n",
            "Epoch9 | Loss:  0.4514 \n",
            "Epoch9 | Loss:  0.4999 \n",
            "Epoch9 | Loss:  0.3310 \n",
            "Epoch9 | Loss:  0.7856 \n",
            "Epoch9 | Loss:  0.6105 \n",
            "Epoch9 | Loss:  0.2883 \n",
            "Epoch9 | Loss:  0.3317 \n",
            "Epoch9 | Loss:  0.9832 \n",
            "Epoch9 | Loss:  0.4939 \n",
            "Epoch9 | Loss:  0.4346 \n",
            "Epoch9 | Loss:  0.4606 \n",
            "Epoch9 | Loss:  0.5847 \n",
            "Epoch9 | Loss:  0.3799 \n",
            "Epoch9 | Loss:  0.5696 \n",
            "Epoch9 | Loss:  0.4432 \n",
            "Epoch9 | Loss:  0.2767 \n",
            "Epoch9 | Loss:  0.6417 \n",
            "Epoch9 | Loss:  0.8795 \n",
            "Epoch9 | Loss:  0.4613 \n",
            "Epoch9 | Loss:  0.4853 \n",
            "Epoch9 | Loss:  0.5070 \n",
            "Epoch9 | Loss:  0.3624 \n",
            "Epoch9 | Loss:  0.6395 \n",
            "Epoch9 | Loss:  0.7744 \n",
            "Epoch9 | Loss:  0.8697 \n",
            "Epoch9 | Loss:  0.4718 \n",
            "Epoch9 | Loss:  0.2940 \n",
            "Epoch9 | Loss:  0.3641 \n",
            "Epoch9 | Loss:  0.9690 \n",
            "Epoch9 | Loss:  0.4413 \n",
            "Epoch9 | Loss:  0.7253 \n",
            "Epoch9 | Loss:  0.5262 \n",
            "Epoch9 | Loss:  0.6121 \n",
            "Epoch9 | Loss:  0.3744 \n",
            "Epoch9 | Loss:  0.4331 \n",
            "Epoch9 | Loss:  0.6406 \n",
            "Epoch9 | Loss:  0.3659 \n",
            "Epoch9 | Loss:  0.5474 \n",
            "Epoch9 | Loss:  0.5506 \n",
            "Epoch9 | Loss:  0.3900 \n",
            "Epoch9 | Loss:  0.6288 \n",
            "Epoch9 | Loss:  0.5076 \n",
            "Epoch9 | Loss:  0.5626 \n",
            "Epoch9 | Loss:  0.5207 \n",
            "Epoch9 | Loss:  0.4497 \n",
            "Epoch9 | Loss:  0.7393 \n",
            "Epoch9 | Loss:  0.6087 \n",
            "Epoch9 | Loss:  0.4252 \n",
            "Epoch9 | Loss:  0.6065 \n",
            "Epoch9 | Loss:  0.2996 \n",
            "Epoch9 | Loss:  0.4033 \n",
            "Epoch9 | Loss:  0.4757 \n",
            "Epoch9 | Loss:  0.5520 \n",
            "Epoch9 | Loss:  0.5205 \n",
            "Epoch9 | Loss:  0.3332 \n",
            "Epoch9 | Loss:  0.6570 \n",
            "Epoch9 | Loss:  0.3763 \n",
            "Epoch9 | Loss:  0.3447 \n",
            "Epoch9 | Loss:  0.5954 \n",
            "Epoch9 | Loss:  0.9227 \n",
            "Epoch9 | Loss:  0.2748 \n",
            "Epoch9 | Loss:  0.6510 \n",
            "Epoch9 | Loss:  0.3621 \n",
            "Epoch9 | Loss:  0.5102 \n",
            "Epoch9 | Loss:  0.4805 \n",
            "Epoch9 | Loss:  0.3238 \n",
            "Epoch9 | Loss:  0.5937 \n",
            "Epoch9 | Loss:  0.1873 \n",
            "Epoch9 | Loss:  0.5995 \n",
            "Epoch9 | Loss:  0.7079 \n",
            "Epoch9 | Loss:  0.4405 \n",
            "Epoch9 | Loss:  0.6684 \n",
            "Epoch9 | Loss:  0.5503 \n",
            "Epoch9 | Loss:  0.4041 \n",
            "Epoch9 | Loss:  0.6296 \n",
            "Epoch9 | Loss:  0.3060 \n",
            "Epoch9 | Loss:  0.5173 \n",
            "Epoch9 | Loss:  0.6191 \n",
            "Epoch9 | Loss:  0.4251 \n",
            "Epoch9 | Loss:  0.5126 \n",
            "Epoch9 | Loss:  0.5383 \n",
            "Epoch9 | Loss:  0.5151 \n",
            "Epoch9 | Loss:  0.8325 \n",
            "Epoch9 | Loss:  0.4691 \n",
            "Epoch9 | Loss:  0.2930 \n",
            "Epoch9 | Loss:  0.4036 \n",
            "Epoch9 | Loss:  0.3793 \n",
            "Epoch9 | Loss:  0.6062 \n",
            "Epoch9 | Loss:  0.4699 \n",
            "Epoch9 | Loss:  0.4873 \n",
            "Epoch9 | Loss:  0.4694 \n",
            "Epoch9 | Loss:  0.3386 \n",
            "Epoch9 | Loss:  0.6204 \n",
            "Epoch9 | Loss:  0.6438 \n",
            "Epoch9 | Loss:  0.3300 \n",
            "Epoch9 | Loss:  0.3383 \n",
            "Epoch9 | Loss:  0.8406 \n",
            "Epoch9 | Loss:  0.4018 \n",
            "Epoch9 | Loss:  0.5590 \n",
            "Epoch9 | Loss:  0.8411 \n",
            "Epoch9 | Loss:  0.5765 \n",
            "Epoch9 | Loss:  0.3622 \n",
            "Epoch9 | Loss:  0.4435 \n",
            "Epoch9 | Loss:  0.6180 \n",
            "Epoch9 | Loss:  0.3966 \n",
            "Epoch9 | Loss:  0.5525 \n",
            "Epoch9 | Loss:  0.7440 \n",
            "Epoch9 | Loss:  0.5820 \n",
            "Epoch9 | Loss:  0.3948 \n",
            "Epoch9 | Loss:  0.2735 \n",
            "Epoch9 | Loss:  0.4540 \n",
            "Epoch9 | Loss:  0.6214 \n",
            "Epoch9 | Loss:  0.5641 \n",
            "Epoch9 | Loss:  0.6565 \n",
            "Epoch9 | Loss:  0.4261 \n",
            "Epoch9 | Loss:  0.8573 \n",
            "Epoch9 | Loss:  0.5017 \n",
            "Epoch9 | Loss:  0.4536 \n",
            "Epoch9 | Loss:  0.5590 \n",
            "Epoch9 | Loss:  0.4514 \n",
            "Epoch9 | Loss:  0.4474 \n",
            "Epoch9 | Loss:  0.4536 \n",
            "Epoch9 | Loss:  0.9033 \n",
            "Epoch9 | Loss:  0.3854 \n",
            "Epoch9 | Loss:  0.6358 \n",
            "Epoch9 | Loss:  0.7066 \n",
            "Epoch9 | Loss:  0.3906 \n",
            "Epoch9 | Loss:  0.3887 \n",
            "Epoch9 | Loss:  0.4372 \n",
            "Epoch9 | Loss:  0.5015 \n",
            "Epoch9 | Loss:  0.6636 \n",
            "Epoch9 | Loss:  0.4046 \n",
            "Epoch9 | Loss:  0.7377 \n",
            "Epoch9 | Loss:  0.8333 \n",
            "Epoch9 | Loss:  0.3210 \n",
            "Epoch9 | Loss:  0.4677 \n",
            "Epoch9 | Loss:  0.5111 \n",
            "Epoch9 | Loss:  0.3364 \n",
            "Epoch9 | Loss:  0.5081 \n",
            "Epoch9 | Loss:  0.4991 \n",
            "Epoch9 | Loss:  0.5566 \n",
            "Epoch9 | Loss:  0.4848 \n",
            "Epoch9 | Loss:  0.3289 \n",
            "Epoch9 | Loss:  0.4977 \n",
            "Epoch9 | Loss:  0.4882 \n",
            "Epoch9 | Loss:  0.5167 \n",
            "Epoch9 | Loss:  0.2819 \n",
            "Epoch9 | Loss:  0.6178 \n",
            "Epoch9 | Loss:  0.2483 \n",
            "Epoch9 | Loss:  0.9576 \n",
            "Epoch9 | Loss:  0.4704 \n",
            "Epoch9 | Loss:  0.4849 \n",
            "Epoch9 | Loss:  0.5325 \n",
            "Epoch9 | Loss:  0.3314 \n",
            "Epoch9 | Loss:  0.4162 \n",
            "Epoch9 | Loss:  0.4810 \n",
            "Epoch9 | Loss:  0.4439 \n",
            "Epoch9 | Loss:  0.5199 \n",
            "Epoch9 | Loss:  0.4797 \n",
            "Epoch9 | Loss:  0.4620 \n",
            "Epoch9 | Loss:  0.4602 \n",
            "Epoch9 | Loss:  0.4225 \n",
            "Epoch9 | Loss:  0.3939 \n",
            "Epoch9 | Loss:  0.5972 \n",
            "Epoch9 | Loss:  0.4703 \n",
            "Epoch9 | Loss:  0.3439 \n",
            "Epoch9 | Loss:  0.6555 \n",
            "Epoch9 | Loss:  0.3991 \n",
            "Epoch9 | Loss:  0.6075 \n",
            "Epoch9 | Loss:  0.4754 \n",
            "Epoch9 | Loss:  0.3226 \n",
            "Epoch9 | Loss:  0.4693 \n",
            "Epoch9 | Loss:  0.7842 \n",
            "Epoch9 | Loss:  0.6264 \n",
            "Epoch9 | Loss:  0.3639 \n",
            "Epoch9 | Loss:  0.4840 \n",
            "Epoch9 | Loss:  0.4607 \n",
            "Epoch9 | Loss:  0.4336 \n",
            "Epoch9 | Loss:  0.6721 \n",
            "Epoch9 | Loss:  0.2531 \n",
            "Epoch9 | Loss:  0.5520 \n",
            "Epoch9 | Loss:  0.5156 \n",
            "Epoch9 | Loss:  0.4486 \n",
            "Epoch9 | Loss:  0.5685 \n",
            "Epoch9 | Loss:  0.4388 \n",
            "Epoch9 | Loss:  0.6999 \n",
            "Epoch9 | Loss:  0.6245 \n",
            "Epoch9 | Loss:  0.5549 \n",
            "Epoch9 | Loss:  0.4591 \n",
            "Epoch9 | Loss:  1.0407 \n",
            "Epoch9 | Loss:  0.5076 \n",
            "Epoch9 | Loss:  0.3124 \n",
            "Epoch9 | Loss:  0.4723 \n",
            "Epoch9 | Loss:  0.5561 \n",
            "Epoch9 | Loss:  0.7364 \n",
            "Epoch9 | Loss:  0.4661 \n",
            "Epoch9 | Loss:  0.3454 \n",
            "Epoch9 | Loss:  0.3812 \n",
            "Epoch9 | Loss:  0.3741 \n",
            "Epoch9 | Loss:  0.8396 \n",
            "Epoch9 | Loss:  0.6467 \n",
            "Epoch9 | Loss:  0.3945 \n",
            "Epoch9 | Loss:  0.5950 \n",
            "Epoch9 | Loss:  0.7282 \n",
            "Epoch9 | Loss:  0.3176 \n",
            "Epoch9 | Loss:  0.3433 \n",
            "Epoch9 | Loss:  0.6719 \n",
            "Epoch9 | Loss:  0.8131 \n",
            "Epoch9 | Loss:  0.7418 \n",
            "Epoch9 | Loss:  0.8179 \n",
            "Epoch9 | Loss:  0.8156 \n",
            "Epoch9 | Loss:  0.5369 \n",
            "Epoch9 | Loss:  0.4166 \n",
            "Epoch9 | Loss:  0.6544 \n",
            "Epoch9 | Loss:  0.3492 \n",
            "Epoch9 | Loss:  0.4865 \n",
            "Epoch9 | Loss:  0.3101 \n",
            "Epoch9 | Loss:  0.6687 \n",
            "Epoch9 | Loss:  0.3594 \n",
            "Epoch9 | Loss:  0.5331 \n",
            "Epoch9 | Loss:  0.5686 \n",
            "Epoch9 | Loss:  0.5308 \n",
            "Epoch9 | Loss:  0.6577 \n",
            "Epoch9 | Loss:  0.4958 \n",
            "Epoch9 | Loss:  0.3457 \n",
            "Epoch9 | Loss:  0.2830 \n",
            "Epoch9 | Loss:  0.3470 \n",
            "Epoch9 | Loss:  0.4976 \n",
            "Epoch9 | Loss:  0.2526 \n",
            "Epoch9 | Loss:  0.5707 \n",
            "Epoch9 | Loss:  0.8017 \n",
            "Epoch9 | Loss:  0.4720 \n",
            "Epoch9 | Loss:  0.4300 \n",
            "Epoch9 | Loss:  0.5484 \n",
            "Epoch9 | Loss:  0.4433 \n",
            "Epoch9 | Loss:  0.6247 \n",
            "Epoch9 | Loss:  0.6599 \n",
            "Epoch9 | Loss:  0.5434 \n",
            "Epoch9 | Loss:  0.7876 \n",
            "Epoch9 | Loss:  0.6707 \n",
            "Epoch9 | Loss:  0.4341 \n",
            "Epoch9 | Loss:  0.4888 \n",
            "Epoch9 | Loss:  0.6112 \n",
            "Epoch9 | Loss:  0.3364 \n",
            "Epoch9 | Loss:  0.5141 \n",
            "Epoch9 | Loss:  0.7286 \n",
            "Epoch9 | Loss:  0.7560 \n",
            "Epoch9 | Loss:  0.3743 \n",
            "Epoch9 | Loss:  0.6919 \n",
            "Epoch9 | Loss:  0.3849 \n",
            "Epoch9 | Loss:  0.7283 \n",
            "Epoch9 | Loss:  0.4515 \n",
            "Epoch9 | Loss:  0.5263 \n",
            "Epoch9 | Loss:  0.4926 \n",
            "Epoch9 | Loss:  0.4967 \n",
            "Epoch9 | Loss:  0.3773 \n",
            "Epoch9 | Loss:  0.7414 \n",
            "Epoch9 | Loss:  0.6554 \n",
            "Epoch9 | Loss:  0.5429 \n",
            "Epoch9 | Loss:  0.5830 \n",
            "Epoch9 | Loss:  0.6594 \n",
            "Epoch9 | Loss:  0.8237 \n",
            "Epoch9 | Loss:  0.4691 \n",
            "Epoch9 | Loss:  0.6179 \n",
            "Epoch9 | Loss:  0.3397 \n",
            "Epoch9 | Loss:  0.6933 \n",
            "Epoch9 | Loss:  0.3892 \n",
            "Epoch9 | Loss:  0.3755 \n",
            "Epoch9 | Loss:  0.5214 \n",
            "Epoch9 | Loss:  0.4749 \n",
            "Epoch9 | Loss:  0.5181 \n",
            "Epoch9 | Loss:  0.4253 \n",
            "Epoch9 | Loss:  0.4190 \n",
            "Epoch9 | Loss:  0.2481 \n",
            "Epoch9 | Loss:  0.3367 \n",
            "Epoch9 | Loss:  0.6379 \n",
            "Epoch9 | Loss:  0.3717 \n",
            "Epoch9 | Loss:  0.4484 \n",
            "Epoch9 | Loss:  0.4700 \n",
            "Epoch9 | Loss:  0.3046 \n",
            "Epoch9 | Loss:  0.6510 \n",
            "Epoch9 | Loss:  0.4195 \n",
            "Epoch9 | Loss:  0.5655 \n",
            "Epoch9 | Loss:  0.3451 \n",
            "Epoch9 | Loss:  0.4475 \n",
            "Epoch9 | Loss:  0.4829 \n",
            "Epoch9 | Loss:  0.5161 \n",
            "Epoch9 | Loss:  0.4768 \n",
            "Epoch9 | Loss:  0.3979 \n",
            "Epoch9 | Loss:  0.5573 \n",
            "Epoch9 | Loss:  0.5675 \n",
            "Epoch9 | Loss:  0.5262 \n",
            "Epoch9 | Loss:  0.4560 \n",
            "Epoch9 | Loss:  0.2905 \n",
            "Epoch9 | Loss:  0.3630 \n",
            "Epoch9 | Loss:  0.4717 \n",
            "Epoch9 | Loss:  0.5936 \n",
            "Epoch9 | Loss:  0.3491 \n",
            "Epoch9 | Loss:  0.4800 \n",
            "Epoch9 | Loss:  0.6106 \n",
            "Epoch9 | Loss:  0.5413 \n",
            "Epoch9 | Loss:  0.6612 \n",
            "Epoch9 | Loss:  0.4034 \n",
            "Epoch9 | Loss:  0.7588 \n",
            "Epoch9 | Loss:  0.6891 \n",
            "Epoch9 | Loss:  0.4788 \n",
            "Epoch9 | Loss:  0.6081 \n",
            "Epoch9 | Loss:  0.5481 \n",
            "Epoch9 | Loss:  0.5206 \n",
            "Epoch9 | Loss:  0.3881 \n",
            "Epoch9 | Loss:  0.6298 \n",
            "Epoch9 | Loss:  0.5637 \n",
            "Epoch9 | Loss:  0.3904 \n",
            "Epoch9 | Loss:  0.6312 \n",
            "Epoch9 | Loss:  0.2208 \n",
            "Epoch9 | Loss:  0.4808 \n",
            "Epoch9 | Loss:  0.5320 \n",
            "Epoch9 | Loss:  0.6442 \n",
            "Epoch9 | Loss:  0.6614 \n",
            "Epoch9 | Loss:  0.5152 \n",
            "Epoch9 | Loss:  0.3447 \n",
            "Epoch9 | Loss:  0.6476 \n",
            "Epoch9 | Loss:  0.6619 \n",
            "Epoch9 | Loss:  0.4933 \n",
            "Epoch9 | Loss:  0.6603 \n",
            "Epoch9 | Loss:  0.5728 \n",
            "Epoch9 | Loss:  0.9045 \n",
            "Epoch9 | Loss:  0.8370 \n",
            "Epoch9 | Loss:  0.5246 \n",
            "Epoch9 | Loss:  0.4218 \n",
            "Epoch9 | Loss:  0.4341 \n",
            "Epoch9 | Loss:  0.3949 \n",
            "Epoch9 | Loss:  0.3069 \n",
            "Epoch9 | Loss:  0.7167 \n",
            "Epoch9 | Loss:  0.5849 \n",
            "Epoch9 | Loss:  0.4599 \n",
            "Epoch9 | Loss:  0.5813 \n",
            "Epoch9 | Loss:  0.4117 \n",
            "Epoch9 | Loss:  0.3556 \n",
            "Epoch9 | Loss:  0.4479 \n",
            "Epoch9 | Loss:  0.3693 \n",
            "Epoch9 | Loss:  0.5791 \n",
            "Epoch9 | Loss:  0.2991 \n",
            "Epoch9 | Loss:  0.4674 \n",
            "Epoch9 | Loss:  0.6668 \n",
            "Epoch9 | Loss:  0.3636 \n",
            "Epoch9 | Loss:  0.2963 \n",
            "Epoch9 | Loss:  0.5224 \n",
            "Epoch9 | Loss:  0.4631 \n",
            "Epoch9 | Loss:  0.5007 \n",
            "Epoch9 | Loss:  0.4654 \n",
            "Epoch9 | Loss:  0.3834 \n",
            "Epoch9 | Loss:  0.4697 \n",
            "Epoch9 | Loss:  0.4662 \n",
            "Epoch9 | Loss:  0.4143 \n",
            "Epoch9 | Loss:  0.3791 \n",
            "Epoch9 | Loss:  0.7578 \n",
            "Epoch9 | Loss:  0.8892 \n",
            "Epoch9 | Loss:  0.5350 \n",
            "Epoch9 | Loss:  0.7228 \n",
            "Epoch9 | Loss:  0.4420 \n",
            "Epoch9 | Loss:  0.4303 \n",
            "Epoch9 | Loss:  0.3948 \n",
            "Epoch9 | Loss:  0.5440 \n",
            "Epoch9 | Loss:  0.6046 \n",
            "Epoch9 | Loss:  0.4960 \n",
            "Epoch9 | Loss:  0.3362 \n",
            "Epoch9 | Loss:  0.4500 \n",
            "Epoch9 | Loss:  0.2748 \n",
            "Epoch9 | Loss:  0.3043 \n",
            "Epoch9 | Loss:  0.6187 \n",
            "Epoch9 | Loss:  0.7125 \n",
            "Epoch9 | Loss:  0.7593 \n",
            "Epoch9 | Loss:  0.4078 \n",
            "Epoch9 | Loss:  0.2857 \n",
            "Epoch9 | Loss:  0.5796 \n",
            "Epoch9 | Loss:  0.4706 \n",
            "Epoch9 | Loss:  0.6985 \n",
            "Epoch9 | Loss:  0.6359 \n",
            "Epoch9 | Loss:  0.4749 \n",
            "Epoch9 | Loss:  0.3009 \n",
            "Epoch9 | Loss:  0.4158 \n",
            "Epoch9 | Loss:  0.8159 \n",
            "Epoch9 | Loss:  0.4583 \n",
            "Epoch9 | Loss:  0.5420 \n",
            "Epoch9 | Loss:  0.5734 \n",
            "Epoch9 | Loss:  0.6120 \n",
            "Epoch9 | Loss:  0.3425 \n",
            "Epoch9 | Loss:  0.7193 \n",
            "Epoch9 | Loss:  0.4088 \n",
            "Epoch9 | Loss:  0.5713 \n",
            "Epoch9 | Loss:  0.2873 \n",
            "Epoch9 | Loss:  0.5770 \n",
            "Epoch9 | Loss:  0.4874 \n",
            "Epoch9 | Loss:  0.6736 \n",
            "Epoch9 | Loss:  0.3342 \n",
            "Epoch9 | Loss:  0.7276 \n",
            "Epoch9 | Loss:  0.4942 \n",
            "Epoch9 | Loss:  0.4108 \n",
            "Epoch9 | Loss:  0.5948 \n",
            "Epoch9 | Loss:  0.4729 \n",
            "Epoch9 | Loss:  0.5973 \n",
            "Epoch9 | Loss:  0.6460 \n",
            "Epoch9 | Loss:  0.4652 \n",
            "Epoch9 | Loss:  0.6229 \n",
            "Epoch9 | Loss:  0.3443 \n",
            "Epoch9 | Loss:  0.5071 \n",
            "Epoch9 | Loss:  0.2733 \n",
            "Epoch9 | Loss:  0.5480 \n",
            "Epoch9 | Loss:  0.4952 \n",
            "Epoch9 | Loss:  0.5878 \n",
            "Epoch9 | Loss:  0.3362 \n",
            "Epoch9 | Loss:  0.4332 \n",
            "Epoch9 | Loss:  0.7841 \n",
            "Epoch9 | Loss:  0.6507 \n",
            "Epoch9 | Loss:  0.3167 \n",
            "Epoch9 | Loss:  0.4356 \n",
            "Epoch9 | Loss:  0.3884 \n",
            "Epoch9 | Loss:  0.4344 \n",
            "Epoch9 | Loss:  0.7293 \n",
            "Epoch9 | Loss:  0.4810 \n",
            "Epoch9 | Loss:  0.4685 \n",
            "Epoch9 | Loss:  0.6757 \n",
            "Epoch9 | Loss:  0.5915 \n",
            "Epoch9 | Loss:  0.4482 \n",
            "Epoch9 | Loss:  0.3947 \n",
            "Epoch9 | Loss:  0.6717 \n",
            "Epoch9 | Loss:  0.5341 \n",
            "Epoch9 | Loss:  0.4789 \n",
            "Epoch9 | Loss:  0.5660 \n",
            "Epoch9 | Loss:  0.7151 \n",
            "Epoch9 | Loss:  0.5348 \n",
            "Epoch9 | Loss:  0.6472 \n",
            "Epoch9 | Loss:  0.5935 \n",
            "Epoch9 | Loss:  0.3771 \n",
            "Epoch9 | Loss:  0.8567 \n",
            "Epoch9 | Loss:  0.4018 \n",
            "Epoch9 | Loss:  0.6872 \n",
            "Epoch9 | Loss:  0.8419 \n",
            "Epoch9 | Loss:  0.4755 \n",
            "Epoch9 | Loss:  0.4475 \n",
            "Epoch9 | Loss:  0.4077 \n",
            "Epoch9 | Loss:  0.8736 \n",
            "Epoch9 | Loss:  0.5966 \n",
            "Epoch9 | Loss:  0.3869 \n",
            "Epoch9 | Loss:  0.5215 \n",
            "Epoch9 | Loss:  0.6718 \n",
            "Epoch9 | Loss:  0.5918 \n",
            "Epoch9 | Loss:  0.5104 \n",
            "Epoch9 | Loss:  0.4996 \n",
            "Epoch9 | Loss:  0.5327 \n",
            "Epoch9 | Loss:  0.8447 \n",
            "Epoch9 | Loss:  0.6097 \n",
            "Epoch9 | Loss:  0.5242 \n",
            "Epoch9 | Loss:  0.4635 \n",
            "Epoch9 | Loss:  0.4635 \n",
            "Epoch9 | Loss:  0.2106 \n",
            "Epoch9 | Loss:  0.6970 \n",
            "Epoch9 | Loss:  0.5517 \n",
            "Epoch9 | Loss:  0.6140 \n",
            "Epoch9 | Loss:  0.4035 \n",
            "Epoch9 | Loss:  0.3747 \n",
            "Epoch9 | Loss:  0.6243 \n",
            "Epoch9 | Loss:  0.4407 \n",
            "Epoch9 | Loss:  0.2772 \n",
            "Epoch9 | Loss:  0.8077 \n",
            "Epoch9 | Loss:  0.5269 \n",
            "Epoch9 | Loss:  0.4949 \n",
            "Epoch9 | Loss:  0.4711 \n",
            "Epoch9 | Loss:  0.3796 \n",
            "Epoch9 | Loss:  0.3633 \n",
            "Epoch9 | Loss:  0.4712 \n",
            "Epoch9 | Loss:  0.4907 \n",
            "Epoch9 | Loss:  0.4715 \n",
            "Epoch9 | Loss:  0.4767 \n",
            "Epoch9 | Loss:  0.7209 \n",
            "Epoch9 | Loss:  0.6488 \n",
            "Epoch9 | Loss:  0.7886 \n",
            "Epoch9 | Loss:  0.6304 \n",
            "Epoch9 | Loss:  0.6628 \n",
            "Epoch9 | Loss:  0.7886 \n",
            "Epoch9 | Loss:  0.7113 \n",
            "Epoch9 | Loss:  0.3616 \n",
            "Epoch9 | Loss:  0.4205 \n",
            "Epoch9 | Loss:  0.4382 \n",
            "Epoch9 | Loss:  0.7941 \n",
            "Epoch9 | Loss:  0.3918 \n",
            "Epoch9 | Loss:  0.5623 \n",
            "Epoch9 | Loss:  0.4885 \n",
            "Epoch9 | Loss:  0.5238 \n",
            "Epoch9 | Loss:  0.7352 \n",
            "Epoch9 | Loss:  0.7351 \n",
            "Epoch9 | Loss:  0.7635 \n",
            "Epoch9 | Loss:  0.4524 \n",
            "Epoch9 | Loss:  0.7223 \n",
            "Epoch9 | Loss:  0.5484 \n",
            "Epoch9 | Loss:  0.7577 \n",
            "Epoch9 | Loss:  0.7435 \n",
            "Epoch9 | Loss:  0.7183 \n",
            "Epoch9 | Loss:  0.5176 \n",
            "Epoch9 | Loss:  0.6371 \n",
            "Epoch9 | Loss:  0.5074 \n",
            "Epoch9 | Loss:  0.5727 \n",
            "Epoch9 | Loss:  0.4907 \n",
            "Epoch9 | Loss:  0.6285 \n",
            "Epoch9 | Loss:  0.8301 \n",
            "Epoch9 | Loss:  0.6883 \n",
            "Epoch9 | Loss:  0.6994 \n",
            "Epoch9 | Loss:  0.4397 \n",
            "Epoch9 | Loss:  0.3595 \n",
            "Epoch9 | Loss:  0.3657 \n",
            "Epoch9 | Loss:  0.6528 \n",
            "Epoch9 | Loss:  0.3650 \n",
            "Epoch9 | Loss:  0.5516 \n",
            "Epoch9 | Loss:  0.4753 \n",
            "Epoch9 | Loss:  0.5627 \n",
            "Epoch9 | Loss:  0.8600 \n",
            "Epoch9 | Loss:  0.4205 \n",
            "Epoch9 | Loss:  0.4768 \n",
            "Epoch9 | Loss:  0.4024 \n",
            "Epoch9 | Loss:  0.4726 \n",
            "Epoch9 | Loss:  0.3335 \n",
            "Epoch9 | Loss:  0.3522 \n",
            "Epoch9 | Loss:  0.7210 \n",
            "Epoch9 | Loss:  0.4578 \n",
            "Epoch9 | Loss:  0.3690 \n",
            "Epoch9 | Loss:  0.5701 \n",
            "Epoch9 | Loss:  0.3820 \n",
            "Epoch9 | Loss:  0.2232 \n",
            "Epoch9 | Loss:  0.6171 \n",
            "Epoch9 | Loss:  0.5207 \n",
            "Epoch9 | Loss:  0.6664 \n",
            "Epoch9 | Loss:  0.5509 \n",
            "Epoch9 | Loss:  0.4788 \n",
            "Epoch9 | Loss:  0.5046 \n",
            "Epoch9 | Loss:  0.6640 \n",
            "Epoch9 | Loss:  0.4311 \n",
            "Epoch9 | Loss:  0.4455 \n",
            "Epoch9 | Loss:  1.0352 \n",
            "Epoch9 | Loss:  0.4143 \n",
            "Epoch9 | Loss:  0.5117 \n",
            "Epoch9 | Loss:  0.4857 \n",
            "Epoch9 | Loss:  0.2109 \n",
            "Epoch9 | Loss:  0.4904 \n",
            "Epoch9 | Loss:  0.8299 \n",
            "Epoch9 | Loss:  0.4846 \n",
            "Epoch9 | Loss:  0.4945 \n",
            "Epoch9 | Loss:  0.5061 \n",
            "Epoch9 | Loss:  0.4435 \n",
            "Epoch9 | Loss:  0.5197 \n",
            "Epoch9 | Loss:  0.4209 \n",
            "Epoch9 | Loss:  0.7923 \n",
            "Epoch9 | Loss:  0.5236 \n",
            "Epoch9 | Loss:  0.7250 \n",
            "Epoch9 | Loss:  0.3344 \n",
            "Epoch9 | Loss:  0.4892 \n",
            "Epoch9 | Loss:  0.4333 \n",
            "Epoch9 | Loss:  0.4235 \n",
            "Epoch9 | Loss:  0.5167 \n",
            "Epoch9 | Loss:  0.4521 \n",
            "Epoch9 | Loss:  0.6252 \n",
            "Epoch9 | Loss:  0.5610 \n",
            "Epoch9 | Loss:  0.3984 \n",
            "Epoch9 | Loss:  0.6079 \n",
            "Epoch9 | Loss:  0.3411 \n",
            "Epoch9 | Loss:  0.6425 \n",
            "Epoch9 | Loss:  0.3519 \n",
            "Epoch9 | Loss:  0.5714 \n",
            "Epoch9 | Loss:  0.5288 \n",
            "Epoch9 | Loss:  0.3370 \n",
            "Epoch9 | Loss:  0.5488 \n",
            "Epoch9 | Loss:  0.6646 \n",
            "Epoch9 | Loss:  0.6100 \n",
            "Epoch9 | Loss:  0.7199 \n",
            "Epoch9 | Loss:  0.4345 \n",
            "Epoch9 | Loss:  0.4503 \n",
            "Epoch9 | Loss:  0.4458 \n",
            "Epoch9 | Loss:  0.4733 \n",
            "Epoch9 | Loss:  0.3194 \n",
            "Epoch9 | Loss:  0.6945 \n",
            "Epoch9 | Loss:  0.3154 \n",
            "Epoch9 | Loss:  0.4854 \n",
            "Epoch9 | Loss:  0.5411 \n",
            "Epoch9 | Loss:  0.4950 \n",
            "Epoch9 | Loss:  0.5250 \n",
            "Epoch9 | Loss:  0.2854 \n",
            "Epoch9 | Loss:  0.6101 \n",
            "Epoch9 | Loss:  0.6367 \n",
            "Epoch9 | Loss:  0.8346 \n",
            "Epoch9 | Loss:  0.4431 \n",
            "Epoch9 | Loss:  0.5189 \n",
            "Epoch9 | Loss:  0.5471 \n",
            "Epoch9 | Loss:  0.9270 \n",
            "Epoch9 | Loss:  0.4990 \n",
            "Epoch9 | Loss:  0.4508 \n",
            "Epoch9 | Loss:  0.6522 \n",
            "Epoch9 | Loss:  0.2445 \n",
            "Epoch9 | Loss:  0.2700 \n",
            "Epoch9 | Loss:  0.4193 \n",
            "Epoch9 | Loss:  0.3893 \n",
            "Epoch9 | Loss:  0.3958 \n",
            "Epoch9 | Loss:  0.3992 \n",
            "Epoch9 | Loss:  0.4846 \n",
            "Epoch9 | Loss:  0.4601 \n",
            "Epoch9 | Loss:  0.2822 \n",
            "Epoch9 | Loss:  0.6026 \n",
            "Epoch9 | Loss:  0.5455 \n",
            "Epoch9 | Loss:  0.6276 \n",
            "Epoch9 | Loss:  0.4944 \n",
            "Epoch9 | Loss:  0.7545 \n",
            "Epoch9 | Loss:  0.4690 \n",
            "Epoch9 | Loss:  0.3869 \n",
            "Epoch9 | Loss:  0.4809 \n",
            "Epoch9 | Loss:  0.4609 \n",
            "Epoch9 | Loss:  0.5222 \n",
            "Epoch9 | Loss:  0.6166 \n",
            "Epoch9 | Loss:  0.4319 \n",
            "Epoch9 | Loss:  0.5292 \n",
            "Epoch9 | Loss:  0.3226 \n",
            "Epoch9 | Loss:  0.4379 \n",
            "Epoch9 | Loss:  0.3342 \n",
            "Epoch9 | Loss:  0.5810 \n",
            "Epoch9 | Loss:  0.3689 \n",
            "Epoch9 | Loss:  0.5361 \n",
            "Epoch9 | Loss:  0.6350 \n",
            "Epoch9 | Loss:  0.3693 \n",
            "Epoch9 | Loss:  0.6047 \n",
            "Epoch9 | Loss:  0.4083 \n",
            "Epoch9 | Loss:  0.4571 \n",
            "Epoch9 | Loss:  0.3668 \n",
            "Epoch9 | Loss:  0.3723 \n",
            "Epoch9 | Loss:  0.5185 \n",
            "Epoch9 | Loss:  0.5513 \n",
            "Epoch9 | Loss:  0.4550 \n",
            "Epoch9 | Loss:  0.6015 \n",
            "Epoch9 | Loss:  0.5261 \n",
            "Epoch9 | Loss:  0.4788 \n",
            "Epoch9 | Loss:  0.8741 \n",
            "Epoch9 | Loss:  0.8045 \n",
            "Epoch9 | Loss:  0.4245 \n",
            "Epoch9 | Loss:  0.2729 \n",
            "Epoch9 | Loss:  0.8221 \n",
            "Epoch10 | Loss:  0.5346 \n",
            "Epoch10 | Loss:  0.6693 \n",
            "Epoch10 | Loss:  0.3476 \n",
            "Epoch10 | Loss:  0.3805 \n",
            "Epoch10 | Loss:  0.3056 \n",
            "Epoch10 | Loss:  0.4556 \n",
            "Epoch10 | Loss:  0.5697 \n",
            "Epoch10 | Loss:  0.2969 \n",
            "Epoch10 | Loss:  0.5643 \n",
            "Epoch10 | Loss:  0.7590 \n",
            "Epoch10 | Loss:  0.4872 \n",
            "Epoch10 | Loss:  0.4763 \n",
            "Epoch10 | Loss:  0.2104 \n",
            "Epoch10 | Loss:  0.3064 \n",
            "Epoch10 | Loss:  0.4799 \n",
            "Epoch10 | Loss:  0.4664 \n",
            "Epoch10 | Loss:  0.6106 \n",
            "Epoch10 | Loss:  0.4340 \n",
            "Epoch10 | Loss:  0.4127 \n",
            "Epoch10 | Loss:  0.6604 \n",
            "Epoch10 | Loss:  0.2890 \n",
            "Epoch10 | Loss:  0.6302 \n",
            "Epoch10 | Loss:  0.4649 \n",
            "Epoch10 | Loss:  0.9785 \n",
            "Epoch10 | Loss:  0.4616 \n",
            "Epoch10 | Loss:  0.4835 \n",
            "Epoch10 | Loss:  0.5555 \n",
            "Epoch10 | Loss:  0.5615 \n",
            "Epoch10 | Loss:  0.3719 \n",
            "Epoch10 | Loss:  0.3959 \n",
            "Epoch10 | Loss:  0.5838 \n",
            "Epoch10 | Loss:  0.5028 \n",
            "Epoch10 | Loss:  0.5609 \n",
            "Epoch10 | Loss:  0.6712 \n",
            "Epoch10 | Loss:  0.4124 \n",
            "Epoch10 | Loss:  0.5013 \n",
            "Epoch10 | Loss:  0.6078 \n",
            "Epoch10 | Loss:  0.3613 \n",
            "Epoch10 | Loss:  0.7087 \n",
            "Epoch10 | Loss:  0.4000 \n",
            "Epoch10 | Loss:  0.3188 \n",
            "Epoch10 | Loss:  0.1689 \n",
            "Epoch10 | Loss:  0.5098 \n",
            "Epoch10 | Loss:  0.2716 \n",
            "Epoch10 | Loss:  0.3410 \n",
            "Epoch10 | Loss:  0.3964 \n",
            "Epoch10 | Loss:  0.3574 \n",
            "Epoch10 | Loss:  0.6348 \n",
            "Epoch10 | Loss:  0.4018 \n",
            "Epoch10 | Loss:  0.6976 \n",
            "Epoch10 | Loss:  0.7061 \n",
            "Epoch10 | Loss:  0.4356 \n",
            "Epoch10 | Loss:  0.3435 \n",
            "Epoch10 | Loss:  0.7007 \n",
            "Epoch10 | Loss:  0.4236 \n",
            "Epoch10 | Loss:  0.3048 \n",
            "Epoch10 | Loss:  0.4676 \n",
            "Epoch10 | Loss:  1.0001 \n",
            "Epoch10 | Loss:  0.3267 \n",
            "Epoch10 | Loss:  0.9006 \n",
            "Epoch10 | Loss:  0.3725 \n",
            "Epoch10 | Loss:  0.7183 \n",
            "Epoch10 | Loss:  0.9529 \n",
            "Epoch10 | Loss:  0.5041 \n",
            "Epoch10 | Loss:  0.6644 \n",
            "Epoch10 | Loss:  0.5037 \n",
            "Epoch10 | Loss:  0.5191 \n",
            "Epoch10 | Loss:  0.4563 \n",
            "Epoch10 | Loss:  0.4069 \n",
            "Epoch10 | Loss:  0.5188 \n",
            "Epoch10 | Loss:  0.5982 \n",
            "Epoch10 | Loss:  0.4746 \n",
            "Epoch10 | Loss:  0.5081 \n",
            "Epoch10 | Loss:  0.2689 \n",
            "Epoch10 | Loss:  0.3076 \n",
            "Epoch10 | Loss:  0.4834 \n",
            "Epoch10 | Loss:  0.4897 \n",
            "Epoch10 | Loss:  0.3761 \n",
            "Epoch10 | Loss:  0.3661 \n",
            "Epoch10 | Loss:  0.5404 \n",
            "Epoch10 | Loss:  0.6494 \n",
            "Epoch10 | Loss:  0.5397 \n",
            "Epoch10 | Loss:  0.4963 \n",
            "Epoch10 | Loss:  0.6013 \n",
            "Epoch10 | Loss:  0.4878 \n",
            "Epoch10 | Loss:  0.4482 \n",
            "Epoch10 | Loss:  0.3234 \n",
            "Epoch10 | Loss:  0.4620 \n",
            "Epoch10 | Loss:  0.5300 \n",
            "Epoch10 | Loss:  0.5532 \n",
            "Epoch10 | Loss:  0.7007 \n",
            "Epoch10 | Loss:  0.6408 \n",
            "Epoch10 | Loss:  0.6390 \n",
            "Epoch10 | Loss:  0.5752 \n",
            "Epoch10 | Loss:  0.4526 \n",
            "Epoch10 | Loss:  0.4368 \n",
            "Epoch10 | Loss:  0.8204 \n",
            "Epoch10 | Loss:  0.6246 \n",
            "Epoch10 | Loss:  0.4934 \n",
            "Epoch10 | Loss:  0.3574 \n",
            "Epoch10 | Loss:  0.4859 \n",
            "Epoch10 | Loss:  0.5734 \n",
            "Epoch10 | Loss:  0.4966 \n",
            "Epoch10 | Loss:  0.4453 \n",
            "Epoch10 | Loss:  0.3016 \n",
            "Epoch10 | Loss:  0.4888 \n",
            "Epoch10 | Loss:  0.6561 \n",
            "Epoch10 | Loss:  0.4451 \n",
            "Epoch10 | Loss:  0.4797 \n",
            "Epoch10 | Loss:  0.3724 \n",
            "Epoch10 | Loss:  0.4302 \n",
            "Epoch10 | Loss:  0.7116 \n",
            "Epoch10 | Loss:  0.3553 \n",
            "Epoch10 | Loss:  0.6574 \n",
            "Epoch10 | Loss:  0.5775 \n",
            "Epoch10 | Loss:  0.5194 \n",
            "Epoch10 | Loss:  0.4062 \n",
            "Epoch10 | Loss:  0.5131 \n",
            "Epoch10 | Loss:  0.7028 \n",
            "Epoch10 | Loss:  0.6741 \n",
            "Epoch10 | Loss:  0.6383 \n",
            "Epoch10 | Loss:  0.7857 \n",
            "Epoch10 | Loss:  0.7454 \n",
            "Epoch10 | Loss:  0.3901 \n",
            "Epoch10 | Loss:  1.0046 \n",
            "Epoch10 | Loss:  0.2505 \n",
            "Epoch10 | Loss:  0.6919 \n",
            "Epoch10 | Loss:  0.6097 \n",
            "Epoch10 | Loss:  0.5408 \n",
            "Epoch10 | Loss:  0.4957 \n",
            "Epoch10 | Loss:  0.4286 \n",
            "Epoch10 | Loss:  0.3939 \n",
            "Epoch10 | Loss:  0.3487 \n",
            "Epoch10 | Loss:  0.4206 \n",
            "Epoch10 | Loss:  0.4369 \n",
            "Epoch10 | Loss:  0.6105 \n",
            "Epoch10 | Loss:  0.6120 \n",
            "Epoch10 | Loss:  0.6762 \n",
            "Epoch10 | Loss:  0.8390 \n",
            "Epoch10 | Loss:  0.4350 \n",
            "Epoch10 | Loss:  0.6687 \n",
            "Epoch10 | Loss:  0.6442 \n",
            "Epoch10 | Loss:  0.5083 \n",
            "Epoch10 | Loss:  0.5791 \n",
            "Epoch10 | Loss:  0.5775 \n",
            "Epoch10 | Loss:  0.3255 \n",
            "Epoch10 | Loss:  0.5417 \n",
            "Epoch10 | Loss:  0.7244 \n",
            "Epoch10 | Loss:  0.4391 \n",
            "Epoch10 | Loss:  0.5122 \n",
            "Epoch10 | Loss:  0.6114 \n",
            "Epoch10 | Loss:  0.3950 \n",
            "Epoch10 | Loss:  0.6794 \n",
            "Epoch10 | Loss:  0.4092 \n",
            "Epoch10 | Loss:  0.4551 \n",
            "Epoch10 | Loss:  0.3644 \n",
            "Epoch10 | Loss:  0.2603 \n",
            "Epoch10 | Loss:  0.4921 \n",
            "Epoch10 | Loss:  0.4623 \n",
            "Epoch10 | Loss:  0.6482 \n",
            "Epoch10 | Loss:  0.3797 \n",
            "Epoch10 | Loss:  0.5563 \n",
            "Epoch10 | Loss:  0.2532 \n",
            "Epoch10 | Loss:  0.5152 \n",
            "Epoch10 | Loss:  0.5263 \n",
            "Epoch10 | Loss:  0.2241 \n",
            "Epoch10 | Loss:  0.6822 \n",
            "Epoch10 | Loss:  0.3642 \n",
            "Epoch10 | Loss:  0.5129 \n",
            "Epoch10 | Loss:  0.3940 \n",
            "Epoch10 | Loss:  0.3753 \n",
            "Epoch10 | Loss:  0.6657 \n",
            "Epoch10 | Loss:  0.4239 \n",
            "Epoch10 | Loss:  0.3411 \n",
            "Epoch10 | Loss:  0.3401 \n",
            "Epoch10 | Loss:  0.7014 \n",
            "Epoch10 | Loss:  0.5281 \n",
            "Epoch10 | Loss:  0.4491 \n",
            "Epoch10 | Loss:  0.4641 \n",
            "Epoch10 | Loss:  0.2995 \n",
            "Epoch10 | Loss:  0.6571 \n",
            "Epoch10 | Loss:  0.2947 \n",
            "Epoch10 | Loss:  0.2792 \n",
            "Epoch10 | Loss:  0.8064 \n",
            "Epoch10 | Loss:  0.5690 \n",
            "Epoch10 | Loss:  0.7211 \n",
            "Epoch10 | Loss:  0.5610 \n",
            "Epoch10 | Loss:  0.7725 \n",
            "Epoch10 | Loss:  0.3978 \n",
            "Epoch10 | Loss:  0.6540 \n",
            "Epoch10 | Loss:  0.6511 \n",
            "Epoch10 | Loss:  0.5018 \n",
            "Epoch10 | Loss:  0.8622 \n",
            "Epoch10 | Loss:  0.6865 \n",
            "Epoch10 | Loss:  0.5132 \n",
            "Epoch10 | Loss:  0.4100 \n",
            "Epoch10 | Loss:  0.5030 \n",
            "Epoch10 | Loss:  0.6618 \n",
            "Epoch10 | Loss:  0.6024 \n",
            "Epoch10 | Loss:  0.4467 \n",
            "Epoch10 | Loss:  0.2874 \n",
            "Epoch10 | Loss:  0.4073 \n",
            "Epoch10 | Loss:  0.5798 \n",
            "Epoch10 | Loss:  0.7255 \n",
            "Epoch10 | Loss:  0.4931 \n",
            "Epoch10 | Loss:  0.3637 \n",
            "Epoch10 | Loss:  0.6826 \n",
            "Epoch10 | Loss:  0.3242 \n",
            "Epoch10 | Loss:  0.6315 \n",
            "Epoch10 | Loss:  0.6161 \n",
            "Epoch10 | Loss:  0.4925 \n",
            "Epoch10 | Loss:  0.5337 \n",
            "Epoch10 | Loss:  0.6417 \n",
            "Epoch10 | Loss:  0.4152 \n",
            "Epoch10 | Loss:  0.5801 \n",
            "Epoch10 | Loss:  0.6899 \n",
            "Epoch10 | Loss:  0.4642 \n",
            "Epoch10 | Loss:  0.4096 \n",
            "Epoch10 | Loss:  0.9024 \n",
            "Epoch10 | Loss:  0.7106 \n",
            "Epoch10 | Loss:  0.7647 \n",
            "Epoch10 | Loss:  0.4655 \n",
            "Epoch10 | Loss:  0.3552 \n",
            "Epoch10 | Loss:  0.8441 \n",
            "Epoch10 | Loss:  0.5119 \n",
            "Epoch10 | Loss:  0.4516 \n",
            "Epoch10 | Loss:  0.4689 \n",
            "Epoch10 | Loss:  0.4801 \n",
            "Epoch10 | Loss:  0.6497 \n",
            "Epoch10 | Loss:  0.7496 \n",
            "Epoch10 | Loss:  0.4882 \n",
            "Epoch10 | Loss:  0.3680 \n",
            "Epoch10 | Loss:  0.4480 \n",
            "Epoch10 | Loss:  0.5334 \n",
            "Epoch10 | Loss:  0.4402 \n",
            "Epoch10 | Loss:  0.6139 \n",
            "Epoch10 | Loss:  0.3691 \n",
            "Epoch10 | Loss:  0.4592 \n",
            "Epoch10 | Loss:  0.3560 \n",
            "Epoch10 | Loss:  0.3087 \n",
            "Epoch10 | Loss:  0.4657 \n",
            "Epoch10 | Loss:  0.5118 \n",
            "Epoch10 | Loss:  0.4119 \n",
            "Epoch10 | Loss:  0.4749 \n",
            "Epoch10 | Loss:  0.5203 \n",
            "Epoch10 | Loss:  0.6692 \n",
            "Epoch10 | Loss:  0.4175 \n",
            "Epoch10 | Loss:  0.6149 \n",
            "Epoch10 | Loss:  0.4911 \n",
            "Epoch10 | Loss:  0.2855 \n",
            "Epoch10 | Loss:  0.5927 \n",
            "Epoch10 | Loss:  0.5201 \n",
            "Epoch10 | Loss:  0.6271 \n",
            "Epoch10 | Loss:  0.6566 \n",
            "Epoch10 | Loss:  0.5573 \n",
            "Epoch10 | Loss:  0.4317 \n",
            "Epoch10 | Loss:  0.6369 \n",
            "Epoch10 | Loss:  0.4134 \n",
            "Epoch10 | Loss:  0.4283 \n",
            "Epoch10 | Loss:  0.4580 \n",
            "Epoch10 | Loss:  0.3989 \n",
            "Epoch10 | Loss:  0.3046 \n",
            "Epoch10 | Loss:  0.3845 \n",
            "Epoch10 | Loss:  0.4274 \n",
            "Epoch10 | Loss:  0.3325 \n",
            "Epoch10 | Loss:  0.5899 \n",
            "Epoch10 | Loss:  0.4125 \n",
            "Epoch10 | Loss:  0.8047 \n",
            "Epoch10 | Loss:  0.7502 \n",
            "Epoch10 | Loss:  0.5816 \n",
            "Epoch10 | Loss:  0.5823 \n",
            "Epoch10 | Loss:  0.7240 \n",
            "Epoch10 | Loss:  0.2783 \n",
            "Epoch10 | Loss:  0.3118 \n",
            "Epoch10 | Loss:  0.4883 \n",
            "Epoch10 | Loss:  0.3963 \n",
            "Epoch10 | Loss:  0.6088 \n",
            "Epoch10 | Loss:  0.8791 \n",
            "Epoch10 | Loss:  0.3612 \n",
            "Epoch10 | Loss:  0.5130 \n",
            "Epoch10 | Loss:  0.6725 \n",
            "Epoch10 | Loss:  0.5511 \n",
            "Epoch10 | Loss:  0.4321 \n",
            "Epoch10 | Loss:  0.5473 \n",
            "Epoch10 | Loss:  0.6972 \n",
            "Epoch10 | Loss:  0.4955 \n",
            "Epoch10 | Loss:  0.5274 \n",
            "Epoch10 | Loss:  0.7894 \n",
            "Epoch10 | Loss:  0.6579 \n",
            "Epoch10 | Loss:  0.4886 \n",
            "Epoch10 | Loss:  0.3439 \n",
            "Epoch10 | Loss:  0.4792 \n",
            "Epoch10 | Loss:  0.8719 \n",
            "Epoch10 | Loss:  0.4533 \n",
            "Epoch10 | Loss:  0.5476 \n",
            "Epoch10 | Loss:  0.4466 \n",
            "Epoch10 | Loss:  0.4402 \n",
            "Epoch10 | Loss:  0.3889 \n",
            "Epoch10 | Loss:  0.3088 \n",
            "Epoch10 | Loss:  0.4304 \n",
            "Epoch10 | Loss:  0.3534 \n",
            "Epoch10 | Loss:  0.6798 \n",
            "Epoch10 | Loss:  0.5474 \n",
            "Epoch10 | Loss:  0.2909 \n",
            "Epoch10 | Loss:  0.5020 \n",
            "Epoch10 | Loss:  0.6825 \n",
            "Epoch10 | Loss:  0.4882 \n",
            "Epoch10 | Loss:  0.6476 \n",
            "Epoch10 | Loss:  0.5114 \n",
            "Epoch10 | Loss:  0.3208 \n",
            "Epoch10 | Loss:  0.4765 \n",
            "Epoch10 | Loss:  0.3948 \n",
            "Epoch10 | Loss:  0.4629 \n",
            "Epoch10 | Loss:  0.5399 \n",
            "Epoch10 | Loss:  0.6754 \n",
            "Epoch10 | Loss:  0.3315 \n",
            "Epoch10 | Loss:  0.6032 \n",
            "Epoch10 | Loss:  0.6066 \n",
            "Epoch10 | Loss:  0.4940 \n",
            "Epoch10 | Loss:  0.4937 \n",
            "Epoch10 | Loss:  0.4955 \n",
            "Epoch10 | Loss:  0.4520 \n",
            "Epoch10 | Loss:  0.5289 \n",
            "Epoch10 | Loss:  0.4916 \n",
            "Epoch10 | Loss:  0.5382 \n",
            "Epoch10 | Loss:  0.5293 \n",
            "Epoch10 | Loss:  0.7180 \n",
            "Epoch10 | Loss:  0.3318 \n",
            "Epoch10 | Loss:  0.4678 \n",
            "Epoch10 | Loss:  0.4642 \n",
            "Epoch10 | Loss:  0.4503 \n",
            "Epoch10 | Loss:  0.4888 \n",
            "Epoch10 | Loss:  0.9841 \n",
            "Epoch10 | Loss:  0.2702 \n",
            "Epoch10 | Loss:  0.7187 \n",
            "Epoch10 | Loss:  0.4583 \n",
            "Epoch10 | Loss:  0.4944 \n",
            "Epoch10 | Loss:  0.4548 \n",
            "Epoch10 | Loss:  0.2291 \n",
            "Epoch10 | Loss:  0.4219 \n",
            "Epoch10 | Loss:  0.8543 \n",
            "Epoch10 | Loss:  0.4686 \n",
            "Epoch10 | Loss:  0.6917 \n",
            "Epoch10 | Loss:  0.3925 \n",
            "Epoch10 | Loss:  0.5078 \n",
            "Epoch10 | Loss:  0.6429 \n",
            "Epoch10 | Loss:  0.8244 \n",
            "Epoch10 | Loss:  0.4334 \n",
            "Epoch10 | Loss:  0.5777 \n",
            "Epoch10 | Loss:  0.5176 \n",
            "Epoch10 | Loss:  0.7285 \n",
            "Epoch10 | Loss:  0.3313 \n",
            "Epoch10 | Loss:  0.6003 \n",
            "Epoch10 | Loss:  0.8968 \n",
            "Epoch10 | Loss:  0.7494 \n",
            "Epoch10 | Loss:  0.5374 \n",
            "Epoch10 | Loss:  0.4586 \n",
            "Epoch10 | Loss:  0.5294 \n",
            "Epoch10 | Loss:  0.6342 \n",
            "Epoch10 | Loss:  0.3920 \n",
            "Epoch10 | Loss:  0.4166 \n",
            "Epoch10 | Loss:  0.6439 \n",
            "Epoch10 | Loss:  0.4468 \n",
            "Epoch10 | Loss:  0.3742 \n",
            "Epoch10 | Loss:  0.5192 \n",
            "Epoch10 | Loss:  0.6079 \n",
            "Epoch10 | Loss:  0.5690 \n",
            "Epoch10 | Loss:  0.5991 \n",
            "Epoch10 | Loss:  0.6197 \n",
            "Epoch10 | Loss:  0.4973 \n",
            "Epoch10 | Loss:  0.5054 \n",
            "Epoch10 | Loss:  0.4296 \n",
            "Epoch10 | Loss:  0.3452 \n",
            "Epoch10 | Loss:  0.3071 \n",
            "Epoch10 | Loss:  0.7361 \n",
            "Epoch10 | Loss:  0.7880 \n",
            "Epoch10 | Loss:  0.7671 \n",
            "Epoch10 | Loss:  0.4674 \n",
            "Epoch10 | Loss:  0.4572 \n",
            "Epoch10 | Loss:  0.7239 \n",
            "Epoch10 | Loss:  0.2409 \n",
            "Epoch10 | Loss:  0.5265 \n",
            "Epoch10 | Loss:  0.4277 \n",
            "Epoch10 | Loss:  0.3799 \n",
            "Epoch10 | Loss:  0.5576 \n",
            "Epoch10 | Loss:  0.3205 \n",
            "Epoch10 | Loss:  0.6609 \n",
            "Epoch10 | Loss:  0.5948 \n",
            "Epoch10 | Loss:  0.5939 \n",
            "Epoch10 | Loss:  0.5753 \n",
            "Epoch10 | Loss:  1.0418 \n",
            "Epoch10 | Loss:  0.4901 \n",
            "Epoch10 | Loss:  0.6302 \n",
            "Epoch10 | Loss:  0.4450 \n",
            "Epoch10 | Loss:  0.4016 \n",
            "Epoch10 | Loss:  0.1925 \n",
            "Epoch10 | Loss:  0.4296 \n",
            "Epoch10 | Loss:  0.3846 \n",
            "Epoch10 | Loss:  0.5824 \n",
            "Epoch10 | Loss:  0.4344 \n",
            "Epoch10 | Loss:  0.4985 \n",
            "Epoch10 | Loss:  0.5629 \n",
            "Epoch10 | Loss:  0.4503 \n",
            "Epoch10 | Loss:  0.3439 \n",
            "Epoch10 | Loss:  0.6500 \n",
            "Epoch10 | Loss:  0.5412 \n",
            "Epoch10 | Loss:  0.5187 \n",
            "Epoch10 | Loss:  0.3577 \n",
            "Epoch10 | Loss:  0.6072 \n",
            "Epoch10 | Loss:  0.4519 \n",
            "Epoch10 | Loss:  0.4845 \n",
            "Epoch10 | Loss:  0.4011 \n",
            "Epoch10 | Loss:  0.3682 \n",
            "Epoch10 | Loss:  0.3630 \n",
            "Epoch10 | Loss:  0.5203 \n",
            "Epoch10 | Loss:  0.5972 \n",
            "Epoch10 | Loss:  0.2320 \n",
            "Epoch10 | Loss:  0.4884 \n",
            "Epoch10 | Loss:  0.5815 \n",
            "Epoch10 | Loss:  0.9820 \n",
            "Epoch10 | Loss:  0.5907 \n",
            "Epoch10 | Loss:  0.4077 \n",
            "Epoch10 | Loss:  0.5253 \n",
            "Epoch10 | Loss:  0.5686 \n",
            "Epoch10 | Loss:  0.6384 \n",
            "Epoch10 | Loss:  0.4670 \n",
            "Epoch10 | Loss:  0.5673 \n",
            "Epoch10 | Loss:  0.5828 \n",
            "Epoch10 | Loss:  0.2520 \n",
            "Epoch10 | Loss:  0.5901 \n",
            "Epoch10 | Loss:  0.4372 \n",
            "Epoch10 | Loss:  0.2590 \n",
            "Epoch10 | Loss:  0.4400 \n",
            "Epoch10 | Loss:  0.8258 \n",
            "Epoch10 | Loss:  0.7733 \n",
            "Epoch10 | Loss:  0.4169 \n",
            "Epoch10 | Loss:  0.3221 \n",
            "Epoch10 | Loss:  0.1958 \n",
            "Epoch10 | Loss:  0.5370 \n",
            "Epoch10 | Loss:  0.3363 \n",
            "Epoch10 | Loss:  0.4800 \n",
            "Epoch10 | Loss:  0.4931 \n",
            "Epoch10 | Loss:  0.6912 \n",
            "Epoch10 | Loss:  0.5298 \n",
            "Epoch10 | Loss:  0.4338 \n",
            "Epoch10 | Loss:  0.4145 \n",
            "Epoch10 | Loss:  1.0492 \n",
            "Epoch10 | Loss:  0.4776 \n",
            "Epoch10 | Loss:  0.4670 \n",
            "Epoch10 | Loss:  0.3130 \n",
            "Epoch10 | Loss:  0.7231 \n",
            "Epoch10 | Loss:  0.8783 \n",
            "Epoch10 | Loss:  0.4777 \n",
            "Epoch10 | Loss:  0.3952 \n",
            "Epoch10 | Loss:  0.8032 \n",
            "Epoch10 | Loss:  0.5489 \n",
            "Epoch10 | Loss:  0.5062 \n",
            "Epoch10 | Loss:  0.5146 \n",
            "Epoch10 | Loss:  0.7858 \n",
            "Epoch10 | Loss:  0.4749 \n",
            "Epoch10 | Loss:  0.4309 \n",
            "Epoch10 | Loss:  0.3573 \n",
            "Epoch10 | Loss:  0.4222 \n",
            "Epoch10 | Loss:  0.6387 \n",
            "Epoch10 | Loss:  0.5871 \n",
            "Epoch10 | Loss:  0.6102 \n",
            "Epoch10 | Loss:  0.5026 \n",
            "Epoch10 | Loss:  0.3777 \n",
            "Epoch10 | Loss:  0.1165 \n",
            "Epoch10 | Loss:  0.5110 \n",
            "Epoch10 | Loss:  0.5790 \n",
            "Epoch10 | Loss:  0.7614 \n",
            "Epoch10 | Loss:  0.6805 \n",
            "Epoch10 | Loss:  0.4337 \n",
            "Epoch10 | Loss:  0.4633 \n",
            "Epoch10 | Loss:  0.6174 \n",
            "Epoch10 | Loss:  0.7886 \n",
            "Epoch10 | Loss:  0.4907 \n",
            "Epoch10 | Loss:  0.4164 \n",
            "Epoch10 | Loss:  0.4115 \n",
            "Epoch10 | Loss:  0.4929 \n",
            "Epoch10 | Loss:  0.2845 \n",
            "Epoch10 | Loss:  0.3867 \n",
            "Epoch10 | Loss:  0.4970 \n",
            "Epoch10 | Loss:  0.6630 \n",
            "Epoch10 | Loss:  0.6917 \n",
            "Epoch10 | Loss:  0.2602 \n",
            "Epoch10 | Loss:  0.5671 \n",
            "Epoch10 | Loss:  0.5852 \n",
            "Epoch10 | Loss:  0.6778 \n",
            "Epoch10 | Loss:  0.5216 \n",
            "Epoch10 | Loss:  0.4727 \n",
            "Epoch10 | Loss:  0.5994 \n",
            "Epoch10 | Loss:  0.2750 \n",
            "Epoch10 | Loss:  0.6260 \n",
            "Epoch10 | Loss:  0.4859 \n",
            "Epoch10 | Loss:  0.3967 \n",
            "Epoch10 | Loss:  0.5935 \n",
            "Epoch10 | Loss:  0.8022 \n",
            "Epoch10 | Loss:  0.5191 \n",
            "Epoch10 | Loss:  0.4368 \n",
            "Epoch10 | Loss:  0.3968 \n",
            "Epoch10 | Loss:  0.5611 \n",
            "Epoch10 | Loss:  0.2913 \n",
            "Epoch10 | Loss:  0.5168 \n",
            "Epoch10 | Loss:  0.3809 \n",
            "Epoch10 | Loss:  0.2724 \n",
            "Epoch10 | Loss:  0.4676 \n",
            "Epoch10 | Loss:  0.3285 \n",
            "Epoch10 | Loss:  0.2583 \n",
            "Epoch10 | Loss:  0.4308 \n",
            "Epoch10 | Loss:  0.4734 \n",
            "Epoch10 | Loss:  0.7534 \n",
            "Epoch10 | Loss:  0.5711 \n",
            "Epoch10 | Loss:  0.4727 \n",
            "Epoch10 | Loss:  0.3194 \n",
            "Epoch10 | Loss:  0.4342 \n",
            "Epoch10 | Loss:  0.6865 \n",
            "Epoch10 | Loss:  0.6630 \n",
            "Epoch10 | Loss:  0.4103 \n",
            "Epoch10 | Loss:  0.3804 \n",
            "Epoch10 | Loss:  0.8149 \n",
            "Epoch10 | Loss:  0.6927 \n",
            "Epoch10 | Loss:  0.3039 \n",
            "Epoch10 | Loss:  0.4523 \n",
            "Epoch10 | Loss:  0.5143 \n",
            "Epoch10 | Loss:  0.9456 \n",
            "Epoch10 | Loss:  0.2777 \n",
            "Epoch10 | Loss:  0.4976 \n",
            "Epoch10 | Loss:  0.5293 \n",
            "Epoch10 | Loss:  0.4296 \n",
            "Epoch10 | Loss:  0.6194 \n",
            "Epoch10 | Loss:  0.5260 \n",
            "Epoch10 | Loss:  0.5208 \n",
            "Epoch10 | Loss:  0.2372 \n",
            "Epoch10 | Loss:  0.5360 \n",
            "Epoch10 | Loss:  0.3483 \n",
            "Epoch10 | Loss:  0.5079 \n",
            "Epoch10 | Loss:  0.5926 \n",
            "Epoch10 | Loss:  0.4905 \n",
            "Epoch10 | Loss:  0.5443 \n",
            "Epoch10 | Loss:  0.6095 \n",
            "Epoch10 | Loss:  0.3088 \n",
            "Epoch10 | Loss:  0.6289 \n",
            "Epoch10 | Loss:  0.3827 \n",
            "Epoch10 | Loss:  0.4727 \n",
            "Epoch10 | Loss:  0.5038 \n",
            "Epoch10 | Loss:  0.4436 \n",
            "Epoch10 | Loss:  0.4477 \n",
            "Epoch10 | Loss:  0.6654 \n",
            "Epoch10 | Loss:  0.5220 \n",
            "Epoch10 | Loss:  0.4550 \n",
            "Epoch10 | Loss:  0.4401 \n",
            "Epoch10 | Loss:  0.5652 \n",
            "Epoch10 | Loss:  0.2690 \n",
            "Epoch10 | Loss:  0.5524 \n",
            "Epoch10 | Loss:  0.9373 \n",
            "Epoch10 | Loss:  0.6662 \n",
            "Epoch10 | Loss:  0.4293 \n",
            "Epoch10 | Loss:  0.2877 \n",
            "Epoch10 | Loss:  0.4445 \n",
            "Epoch10 | Loss:  0.5809 \n",
            "Epoch10 | Loss:  0.3142 \n",
            "Epoch10 | Loss:  0.4358 \n",
            "Epoch10 | Loss:  0.4115 \n",
            "Epoch10 | Loss:  0.5333 \n",
            "Epoch10 | Loss:  0.5551 \n",
            "Epoch10 | Loss:  0.9204 \n",
            "Epoch10 | Loss:  0.2730 \n",
            "Epoch10 | Loss:  0.2918 \n",
            "Epoch10 | Loss:  0.5082 \n",
            "Epoch10 | Loss:  0.6574 \n",
            "Epoch10 | Loss:  0.4255 \n",
            "Epoch10 | Loss:  0.4180 \n",
            "Epoch10 | Loss:  0.9598 \n",
            "Epoch10 | Loss:  0.5388 \n",
            "Epoch10 | Loss:  0.2734 \n",
            "Epoch10 | Loss:  0.4300 \n",
            "Epoch10 | Loss:  0.4843 \n",
            "Epoch10 | Loss:  0.7575 \n",
            "Epoch10 | Loss:  0.7813 \n",
            "Epoch10 | Loss:  0.5203 \n",
            "Epoch10 | Loss:  0.4413 \n",
            "Epoch10 | Loss:  0.1672 \n",
            "Epoch10 | Loss:  0.7232 \n",
            "Epoch10 | Loss:  0.5145 \n",
            "Epoch10 | Loss:  0.2553 \n",
            "Epoch10 | Loss:  0.3754 \n",
            "Epoch10 | Loss:  0.2527 \n",
            "Epoch10 | Loss:  0.3883 \n",
            "Epoch10 | Loss:  0.3445 \n",
            "Epoch10 | Loss:  0.5897 \n",
            "Epoch10 | Loss:  0.4894 \n",
            "Epoch10 | Loss:  0.5534 \n",
            "Epoch10 | Loss:  0.5105 \n",
            "Epoch10 | Loss:  0.5608 \n",
            "Epoch10 | Loss:  0.4686 \n",
            "Epoch10 | Loss:  0.5167 \n",
            "Epoch10 | Loss:  0.4608 \n",
            "Epoch10 | Loss:  0.5863 \n",
            "Epoch10 | Loss:  0.6913 \n",
            "Epoch10 | Loss:  0.4407 \n",
            "Epoch10 | Loss:  0.9004 \n",
            "Epoch10 | Loss:  0.4333 \n",
            "Epoch10 | Loss:  0.5747 \n",
            "Epoch10 | Loss:  0.3646 \n",
            "Epoch10 | Loss:  0.5020 \n",
            "Epoch10 | Loss:  0.3616 \n",
            "Epoch10 | Loss:  0.6274 \n",
            "Epoch10 | Loss:  0.4439 \n",
            "Epoch10 | Loss:  0.5905 \n",
            "Epoch10 | Loss:  0.4649 \n",
            "Epoch10 | Loss:  0.4668 \n",
            "Epoch10 | Loss:  0.4990 \n",
            "Epoch10 | Loss:  0.5802 \n",
            "Epoch10 | Loss:  0.4686 \n",
            "Epoch10 | Loss:  0.4579 \n",
            "Epoch10 | Loss:  0.4709 \n",
            "Epoch10 | Loss:  0.3173 \n",
            "Epoch10 | Loss:  0.4524 \n",
            "Epoch10 | Loss:  0.4345 \n",
            "Epoch10 | Loss:  0.3521 \n",
            "Epoch10 | Loss:  0.5122 \n",
            "Epoch10 | Loss:  0.4264 \n",
            "Epoch10 | Loss:  0.3974 \n",
            "Epoch10 | Loss:  0.3630 \n",
            "Epoch10 | Loss:  0.8172 \n",
            "Epoch10 | Loss:  0.4739 \n",
            "Epoch10 | Loss:  0.6856 \n",
            "Epoch10 | Loss:  0.6141 \n",
            "Epoch10 | Loss:  0.8812 \n",
            "Epoch10 | Loss:  0.4178 \n",
            "Epoch10 | Loss:  0.3042 \n",
            "Epoch10 | Loss:  0.3189 \n",
            "Epoch10 | Loss:  0.7094 \n",
            "Epoch10 | Loss:  0.5579 \n",
            "Epoch10 | Loss:  0.7056 \n",
            "Epoch10 | Loss:  0.5706 \n",
            "Epoch10 | Loss:  1.0250 \n",
            "Epoch10 | Loss:  0.3651 \n",
            "Epoch10 | Loss:  0.5111 \n",
            "Epoch10 | Loss:  0.7070 \n",
            "Epoch10 | Loss:  0.7497 \n",
            "Epoch10 | Loss:  0.4607 \n",
            "Epoch10 | Loss:  0.3067 \n",
            "Epoch10 | Loss:  0.3664 \n",
            "Epoch10 | Loss:  0.3899 \n",
            "Epoch10 | Loss:  0.5942 \n",
            "Epoch10 | Loss:  0.5687 \n",
            "Epoch10 | Loss:  0.2315 \n",
            "Epoch10 | Loss:  0.6775 \n",
            "Epoch10 | Loss:  0.6619 \n",
            "Epoch10 | Loss:  0.6353 \n",
            "Epoch10 | Loss:  0.4716 \n",
            "Epoch10 | Loss:  0.7689 \n",
            "Epoch10 | Loss:  0.6474 \n",
            "Epoch10 | Loss:  0.5235 \n",
            "Epoch10 | Loss:  0.5660 \n",
            "Epoch10 | Loss:  0.3699 \n",
            "Epoch10 | Loss:  0.5965 \n",
            "Epoch10 | Loss:  0.4603 \n",
            "Epoch10 | Loss:  0.4099 \n",
            "Epoch10 | Loss:  0.2903 \n",
            "Epoch10 | Loss:  0.8414 \n",
            "Epoch10 | Loss:  0.9389 \n",
            "Epoch10 | Loss:  0.4989 \n",
            "Epoch10 | Loss:  0.2688 \n",
            "Epoch10 | Loss:  0.2382 \n",
            "Epoch10 | Loss:  0.5477 \n",
            "Epoch10 | Loss:  0.3048 \n",
            "Epoch10 | Loss:  0.3493 \n",
            "Epoch10 | Loss:  0.6341 \n",
            "Epoch10 | Loss:  0.4126 \n",
            "Epoch10 | Loss:  0.5596 \n",
            "Epoch10 | Loss:  0.5878 \n",
            "Epoch10 | Loss:  0.3130 \n",
            "Epoch10 | Loss:  0.4284 \n",
            "Epoch10 | Loss:  0.6036 \n",
            "Epoch10 | Loss:  0.3268 \n",
            "Epoch10 | Loss:  0.5554 \n",
            "Epoch10 | Loss:  0.4718 \n",
            "Epoch10 | Loss:  0.4765 \n",
            "Epoch10 | Loss:  0.5488 \n",
            "Epoch10 | Loss:  0.4602 \n",
            "Epoch10 | Loss:  0.4933 \n",
            "Epoch10 | Loss:  0.6054 \n",
            "Epoch10 | Loss:  0.6312 \n",
            "Epoch10 | Loss:  0.5337 \n",
            "Epoch10 | Loss:  0.6470 \n",
            "Epoch10 | Loss:  0.4432 \n",
            "Epoch10 | Loss:  0.4086 \n",
            "Epoch10 | Loss:  0.5905 \n",
            "Epoch10 | Loss:  0.5321 \n",
            "Epoch10 | Loss:  0.5095 \n",
            "Epoch10 | Loss:  0.3353 \n",
            "Epoch10 | Loss:  0.5203 \n",
            "Epoch10 | Loss:  0.5676 \n",
            "Epoch10 | Loss:  0.6622 \n",
            "Epoch10 | Loss:  0.5889 \n",
            "Epoch10 | Loss:  0.4222 \n",
            "Epoch10 | Loss:  0.4679 \n",
            "Epoch10 | Loss:  0.6460 \n",
            "Epoch10 | Loss:  0.5060 \n",
            "Epoch10 | Loss:  0.5157 \n",
            "Epoch10 | Loss:  1.0740 \n",
            "Epoch10 | Loss:  0.2962 \n",
            "Epoch10 | Loss:  0.4039 \n",
            "Epoch10 | Loss:  0.6032 \n",
            "Epoch10 | Loss:  0.6231 \n",
            "Epoch10 | Loss:  0.6416 \n",
            "Epoch10 | Loss:  0.5800 \n",
            "Epoch10 | Loss:  0.3209 \n",
            "Epoch10 | Loss:  0.7919 \n",
            "Epoch10 | Loss:  0.7687 \n",
            "Epoch10 | Loss:  0.5468 \n",
            "Epoch10 | Loss:  0.4983 \n",
            "Epoch10 | Loss:  0.2356 \n",
            "Epoch10 | Loss:  0.6682 \n",
            "Epoch10 | Loss:  0.3579 \n",
            "Epoch10 | Loss:  0.3149 \n",
            "Epoch10 | Loss:  0.3127 \n",
            "Epoch10 | Loss:  0.6662 \n",
            "Epoch10 | Loss:  0.4561 \n",
            "Epoch10 | Loss:  0.3777 \n",
            "Epoch10 | Loss:  0.4415 \n",
            "Epoch10 | Loss:  0.4174 \n",
            "Epoch10 | Loss:  0.4061 \n",
            "Epoch10 | Loss:  0.4383 \n",
            "Epoch10 | Loss:  0.6374 \n",
            "Epoch10 | Loss:  0.9915 \n",
            "Epoch10 | Loss:  0.4263 \n",
            "Epoch10 | Loss:  0.5613 \n",
            "Epoch10 | Loss:  0.7187 \n",
            "Epoch10 | Loss:  0.5607 \n",
            "Epoch10 | Loss:  0.5166 \n",
            "Epoch10 | Loss:  0.5111 \n",
            "Epoch10 | Loss:  0.5987 \n",
            "Epoch10 | Loss:  0.4825 \n",
            "Epoch10 | Loss:  0.4340 \n",
            "Epoch10 | Loss:  0.8667 \n",
            "Epoch10 | Loss:  0.4575 \n",
            "Epoch10 | Loss:  0.5611 \n",
            "Epoch10 | Loss:  0.5865 \n",
            "Epoch10 | Loss:  0.2919 \n",
            "Epoch10 | Loss:  0.5727 \n",
            "Epoch10 | Loss:  0.6802 \n",
            "Epoch10 | Loss:  0.5589 \n",
            "Epoch10 | Loss:  0.6615 \n",
            "Epoch10 | Loss:  0.7546 \n",
            "Epoch10 | Loss:  0.2510 \n",
            "Epoch10 | Loss:  0.5951 \n",
            "Epoch10 | Loss:  0.5514 \n",
            "Epoch10 | Loss:  0.6815 \n",
            "Epoch10 | Loss:  0.4958 \n",
            "Epoch10 | Loss:  0.6522 \n",
            "Epoch10 | Loss:  0.5080 \n",
            "Epoch10 | Loss:  0.5883 \n",
            "Epoch10 | Loss:  0.4256 \n",
            "Epoch10 | Loss:  0.5455 \n",
            "Epoch10 | Loss:  0.6247 \n",
            "Epoch10 | Loss:  0.5854 \n",
            "Epoch10 | Loss:  0.5482 \n",
            "Epoch10 | Loss:  0.6110 \n",
            "Epoch10 | Loss:  0.7073 \n",
            "Epoch10 | Loss:  0.4934 \n",
            "Epoch10 | Loss:  0.3052 \n",
            "Epoch10 | Loss:  0.6957 \n",
            "Epoch10 | Loss:  0.7676 \n",
            "Epoch10 | Loss:  0.4041 \n",
            "Epoch10 | Loss:  0.2601 \n",
            "Epoch10 | Loss:  0.8896 \n",
            "Epoch10 | Loss:  0.6565 \n",
            "Epoch10 | Loss:  0.4990 \n",
            "Epoch10 | Loss:  0.4171 \n",
            "Epoch10 | Loss:  0.3918 \n",
            "Epoch10 | Loss:  0.6502 \n",
            "Epoch10 | Loss:  0.5947 \n",
            "Epoch10 | Loss:  0.6011 \n",
            "Epoch10 | Loss:  0.4191 \n",
            "Epoch10 | Loss:  0.5251 \n",
            "Epoch10 | Loss:  0.5834 \n",
            "Epoch10 | Loss:  0.6162 \n",
            "Epoch10 | Loss:  0.8265 \n",
            "Epoch10 | Loss:  0.7627 \n",
            "Epoch10 | Loss:  0.3418 \n",
            "Epoch10 | Loss:  0.6466 \n",
            "Epoch10 | Loss:  0.6569 \n",
            "Epoch10 | Loss:  0.4255 \n",
            "Epoch10 | Loss:  0.6401 \n",
            "Epoch10 | Loss:  0.5209 \n",
            "Epoch10 | Loss:  0.3902 \n",
            "Epoch10 | Loss:  0.4600 \n",
            "Epoch10 | Loss:  0.4550 \n",
            "Epoch10 | Loss:  0.7068 \n",
            "Epoch10 | Loss:  0.3384 \n",
            "Epoch10 | Loss:  0.6755 \n",
            "Epoch10 | Loss:  0.4336 \n",
            "Epoch10 | Loss:  0.5901 \n",
            "Epoch10 | Loss:  0.3614 \n",
            "Epoch10 | Loss:  0.6966 \n",
            "Epoch10 | Loss:  0.4737 \n",
            "Epoch10 | Loss:  0.1945 \n",
            "Epoch10 | Loss:  0.4012 \n",
            "Epoch10 | Loss:  0.4118 \n",
            "Epoch10 | Loss:  0.8160 \n",
            "Epoch10 | Loss:  0.5250 \n",
            "Epoch10 | Loss:  0.5460 \n",
            "Epoch10 | Loss:  0.4064 \n",
            "Epoch10 | Loss:  0.3851 \n",
            "Epoch10 | Loss:  0.4019 \n",
            "Epoch10 | Loss:  0.4098 \n",
            "Epoch10 | Loss:  0.5611 \n",
            "Epoch10 | Loss:  0.5195 \n",
            "Epoch10 | Loss:  0.6306 \n",
            "Epoch10 | Loss:  0.6556 \n",
            "Epoch10 | Loss:  0.7559 \n",
            "Epoch10 | Loss:  0.4474 \n",
            "Epoch10 | Loss:  0.6690 \n",
            "Epoch10 | Loss:  0.3788 \n",
            "Epoch10 | Loss:  0.3066 \n",
            "Epoch10 | Loss:  0.4965 \n",
            "Epoch10 | Loss:  0.6187 \n",
            "Epoch10 | Loss:  0.3324 \n",
            "Epoch10 | Loss:  0.7316 \n",
            "Epoch10 | Loss:  0.6045 \n",
            "Epoch10 | Loss:  0.5561 \n",
            "Epoch10 | Loss:  0.4452 \n",
            "Epoch10 | Loss:  0.6932 \n",
            "Epoch10 | Loss:  0.2786 \n",
            "Epoch10 | Loss:  0.6243 \n",
            "Epoch10 | Loss:  0.5848 \n",
            "Epoch10 | Loss:  0.4769 \n",
            "Epoch10 | Loss:  0.5135 \n",
            "Epoch10 | Loss:  0.4323 \n",
            "Epoch10 | Loss:  0.4986 \n",
            "Epoch10 | Loss:  0.7628 \n",
            "Epoch10 | Loss:  0.4523 \n",
            "Epoch10 | Loss:  0.5857 \n",
            "Epoch10 | Loss:  0.2629 \n",
            "Epoch10 | Loss:  0.3367 \n",
            "Epoch10 | Loss:  0.6071 \n",
            "Epoch10 | Loss:  0.4335 \n",
            "Epoch10 | Loss:  0.4601 \n",
            "Epoch10 | Loss:  0.3579 \n",
            "Epoch10 | Loss:  0.4652 \n",
            "Epoch10 | Loss:  0.5780 \n",
            "Epoch10 | Loss:  0.2958 \n",
            "Epoch10 | Loss:  0.5532 \n",
            "Epoch10 | Loss:  0.5004 \n",
            "Epoch10 | Loss:  0.5583 \n",
            "Epoch10 | Loss:  0.3571 \n",
            "Epoch10 | Loss:  0.6042 \n",
            "Epoch10 | Loss:  0.2718 \n",
            "Epoch10 | Loss:  0.4249 \n",
            "Epoch10 | Loss:  0.6418 \n",
            "Epoch10 | Loss:  0.3140 \n",
            "Epoch10 | Loss:  0.4010 \n",
            "Epoch10 | Loss:  0.4839 \n",
            "Epoch10 | Loss:  0.3883 \n",
            "Epoch10 | Loss:  0.3721 \n",
            "Epoch10 | Loss:  0.4008 \n",
            "Epoch10 | Loss:  0.4506 \n",
            "Epoch10 | Loss:  0.4570 \n",
            "Epoch10 | Loss:  0.8254 \n",
            "Epoch10 | Loss:  0.4655 \n",
            "Epoch10 | Loss:  0.4147 \n",
            "Epoch10 | Loss:  0.4693 \n",
            "Epoch10 | Loss:  0.9190 \n",
            "Epoch10 | Loss:  0.4829 \n",
            "Epoch10 | Loss:  0.7273 \n",
            "Epoch10 | Loss:  0.5386 \n",
            "Epoch10 | Loss:  0.6433 \n",
            "Epoch10 | Loss:  0.3190 \n",
            "Epoch10 | Loss:  0.2688 \n",
            "Epoch10 | Loss:  0.5515 \n",
            "Epoch10 | Loss:  0.4053 \n",
            "Epoch10 | Loss:  0.3091 \n",
            "Epoch10 | Loss:  0.4573 \n",
            "Epoch10 | Loss:  0.4311 \n",
            "Epoch10 | Loss:  0.5171 \n",
            "Epoch10 | Loss:  0.5202 \n",
            "Epoch10 | Loss:  0.5361 \n",
            "Epoch10 | Loss:  0.4182 \n",
            "Epoch10 | Loss:  0.5647 \n",
            "Epoch10 | Loss:  0.4785 \n",
            "Epoch10 | Loss:  0.5803 \n",
            "Epoch10 | Loss:  0.4977 \n",
            "Epoch10 | Loss:  0.5110 \n",
            "Epoch10 | Loss:  0.5591 \n",
            "Epoch10 | Loss:  0.5024 \n",
            "Epoch10 | Loss:  0.4043 \n",
            "Epoch10 | Loss:  0.7182 \n",
            "Epoch10 | Loss:  0.5912 \n",
            "Epoch10 | Loss:  0.3387 \n",
            "Epoch10 | Loss:  0.3850 \n",
            "Epoch10 | Loss:  0.4646 \n",
            "Epoch10 | Loss:  0.5126 \n",
            "Epoch10 | Loss:  0.2653 \n",
            "Epoch10 | Loss:  0.6434 \n",
            "Epoch10 | Loss:  0.6445 \n",
            "Epoch10 | Loss:  0.6034 \n",
            "Epoch10 | Loss:  0.5434 \n",
            "Epoch10 | Loss:  0.5948 \n",
            "Epoch10 | Loss:  0.4018 \n",
            "Epoch10 | Loss:  0.5089 \n",
            "Epoch10 | Loss:  0.6513 \n",
            "Epoch10 | Loss:  0.5586 \n",
            "Epoch10 | Loss:  0.3545 \n",
            "Epoch10 | Loss:  0.7295 \n",
            "Epoch10 | Loss:  0.7252 \n",
            "Epoch10 | Loss:  0.4354 \n",
            "Epoch10 | Loss:  0.6276 \n",
            "Epoch10 | Loss:  0.8463 \n",
            "Epoch10 | Loss:  0.7321 \n",
            "Epoch10 | Loss:  0.4710 \n",
            "Epoch10 | Loss:  0.4750 \n",
            "Epoch10 | Loss:  0.3451 \n",
            "Epoch10 | Loss:  0.8072 \n",
            "Epoch10 | Loss:  0.5730 \n",
            "Epoch10 | Loss:  0.3533 \n",
            "Epoch10 | Loss:  0.4649 \n",
            "Epoch10 | Loss:  0.7203 \n",
            "Epoch10 | Loss:  0.5886 \n",
            "Epoch10 | Loss:  0.4260 \n",
            "Epoch10 | Loss:  0.6331 \n",
            "Epoch10 | Loss:  0.3454 \n",
            "Epoch10 | Loss:  0.4888 \n",
            "Epoch10 | Loss:  0.5671 \n",
            "Epoch10 | Loss:  0.3175 \n",
            "Epoch10 | Loss:  0.5414 \n",
            "Epoch10 | Loss:  0.3986 \n",
            "Epoch10 | Loss:  0.7578 \n",
            "Epoch10 | Loss:  0.6319 \n",
            "Epoch10 | Loss:  0.8345 \n",
            "Epoch10 | Loss:  0.4242 \n",
            "Epoch10 | Loss:  0.3737 \n",
            "Epoch10 | Loss:  0.4601 \n",
            "Epoch10 | Loss:  0.5001 \n",
            "Epoch10 | Loss:  0.5714 \n",
            "Epoch10 | Loss:  0.3666 \n",
            "Epoch10 | Loss:  0.4901 \n",
            "Epoch10 | Loss:  0.4726 \n",
            "Epoch10 | Loss:  0.5850 \n",
            "Epoch10 | Loss:  0.4132 \n",
            "Epoch10 | Loss:  0.1945 \n",
            "Epoch10 | Loss:  0.4660 \n",
            "Epoch10 | Loss:  0.3133 \n",
            "Epoch10 | Loss:  0.5966 \n",
            "Epoch10 | Loss:  0.4322 \n",
            "Epoch10 | Loss:  0.5441 \n",
            "Epoch10 | Loss:  0.5469 \n",
            "Epoch10 | Loss:  0.4785 \n",
            "Epoch10 | Loss:  0.4946 \n",
            "Epoch10 | Loss:  0.6551 \n",
            "Epoch10 | Loss:  0.6875 \n",
            "Epoch10 | Loss:  0.6485 \n",
            "Epoch10 | Loss:  0.3214 \n",
            "Epoch10 | Loss:  0.7003 \n",
            "Epoch10 | Loss:  0.4285 \n",
            "Epoch10 | Loss:  0.4887 \n",
            "Epoch10 | Loss:  0.3749 \n",
            "Epoch10 | Loss:  0.3892 \n",
            "Epoch10 | Loss:  0.6273 \n",
            "Epoch10 | Loss:  0.5578 \n",
            "Epoch10 | Loss:  0.6604 \n",
            "Epoch10 | Loss:  0.4883 \n",
            "Epoch10 | Loss:  0.4308 \n",
            "Epoch10 | Loss:  0.3941 \n",
            "Epoch10 | Loss:  0.4277 \n",
            "Epoch10 | Loss:  0.7157 \n",
            "Epoch10 | Loss:  0.7720 \n",
            "Epoch10 | Loss:  0.4453 \n",
            "Epoch10 | Loss:  0.6714 \n",
            "Epoch10 | Loss:  0.4701 \n",
            "Epoch10 | Loss:  0.2660 \n",
            "Epoch10 | Loss:  0.6138 \n",
            "Epoch10 | Loss:  0.3968 \n",
            "Epoch10 | Loss:  0.5657 \n",
            "Epoch10 | Loss:  0.7764 \n",
            "Epoch10 | Loss:  0.5518 \n",
            "Epoch10 | Loss:  0.7158 \n",
            "Epoch10 | Loss:  0.2409 \n",
            "Epoch10 | Loss:  0.6842 \n",
            "Epoch10 | Loss:  0.4840 \n",
            "Epoch10 | Loss:  0.5060 \n",
            "Epoch10 | Loss:  0.4566 \n",
            "Epoch10 | Loss:  0.6024 \n",
            "Epoch10 | Loss:  0.5715 \n",
            "Epoch10 | Loss:  0.5753 \n",
            "Epoch10 | Loss:  0.4365 \n",
            "Epoch10 | Loss:  0.5918 \n",
            "Epoch10 | Loss:  0.7901 \n",
            "Epoch10 | Loss:  0.3290 \n",
            "Epoch10 | Loss:  0.4048 \n",
            "Epoch10 | Loss:  0.4384 \n",
            "Epoch10 | Loss:  0.9522 \n",
            "Epoch10 | Loss:  0.3910 \n",
            "Epoch10 | Loss:  0.4544 \n",
            "Epoch10 | Loss:  0.6139 \n",
            "Epoch10 | Loss:  0.4548 \n",
            "Epoch10 | Loss:  0.6165 \n",
            "Epoch10 | Loss:  0.6480 \n",
            "Epoch10 | Loss:  0.5273 \n",
            "Epoch10 | Loss:  0.5368 \n",
            "Epoch10 | Loss:  0.5027 \n",
            "Epoch10 | Loss:  0.5495 \n",
            "Epoch10 | Loss:  0.5296 \n",
            "Epoch10 | Loss:  0.7707 \n",
            "Epoch10 | Loss:  0.3464 \n",
            "Epoch10 | Loss:  0.4835 \n",
            "Epoch10 | Loss:  0.3573 \n",
            "Epoch10 | Loss:  0.4587 \n",
            "Epoch10 | Loss:  0.3375 \n",
            "Epoch10 | Loss:  0.4527 \n",
            "Epoch10 | Loss:  0.4098 \n",
            "Epoch10 | Loss:  0.3585 \n",
            "Epoch10 | Loss:  0.6384 \n",
            "Epoch10 | Loss:  0.3651 \n",
            "Epoch10 | Loss:  0.4926 \n",
            "Epoch10 | Loss:  0.4180 \n",
            "Epoch10 | Loss:  0.6371 \n",
            "Epoch10 | Loss:  0.5855 \n",
            "Epoch10 | Loss:  0.5363 \n",
            "Epoch10 | Loss:  0.5604 \n",
            "Epoch10 | Loss:  0.6436 \n",
            "Epoch10 | Loss:  0.3749 \n",
            "Epoch10 | Loss:  0.4749 \n",
            "Epoch10 | Loss:  0.5604 \n",
            "Epoch10 | Loss:  0.5269 \n",
            "Epoch10 | Loss:  0.8114 \n",
            "Epoch10 | Loss:  0.6568 \n",
            "Epoch10 | Loss:  0.3047 \n",
            "Epoch10 | Loss:  0.6939 \n",
            "Epoch10 | Loss:  0.5667 \n",
            "Epoch10 | Loss:  0.4480 \n",
            "Epoch10 | Loss:  0.4686 \n",
            "Epoch10 | Loss:  0.3701 \n",
            "Epoch10 | Loss:  0.2732 \n",
            "Epoch10 | Loss:  0.4807 \n",
            "Epoch10 | Loss:  0.5490 \n",
            "Epoch10 | Loss:  0.4075 \n",
            "Epoch10 | Loss:  0.5263 \n",
            "Epoch10 | Loss:  0.5302 \n",
            "Epoch10 | Loss:  0.3767 \n",
            "Epoch10 | Loss:  0.5585 \n",
            "Epoch10 | Loss:  0.4920 \n",
            "Epoch10 | Loss:  0.3382 \n",
            "Epoch10 | Loss:  0.4428 \n",
            "Epoch10 | Loss:  0.6049 \n",
            "Epoch10 | Loss:  0.9464 \n",
            "Epoch10 | Loss:  0.3247 \n",
            "Epoch10 | Loss:  0.4542 \n",
            "Epoch10 | Loss:  0.6913 \n",
            "Epoch10 | Loss:  0.6183 \n",
            "Epoch10 | Loss:  0.4587 \n",
            "Epoch10 | Loss:  0.7959 \n",
            "Epoch10 | Loss:  0.3230 \n",
            "Epoch10 | Loss:  0.3404 \n",
            "Epoch10 | Loss:  0.5612 \n",
            "Epoch10 | Loss:  0.3287 \n",
            "Epoch10 | Loss:  0.4672 \n",
            "Epoch10 | Loss:  0.6558 \n",
            "Epoch10 | Loss:  0.3761 \n",
            "Epoch10 | Loss:  0.3956 \n",
            "Epoch10 | Loss:  0.7769 \n",
            "Epoch10 | Loss:  0.5753 \n",
            "Epoch10 | Loss:  0.7556 \n",
            "Epoch10 | Loss:  0.5787 \n",
            "Epoch10 | Loss:  0.7140 \n",
            "Epoch10 | Loss:  0.3900 \n",
            "Epoch10 | Loss:  0.9109 \n",
            "Epoch10 | Loss:  0.4184 \n",
            "Epoch10 | Loss:  0.3524 \n",
            "Epoch10 | Loss:  0.5994 \n",
            "Epoch10 | Loss:  0.3535 \n",
            "Epoch10 | Loss:  0.6028 \n",
            "Epoch10 | Loss:  0.6016 \n",
            "Epoch10 | Loss:  0.5908 \n",
            "Epoch10 | Loss:  0.4005 \n",
            "Epoch10 | Loss:  0.6246 \n",
            "Epoch10 | Loss:  0.3760 \n",
            "Epoch10 | Loss:  0.8566 \n",
            "Epoch10 | Loss:  0.2619 \n",
            "Epoch10 | Loss:  0.3229 \n",
            "Epoch10 | Loss:  0.7925 \n",
            "Epoch10 | Loss:  0.6531 \n",
            "Epoch10 | Loss:  0.6156 \n",
            "Epoch10 | Loss:  0.5929 \n",
            "Epoch10 | Loss:  0.5075 \n",
            "Epoch10 | Loss:  0.5467 \n",
            "Epoch10 | Loss:  0.3142 \n",
            "Epoch10 | Loss:  0.3188 \n",
            "Epoch10 | Loss:  0.7101 \n",
            "Epoch10 | Loss:  0.5187 \n",
            "Epoch10 | Loss:  0.2177 \n",
            "Epoch10 | Loss:  0.3748 \n",
            "Epoch10 | Loss:  0.4757 \n",
            "Epoch10 | Loss:  0.5009 \n",
            "Epoch10 | Loss:  0.5876 \n",
            "Epoch10 | Loss:  0.5675 \n",
            "Epoch10 | Loss:  0.4445 \n",
            "Epoch10 | Loss:  0.5248 \n",
            "Epoch10 | Loss:  0.7982 \n",
            "Epoch10 | Loss:  0.5501 \n",
            "Epoch10 | Loss:  0.5524 \n",
            "Epoch10 | Loss:  0.4712 \n",
            "Epoch10 | Loss:  0.7176 \n",
            "Epoch10 | Loss:  0.3716 \n",
            "Epoch10 | Loss:  0.7289 \n",
            "Epoch10 | Loss:  0.3694 \n",
            "Epoch10 | Loss:  0.5009 \n",
            "Epoch10 | Loss:  0.3639 \n",
            "Epoch10 | Loss:  0.4483 \n",
            "Epoch10 | Loss:  1.0018 \n",
            "Epoch10 | Loss:  0.4047 \n",
            "Epoch10 | Loss:  0.7050 \n",
            "Epoch10 | Loss:  0.5564 \n",
            "Epoch10 | Loss:  0.5366 \n",
            "Epoch10 | Loss:  0.5557 \n",
            "Epoch10 | Loss:  0.5358 \n",
            "Epoch10 | Loss:  0.5880 \n",
            "Epoch10 | Loss:  0.6351 \n",
            "Epoch10 | Loss:  0.5521 \n",
            "Epoch10 | Loss:  0.4898 \n",
            "Epoch10 | Loss:  0.8433 \n",
            "Epoch10 | Loss:  0.5763 \n",
            "Epoch10 | Loss:  0.5435 \n",
            "Epoch10 | Loss:  0.3814 \n",
            "Epoch10 | Loss:  0.4109 \n",
            "Epoch10 | Loss:  0.4131 \n",
            "Epoch10 | Loss:  0.7044 \n",
            "Epoch10 | Loss:  0.3579 \n",
            "Epoch10 | Loss:  0.4942 \n",
            "Epoch10 | Loss:  0.5250 \n",
            "Epoch10 | Loss:  0.6038 \n",
            "Epoch10 | Loss:  0.4165 \n",
            "Epoch10 | Loss:  0.3030 \n",
            "Epoch10 | Loss:  0.4605 \n",
            "Epoch10 | Loss:  0.3781 \n",
            "Epoch10 | Loss:  0.4097 \n",
            "Epoch10 | Loss:  0.3074 \n",
            "Epoch10 | Loss:  0.7215 \n",
            "Epoch10 | Loss:  0.4659 \n",
            "Epoch10 | Loss:  0.2824 \n",
            "Epoch10 | Loss:  0.6516 \n",
            "Epoch10 | Loss:  0.3542 \n",
            "Epoch10 | Loss:  0.6408 \n",
            "Epoch10 | Loss:  0.3843 \n",
            "Epoch10 | Loss:  0.6738 \n",
            "Epoch10 | Loss:  0.3533 \n",
            "Epoch10 | Loss:  0.8680 \n",
            "Epoch10 | Loss:  0.7009 \n",
            "Epoch10 | Loss:  0.5023 \n",
            "Epoch10 | Loss:  0.3499 \n",
            "Epoch10 | Loss:  0.8373 \n",
            "Epoch10 | Loss:  0.8624 \n",
            "Epoch10 | Loss:  0.2323 \n",
            "Epoch10 | Loss:  0.6867 \n",
            "Epoch10 | Loss:  0.4676 \n",
            "Epoch10 | Loss:  0.4559 \n",
            "Epoch10 | Loss:  0.5149 \n",
            "Epoch10 | Loss:  0.6568 \n",
            "Epoch10 | Loss:  0.2951 \n",
            "Epoch10 | Loss:  0.3336 \n",
            "Epoch10 | Loss:  0.4185 \n",
            "Epoch10 | Loss:  0.4034 \n",
            "Epoch10 | Loss:  0.5717 \n",
            "Epoch10 | Loss:  0.3695 \n",
            "Epoch10 | Loss:  0.6391 \n",
            "Epoch10 | Loss:  0.5883 \n",
            "Epoch10 | Loss:  0.5396 \n",
            "Epoch10 | Loss:  0.7901 \n",
            "Epoch10 | Loss:  0.3674 \n",
            "Epoch10 | Loss:  0.5232 \n",
            "Epoch10 | Loss:  0.5851 \n",
            "Epoch10 | Loss:  0.5154 \n",
            "Epoch10 | Loss:  0.7236 \n",
            "Epoch10 | Loss:  0.7432 \n",
            "Epoch10 | Loss:  0.2956 \n",
            "Epoch10 | Loss:  0.5928 \n",
            "Epoch10 | Loss:  0.6252 \n",
            "Epoch10 | Loss:  0.3530 \n",
            "Epoch10 | Loss:  0.4671 \n",
            "Epoch10 | Loss:  0.3978 \n",
            "Epoch10 | Loss:  0.4275 \n",
            "Epoch10 | Loss:  0.5785 \n",
            "Epoch10 | Loss:  0.6120 \n",
            "Epoch10 | Loss:  0.8415 \n",
            "Epoch10 | Loss:  0.3979 \n",
            "Epoch10 | Loss:  0.5046 \n",
            "Epoch10 | Loss:  0.3154 \n",
            "Epoch10 | Loss:  0.5678 \n",
            "Epoch10 | Loss:  0.6675 \n",
            "Epoch10 | Loss:  0.3292 \n",
            "Epoch10 | Loss:  0.9010 \n",
            "Epoch10 | Loss:  0.4128 \n",
            "Epoch10 | Loss:  0.4107 \n",
            "Epoch10 | Loss:  0.4763 \n",
            "Epoch10 | Loss:  0.3465 \n",
            "Epoch10 | Loss:  0.5625 \n",
            "Epoch10 | Loss:  0.3836 \n",
            "Epoch10 | Loss:  0.6570 \n",
            "Epoch10 | Loss:  0.4030 \n",
            "Epoch10 | Loss:  0.8778 \n",
            "Epoch10 | Loss:  0.6304 \n",
            "Epoch10 | Loss:  0.4497 \n",
            "Epoch10 | Loss:  0.4864 \n",
            "Epoch10 | Loss:  0.4510 \n",
            "Epoch10 | Loss:  0.5881 \n",
            "Epoch10 | Loss:  0.8571 \n",
            "Epoch10 | Loss:  0.4249 \n",
            "Epoch10 | Loss:  0.2286 \n",
            "Epoch10 | Loss:  0.4648 \n",
            "Epoch10 | Loss:  0.6328 \n",
            "Epoch10 | Loss:  0.7981 \n",
            "Epoch10 | Loss:  0.7308 \n",
            "Epoch10 | Loss:  0.3740 \n",
            "Epoch10 | Loss:  0.8192 \n",
            "Epoch10 | Loss:  0.4001 \n",
            "Epoch10 | Loss:  0.4158 \n",
            "Epoch10 | Loss:  0.6372 \n",
            "Epoch10 | Loss:  0.7909 \n",
            "Epoch10 | Loss:  0.8571 \n",
            "Epoch10 | Loss:  0.6738 \n",
            "Epoch10 | Loss:  0.6223 \n",
            "Epoch10 | Loss:  0.7372 \n",
            "Epoch10 | Loss:  0.3443 \n",
            "Epoch10 | Loss:  0.7935 \n",
            "Epoch10 | Loss:  0.4516 \n",
            "Epoch10 | Loss:  0.7477 \n",
            "Epoch10 | Loss:  0.4344 \n",
            "Epoch10 | Loss:  0.5950 \n",
            "Epoch10 | Loss:  0.5683 \n",
            "Epoch10 | Loss:  0.5337 \n",
            "Epoch10 | Loss:  0.5057 \n",
            "Epoch10 | Loss:  0.6503 \n",
            "Epoch10 | Loss:  0.3533 \n",
            "Epoch10 | Loss:  0.3468 \n",
            "Epoch10 | Loss:  0.3809 \n",
            "Epoch10 | Loss:  0.5460 \n",
            "Epoch10 | Loss:  0.4484 \n",
            "Epoch10 | Loss:  0.5537 \n",
            "Epoch10 | Loss:  0.4501 \n",
            "Epoch10 | Loss:  0.5707 \n",
            "Epoch10 | Loss:  0.3620 \n",
            "Epoch10 | Loss:  0.6367 \n",
            "Epoch10 | Loss:  0.7801 \n",
            "Epoch10 | Loss:  0.3890 \n",
            "Epoch10 | Loss:  0.5590 \n",
            "Epoch10 | Loss:  0.5036 \n",
            "Epoch10 | Loss:  0.5287 \n",
            "Epoch10 | Loss:  0.5438 \n",
            "Epoch10 | Loss:  0.4955 \n",
            "Epoch10 | Loss:  0.4604 \n",
            "Epoch10 | Loss:  0.2808 \n",
            "Epoch10 | Loss:  0.2911 \n",
            "Epoch10 | Loss:  0.7253 \n",
            "Epoch10 | Loss:  0.5000 \n",
            "Epoch10 | Loss:  0.2621 \n",
            "Epoch10 | Loss:  0.6457 \n",
            "Epoch10 | Loss:  0.4421 \n",
            "Epoch10 | Loss:  0.6622 \n",
            "Epoch10 | Loss:  0.9766 \n",
            "Epoch10 | Loss:  0.3889 \n",
            "Epoch10 | Loss:  0.4800 \n",
            "Epoch10 | Loss:  0.3410 \n",
            "Epoch10 | Loss:  0.4876 \n",
            "Epoch10 | Loss:  0.3559 \n",
            "Epoch10 | Loss:  0.6087 \n",
            "Epoch10 | Loss:  0.5391 \n",
            "Epoch10 | Loss:  0.2826 \n",
            "Epoch10 | Loss:  0.5092 \n",
            "Epoch10 | Loss:  0.6177 \n",
            "Epoch10 | Loss:  0.4229 \n",
            "Epoch10 | Loss:  0.4448 \n",
            "Epoch10 | Loss:  0.3259 \n",
            "Epoch10 | Loss:  0.8744 \n",
            "Epoch10 | Loss:  0.3958 \n",
            "Epoch10 | Loss:  0.3799 \n",
            "Epoch10 | Loss:  0.4124 \n",
            "Epoch10 | Loss:  0.3257 \n",
            "Epoch10 | Loss:  0.4297 \n",
            "Epoch10 | Loss:  0.4175 \n",
            "Epoch10 | Loss:  0.4578 \n",
            "Epoch10 | Loss:  0.1911 \n",
            "Epoch10 | Loss:  0.4595 \n",
            "Epoch10 | Loss:  0.3002 \n",
            "Epoch10 | Loss:  0.2878 \n",
            "Epoch10 | Loss:  0.9108 \n",
            "Epoch10 | Loss:  0.5201 \n",
            "Epoch10 | Loss:  0.2076 \n",
            "Epoch10 | Loss:  0.5854 \n",
            "Epoch10 | Loss:  0.6969 \n",
            "Epoch10 | Loss:  0.4194 \n",
            "Epoch10 | Loss:  0.4188 \n",
            "Epoch10 | Loss:  0.4224 \n",
            "Epoch10 | Loss:  0.4448 \n",
            "Epoch10 | Loss:  0.4873 \n",
            "Epoch10 | Loss:  0.6555 \n",
            "Epoch10 | Loss:  0.4422 \n",
            "Epoch10 | Loss:  0.5829 \n",
            "Epoch10 | Loss:  0.6339 \n",
            "Epoch10 | Loss:  0.4821 \n",
            "Epoch10 | Loss:  0.2984 \n",
            "Epoch10 | Loss:  0.4199 \n",
            "Epoch10 | Loss:  0.5643 \n",
            "Epoch10 | Loss:  0.4656 \n",
            "Epoch10 | Loss:  0.4668 \n",
            "Epoch10 | Loss:  0.3962 \n",
            "Epoch10 | Loss:  0.6603 \n",
            "Epoch10 | Loss:  0.4419 \n",
            "Epoch10 | Loss:  0.6647 \n",
            "Epoch10 | Loss:  0.5908 \n",
            "Epoch10 | Loss:  0.2686 \n",
            "Epoch10 | Loss:  0.3840 \n",
            "Epoch10 | Loss:  0.7577 \n",
            "Epoch10 | Loss:  0.4953 \n",
            "Epoch10 | Loss:  0.5748 \n",
            "Epoch10 | Loss:  0.3181 \n",
            "Epoch10 | Loss:  0.5622 \n",
            "Epoch10 | Loss:  0.4428 \n",
            "Epoch10 | Loss:  0.6940 \n",
            "Epoch10 | Loss:  0.7586 \n",
            "Epoch10 | Loss:  0.7923 \n",
            "Epoch10 | Loss:  0.4342 \n",
            "Epoch10 | Loss:  0.4364 \n",
            "Epoch10 | Loss:  0.6029 \n",
            "Epoch10 | Loss:  0.2573 \n",
            "Epoch10 | Loss:  0.5953 \n",
            "Epoch10 | Loss:  1.0296 \n",
            "Epoch10 | Loss:  0.3360 \n",
            "Epoch10 | Loss:  0.5027 \n",
            "Epoch10 | Loss:  0.5705 \n",
            "Epoch10 | Loss:  0.7543 \n",
            "Epoch10 | Loss:  0.6368 \n",
            "Epoch10 | Loss:  0.4725 \n",
            "Epoch10 | Loss:  0.5759 \n",
            "Epoch10 | Loss:  0.7011 \n",
            "Epoch10 | Loss:  0.7506 \n",
            "Epoch10 | Loss:  0.5831 \n",
            "Epoch10 | Loss:  0.2818 \n",
            "Epoch10 | Loss:  0.4724 \n",
            "Epoch10 | Loss:  0.5408 \n",
            "Epoch10 | Loss:  0.6038 \n",
            "Epoch10 | Loss:  0.5353 \n",
            "Epoch10 | Loss:  0.6559 \n",
            "Epoch10 | Loss:  0.3804 \n",
            "Epoch10 | Loss:  0.3456 \n",
            "Epoch10 | Loss:  0.4733 \n",
            "Epoch10 | Loss:  0.1933 \n",
            "Epoch10 | Loss:  0.4012 \n",
            "Epoch10 | Loss:  0.3542 \n",
            "Epoch10 | Loss:  0.4993 \n",
            "Epoch10 | Loss:  0.4631 \n",
            "Epoch10 | Loss:  0.6051 \n",
            "Epoch10 | Loss:  0.5319 \n",
            "Epoch10 | Loss:  0.7963 \n",
            "Epoch10 | Loss:  0.5853 \n",
            "Epoch10 | Loss:  0.3724 \n",
            "Epoch10 | Loss:  0.3173 \n",
            "Epoch10 | Loss:  0.5071 \n",
            "Epoch10 | Loss:  0.6689 \n",
            "Epoch10 | Loss:  0.3689 \n",
            "Epoch10 | Loss:  0.3848 \n",
            "Epoch10 | Loss:  0.3936 \n",
            "Epoch10 | Loss:  0.7549 \n",
            "Epoch10 | Loss:  0.8137 \n",
            "Epoch10 | Loss:  1.0058 \n",
            "Epoch10 | Loss:  0.6262 \n",
            "Epoch10 | Loss:  0.3628 \n",
            "Epoch10 | Loss:  0.1833 \n",
            "Epoch10 | Loss:  0.6604 \n",
            "Epoch10 | Loss:  0.5877 \n",
            "Epoch10 | Loss:  0.3462 \n",
            "Epoch10 | Loss:  0.5871 \n",
            "Epoch10 | Loss:  0.2755 \n",
            "Epoch10 | Loss:  0.5764 \n",
            "Epoch10 | Loss:  0.3152 \n",
            "Epoch10 | Loss:  0.5971 \n",
            "Epoch10 | Loss:  0.4078 \n",
            "Epoch10 | Loss:  0.3816 \n",
            "Epoch10 | Loss:  0.3639 \n",
            "Epoch10 | Loss:  0.3192 \n",
            "Epoch10 | Loss:  0.6216 \n",
            "Epoch10 | Loss:  0.4884 \n",
            "Epoch10 | Loss:  0.4283 \n",
            "Epoch10 | Loss:  0.5045 \n",
            "Epoch10 | Loss:  0.4145 \n",
            "Epoch10 | Loss:  0.4162 \n",
            "Epoch10 | Loss:  0.4650 \n",
            "Epoch10 | Loss:  0.7528 \n",
            "Epoch10 | Loss:  0.5008 \n",
            "Epoch10 | Loss:  0.4377 \n",
            "Epoch10 | Loss:  0.5286 \n",
            "Epoch10 | Loss:  0.4413 \n",
            "Epoch10 | Loss:  0.2572 \n",
            "Epoch10 | Loss:  0.2739 \n",
            "Epoch10 | Loss:  0.3199 \n",
            "Epoch10 | Loss:  0.5398 \n",
            "Epoch10 | Loss:  0.6790 \n",
            "Epoch10 | Loss:  0.4478 \n",
            "Epoch10 | Loss:  0.6551 \n",
            "Epoch10 | Loss:  0.4326 \n",
            "Epoch10 | Loss:  0.3621 \n",
            "Epoch10 | Loss:  0.3906 \n",
            "Epoch10 | Loss:  0.3729 \n",
            "Epoch10 | Loss:  0.3693 \n",
            "Epoch10 | Loss:  0.3630 \n",
            "Epoch10 | Loss:  0.4117 \n",
            "Epoch10 | Loss:  0.4108 \n",
            "Epoch10 | Loss:  0.5631 \n",
            "Epoch10 | Loss:  0.6774 \n",
            "Epoch10 | Loss:  0.5437 \n",
            "Epoch10 | Loss:  0.5727 \n",
            "Epoch10 | Loss:  0.3453 \n",
            "Epoch10 | Loss:  0.3783 \n",
            "Epoch10 | Loss:  0.3849 \n",
            "Epoch10 | Loss:  0.6547 \n",
            "Epoch10 | Loss:  0.3504 \n",
            "Epoch10 | Loss:  0.5820 \n",
            "Epoch10 | Loss:  0.5655 \n",
            "Epoch10 | Loss:  0.7777 \n",
            "Epoch10 | Loss:  0.4121 \n",
            "Epoch10 | Loss:  0.3059 \n",
            "Epoch10 | Loss:  0.6976 \n",
            "Epoch10 | Loss:  0.4200 \n",
            "Epoch10 | Loss:  0.5140 \n",
            "Epoch10 | Loss:  0.6709 \n",
            "Epoch10 | Loss:  0.6305 \n",
            "Epoch10 | Loss:  0.3953 \n",
            "Epoch10 | Loss:  0.4921 \n",
            "Epoch10 | Loss:  0.6959 \n",
            "Epoch10 | Loss:  0.3875 \n",
            "Epoch10 | Loss:  0.4474 \n",
            "Epoch10 | Loss:  0.2793 \n",
            "Epoch10 | Loss:  0.7273 \n",
            "Epoch10 | Loss:  0.6525 \n",
            "Epoch10 | Loss:  0.5208 \n",
            "Epoch10 | Loss:  0.3513 \n",
            "Epoch10 | Loss:  0.5403 \n",
            "Epoch10 | Loss:  0.6193 \n",
            "Epoch10 | Loss:  0.4238 \n",
            "Epoch10 | Loss:  0.3425 \n",
            "Epoch10 | Loss:  0.4726 \n",
            "Epoch10 | Loss:  0.4473 \n",
            "Epoch10 | Loss:  0.7810 \n",
            "Epoch10 | Loss:  0.4146 \n",
            "Epoch10 | Loss:  0.8932 \n",
            "Epoch10 | Loss:  0.5241 \n",
            "Epoch10 | Loss:  0.6285 \n",
            "Epoch10 | Loss:  0.5843 \n",
            "Epoch10 | Loss:  0.4611 \n",
            "Epoch10 | Loss:  0.7341 \n",
            "Epoch10 | Loss:  0.5334 \n",
            "Epoch10 | Loss:  0.4900 \n",
            "Epoch10 | Loss:  0.7092 \n",
            "Epoch10 | Loss:  0.3231 \n",
            "Epoch10 | Loss:  0.4772 \n",
            "Epoch10 | Loss:  0.5155 \n",
            "Epoch10 | Loss:  0.3226 \n",
            "Epoch10 | Loss:  0.6097 \n",
            "Epoch10 | Loss:  0.5704 \n",
            "Epoch10 | Loss:  0.3650 \n",
            "Epoch10 | Loss:  0.4079 \n",
            "Epoch10 | Loss:  0.5844 \n",
            "Epoch10 | Loss:  0.3750 \n",
            "Epoch10 | Loss:  0.3859 \n",
            "Epoch10 | Loss:  0.5852 \n",
            "Epoch10 | Loss:  0.6950 \n",
            "Epoch10 | Loss:  0.5273 \n",
            "Epoch10 | Loss:  0.3797 \n",
            "Epoch10 | Loss:  0.4525 \n",
            "Epoch10 | Loss:  0.6575 \n",
            "Epoch10 | Loss:  0.5227 \n",
            "Epoch10 | Loss:  0.5409 \n",
            "Epoch10 | Loss:  0.4859 \n",
            "Epoch10 | Loss:  0.4149 \n",
            "Epoch10 | Loss:  0.4003 \n",
            "Epoch10 | Loss:  0.5812 \n",
            "Epoch10 | Loss:  0.5467 \n",
            "Epoch10 | Loss:  0.5824 \n",
            "Epoch10 | Loss:  0.5635 \n",
            "Epoch10 | Loss:  0.4444 \n",
            "Epoch10 | Loss:  0.4832 \n",
            "Epoch10 | Loss:  0.4402 \n",
            "Epoch10 | Loss:  0.6669 \n",
            "Epoch10 | Loss:  0.5252 \n",
            "Epoch10 | Loss:  0.4713 \n",
            "Epoch10 | Loss:  0.5925 \n",
            "Epoch10 | Loss:  0.3932 \n",
            "Epoch10 | Loss:  0.6173 \n",
            "Epoch10 | Loss:  0.5605 \n",
            "Epoch10 | Loss:  0.8462 \n",
            "Epoch10 | Loss:  0.5090 \n",
            "Epoch10 | Loss:  0.3682 \n",
            "Epoch10 | Loss:  0.6076 \n",
            "Epoch10 | Loss:  0.5742 \n",
            "Epoch10 | Loss:  0.4571 \n",
            "Epoch10 | Loss:  0.5785 \n",
            "Epoch10 | Loss:  0.5732 \n",
            "Epoch10 | Loss:  0.4694 \n",
            "Epoch10 | Loss:  0.4177 \n",
            "Epoch10 | Loss:  0.4691 \n",
            "Epoch10 | Loss:  0.6008 \n",
            "Epoch10 | Loss:  0.4345 \n",
            "Epoch10 | Loss:  0.2979 \n",
            "Epoch10 | Loss:  0.5649 \n",
            "Epoch10 | Loss:  0.4933 \n",
            "Epoch10 | Loss:  0.6651 \n",
            "Epoch10 | Loss:  0.7021 \n",
            "Epoch10 | Loss:  0.4894 \n",
            "Epoch10 | Loss:  0.5963 \n",
            "Epoch10 | Loss:  0.4625 \n",
            "Epoch10 | Loss:  0.5467 \n",
            "Epoch10 | Loss:  0.7071 \n",
            "Epoch10 | Loss:  0.4913 \n",
            "Epoch10 | Loss:  0.3863 \n",
            "Epoch10 | Loss:  0.4850 \n",
            "Epoch10 | Loss:  0.4565 \n",
            "Epoch10 | Loss:  0.6780 \n",
            "Epoch10 | Loss:  0.5838 \n",
            "Epoch10 | Loss:  0.4369 \n",
            "Epoch10 | Loss:  0.4727 \n",
            "Epoch10 | Loss:  0.8552 \n",
            "Epoch10 | Loss:  0.2838 \n",
            "Epoch10 | Loss:  0.5930 \n",
            "Epoch10 | Loss:  0.4743 \n",
            "Epoch10 | Loss:  0.4206 \n",
            "Epoch10 | Loss:  0.5035 \n",
            "Epoch10 | Loss:  0.6611 \n",
            "Epoch10 | Loss:  0.5569 \n",
            "Epoch10 | Loss:  0.2869 \n",
            "Epoch10 | Loss:  0.4246 \n",
            "Epoch10 | Loss:  0.1968 \n",
            "Epoch10 | Loss:  0.3541 \n",
            "Epoch10 | Loss:  0.6558 \n",
            "Epoch10 | Loss:  0.3670 \n",
            "Epoch10 | Loss:  0.4510 \n",
            "Epoch10 | Loss:  0.3714 \n",
            "Epoch10 | Loss:  0.5221 \n",
            "Epoch10 | Loss:  0.6715 \n",
            "Epoch10 | Loss:  0.7171 \n",
            "Epoch10 | Loss:  0.3171 \n",
            "Epoch10 | Loss:  0.3685 \n",
            "Epoch10 | Loss:  0.5458 \n",
            "Epoch10 | Loss:  0.5847 \n",
            "Epoch10 | Loss:  0.4310 \n",
            "Epoch10 | Loss:  0.5031 \n",
            "Epoch10 | Loss:  0.4653 \n",
            "Epoch10 | Loss:  0.3567 \n",
            "Epoch10 | Loss:  0.4276 \n",
            "Epoch10 | Loss:  0.5255 \n",
            "Epoch10 | Loss:  0.5277 \n",
            "Epoch10 | Loss:  0.4378 \n",
            "Epoch10 | Loss:  0.4417 \n",
            "Epoch10 | Loss:  0.3925 \n",
            "Epoch10 | Loss:  0.4582 \n",
            "Epoch10 | Loss:  0.8960 \n",
            "Epoch10 | Loss:  1.4617 \n",
            "Epoch10 | Loss:  0.4782 \n",
            "Epoch10 | Loss:  0.3642 \n",
            "Epoch10 | Loss:  0.2298 \n",
            "Epoch10 | Loss:  0.7186 \n",
            "Epoch10 | Loss:  0.3941 \n",
            "Epoch10 | Loss:  0.3449 \n",
            "Epoch10 | Loss:  0.5058 \n",
            "Epoch10 | Loss:  0.7116 \n",
            "Epoch10 | Loss:  0.5158 \n",
            "Epoch10 | Loss:  0.3824 \n",
            "Epoch10 | Loss:  0.5240 \n",
            "Epoch10 | Loss:  0.5015 \n",
            "Epoch10 | Loss:  0.4224 \n",
            "Epoch10 | Loss:  0.6183 \n",
            "Epoch10 | Loss:  0.6087 \n",
            "Epoch10 | Loss:  0.6458 \n",
            "Epoch10 | Loss:  0.7091 \n",
            "Epoch10 | Loss:  0.4525 \n",
            "Epoch10 | Loss:  0.4537 \n",
            "Epoch10 | Loss:  0.3652 \n",
            "Epoch10 | Loss:  0.6550 \n",
            "Epoch10 | Loss:  0.5385 \n",
            "Epoch10 | Loss:  0.3511 \n",
            "Epoch10 | Loss:  0.2533 \n",
            "Epoch10 | Loss:  0.5204 \n",
            "Epoch10 | Loss:  0.4286 \n",
            "Epoch10 | Loss:  0.6672 \n",
            "Epoch10 | Loss:  0.3957 \n",
            "Epoch10 | Loss:  0.8464 \n",
            "Epoch10 | Loss:  0.8200 \n",
            "Epoch10 | Loss:  0.2992 \n",
            "Epoch10 | Loss:  0.4129 \n",
            "Epoch10 | Loss:  0.7655 \n",
            "Epoch10 | Loss:  0.4456 \n",
            "Epoch10 | Loss:  0.4759 \n",
            "Epoch10 | Loss:  0.3930 \n",
            "Epoch10 | Loss:  0.7147 \n",
            "Epoch10 | Loss:  0.6479 \n",
            "Epoch10 | Loss:  0.4481 \n",
            "Epoch10 | Loss:  0.3706 \n",
            "Epoch10 | Loss:  0.6315 \n",
            "Epoch10 | Loss:  0.4379 \n",
            "Epoch10 | Loss:  0.5143 \n",
            "Epoch10 | Loss:  0.6270 \n",
            "Epoch10 | Loss:  0.8401 \n",
            "Epoch10 | Loss:  0.2789 \n",
            "Epoch10 | Loss:  0.4506 \n",
            "Epoch10 | Loss:  0.3791 \n",
            "Epoch10 | Loss:  0.8197 \n",
            "Epoch10 | Loss:  0.4774 \n",
            "Epoch10 | Loss:  0.9818 \n",
            "Epoch10 | Loss:  0.4806 \n",
            "Epoch10 | Loss:  0.5571 \n",
            "Epoch10 | Loss:  0.5251 \n",
            "Epoch10 | Loss:  0.3671 \n",
            "Epoch10 | Loss:  0.5843 \n",
            "Epoch10 | Loss:  0.6422 \n",
            "Epoch10 | Loss:  0.4072 \n",
            "Epoch10 | Loss:  0.6753 \n",
            "Epoch10 | Loss:  0.5905 \n",
            "Epoch10 | Loss:  0.6418 \n",
            "Epoch10 | Loss:  0.4541 \n",
            "Epoch10 | Loss:  0.4660 \n",
            "Epoch10 | Loss:  0.3585 \n",
            "Epoch10 | Loss:  0.6797 \n",
            "Epoch10 | Loss:  0.6198 \n",
            "Epoch10 | Loss:  0.3163 \n",
            "Epoch10 | Loss:  0.7492 \n",
            "Epoch10 | Loss:  0.6592 \n",
            "Epoch10 | Loss:  0.3657 \n",
            "Epoch10 | Loss:  0.3004 \n",
            "Epoch10 | Loss:  0.4977 \n",
            "Epoch10 | Loss:  0.5673 \n",
            "Epoch10 | Loss:  0.6205 \n",
            "Epoch10 | Loss:  0.3164 \n",
            "Epoch10 | Loss:  0.6528 \n",
            "Epoch10 | Loss:  0.2363 \n",
            "Epoch10 | Loss:  0.4634 \n",
            "Epoch10 | Loss:  0.8372 \n",
            "Epoch10 | Loss:  0.5827 \n",
            "Epoch10 | Loss:  1.1213 \n",
            "Epoch10 | Loss:  0.5004 \n",
            "Epoch10 | Loss:  0.3423 \n",
            "Epoch10 | Loss:  0.4429 \n",
            "Epoch10 | Loss:  0.6269 \n",
            "Epoch10 | Loss:  0.4904 \n",
            "Epoch10 | Loss:  0.3984 \n",
            "Epoch10 | Loss:  0.4985 \n",
            "Epoch10 | Loss:  0.7085 \n",
            "Epoch10 | Loss:  0.2862 \n",
            "Epoch10 | Loss:  0.4508 \n",
            "Epoch10 | Loss:  0.7018 \n",
            "Epoch10 | Loss:  0.3329 \n",
            "Epoch10 | Loss:  0.3461 \n",
            "Epoch10 | Loss:  0.7497 \n",
            "Epoch10 | Loss:  0.8095 \n",
            "Epoch10 | Loss:  1.0827 \n",
            "Epoch10 | Loss:  0.5251 \n",
            "Epoch10 | Loss:  0.5540 \n",
            "Epoch10 | Loss:  0.5383 \n",
            "Epoch10 | Loss:  0.5584 \n",
            "Epoch10 | Loss:  0.4673 \n",
            "Epoch10 | Loss:  0.4799 \n",
            "Epoch10 | Loss:  0.6920 \n",
            "Epoch10 | Loss:  0.7160 \n",
            "Epoch10 | Loss:  0.5337 \n",
            "Epoch10 | Loss:  0.4901 \n",
            "Epoch10 | Loss:  0.4102 \n",
            "Epoch10 | Loss:  0.6220 \n",
            "Epoch10 | Loss:  0.4819 \n",
            "Epoch10 | Loss:  0.6231 \n",
            "Epoch10 | Loss:  1.0092 \n",
            "Epoch10 | Loss:  0.4201 \n",
            "Epoch10 | Loss:  0.4324 \n",
            "Epoch10 | Loss:  0.6406 \n",
            "Epoch10 | Loss:  0.6113 \n",
            "Epoch10 | Loss:  0.5070 \n",
            "Epoch10 | Loss:  0.6178 \n",
            "Epoch10 | Loss:  0.4766 \n",
            "Epoch10 | Loss:  0.5224 \n",
            "Epoch10 | Loss:  0.6018 \n",
            "Epoch10 | Loss:  0.2361 \n",
            "Epoch10 | Loss:  0.4740 \n",
            "Epoch10 | Loss:  0.3923 \n",
            "Epoch10 | Loss:  0.6824 \n",
            "Epoch10 | Loss:  0.4453 \n",
            "Epoch10 | Loss:  0.5140 \n",
            "Epoch10 | Loss:  0.9913 \n",
            "Epoch10 | Loss:  0.4303 \n",
            "Epoch10 | Loss:  0.5400 \n",
            "Epoch10 | Loss:  0.6439 \n",
            "Epoch10 | Loss:  0.3417 \n",
            "Epoch10 | Loss:  0.6171 \n",
            "Epoch10 | Loss:  0.5916 \n",
            "Epoch10 | Loss:  0.6314 \n",
            "Epoch10 | Loss:  0.2864 \n",
            "Epoch10 | Loss:  0.4556 \n",
            "Epoch10 | Loss:  0.2168 \n",
            "Epoch10 | Loss:  0.3030 \n",
            "Epoch10 | Loss:  0.4138 \n",
            "Epoch10 | Loss:  0.4610 \n",
            "Epoch10 | Loss:  0.4818 \n",
            "Epoch10 | Loss:  0.7369 \n",
            "Epoch10 | Loss:  0.4697 \n",
            "Epoch10 | Loss:  0.5430 \n",
            "Epoch10 | Loss:  0.4100 \n",
            "Epoch10 | Loss:  0.4546 \n",
            "Epoch10 | Loss:  0.7369 \n",
            "Epoch10 | Loss:  0.3665 \n",
            "Epoch10 | Loss:  0.6338 \n",
            "Epoch10 | Loss:  0.7429 \n",
            "Epoch10 | Loss:  0.7544 \n",
            "Epoch10 | Loss:  0.6702 \n",
            "Epoch10 | Loss:  0.5648 \n",
            "Epoch10 | Loss:  0.5637 \n",
            "Epoch10 | Loss:  0.3811 \n",
            "Epoch10 | Loss:  0.3801 \n",
            "Epoch10 | Loss:  0.6994 \n",
            "Epoch10 | Loss:  0.5118 \n",
            "Epoch10 | Loss:  0.6616 \n",
            "Epoch10 | Loss:  0.4954 \n",
            "Epoch10 | Loss:  0.4388 \n",
            "Epoch10 | Loss:  0.5876 \n",
            "Epoch10 | Loss:  0.3947 \n",
            "Epoch10 | Loss:  0.6414 \n",
            "Epoch10 | Loss:  0.6369 \n",
            "Epoch10 | Loss:  0.4429 \n",
            "Epoch10 | Loss:  0.5269 \n",
            "Epoch10 | Loss:  0.6772 \n",
            "Epoch10 | Loss:  0.5222 \n",
            "Epoch10 | Loss:  0.7018 \n",
            "Epoch10 | Loss:  0.5290 \n",
            "Epoch10 | Loss:  0.7794 \n",
            "Epoch10 | Loss:  0.4203 \n",
            "Epoch10 | Loss:  0.5229 \n",
            "Epoch10 | Loss:  0.4371 \n",
            "Epoch10 | Loss:  0.6219 \n",
            "Epoch10 | Loss:  0.5659 \n",
            "Epoch10 | Loss:  0.2980 \n",
            "Epoch10 | Loss:  0.4714 \n",
            "Epoch10 | Loss:  0.2299 \n",
            "Epoch10 | Loss:  0.6206 \n",
            "Epoch10 | Loss:  0.6066 \n",
            "Epoch10 | Loss:  0.7006 \n",
            "Epoch10 | Loss:  0.6352 \n",
            "Epoch10 | Loss:  0.3355 \n",
            "Epoch10 | Loss:  0.7474 \n",
            "Epoch10 | Loss:  0.6450 \n",
            "Epoch10 | Loss:  0.8611 \n",
            "Epoch10 | Loss:  0.4498 \n",
            "Epoch10 | Loss:  0.2551 \n",
            "Epoch10 | Loss:  0.2505 \n",
            "Epoch10 | Loss:  0.5700 \n",
            "Epoch10 | Loss:  0.4320 \n",
            "Epoch10 | Loss:  0.6483 \n",
            "Epoch10 | Loss:  0.6563 \n",
            "Epoch10 | Loss:  0.2624 \n",
            "Epoch10 | Loss:  0.3869 \n",
            "Epoch10 | Loss:  0.4690 \n",
            "Epoch10 | Loss:  0.3253 \n",
            "Epoch10 | Loss:  0.4314 \n",
            "Epoch10 | Loss:  0.3374 \n",
            "Epoch10 | Loss:  0.5493 \n",
            "Epoch10 | Loss:  0.3526 \n",
            "Epoch10 | Loss:  0.6247 \n",
            "Epoch10 | Loss:  0.4332 \n",
            "Epoch10 | Loss:  0.7186 \n",
            "Epoch10 | Loss:  0.5183 \n",
            "Epoch10 | Loss:  0.5866 \n",
            "Epoch10 | Loss:  0.4068 \n",
            "Epoch10 | Loss:  0.7240 \n",
            "Epoch10 | Loss:  0.5365 \n",
            "Epoch10 | Loss:  0.4764 \n",
            "Epoch10 | Loss:  0.6226 \n",
            "Epoch10 | Loss:  0.3943 \n",
            "Epoch10 | Loss:  0.5496 \n",
            "Epoch10 | Loss:  0.4953 \n",
            "Epoch10 | Loss:  0.5198 \n",
            "Epoch10 | Loss:  0.7163 \n",
            "Epoch10 | Loss:  0.5256 \n",
            "Epoch10 | Loss:  0.4259 \n",
            "Epoch10 | Loss:  0.3748 \n",
            "Epoch10 | Loss:  0.5354 \n",
            "Epoch10 | Loss:  0.2590 \n",
            "Epoch10 | Loss:  0.5474 \n",
            "Epoch10 | Loss:  0.9173 \n",
            "Epoch10 | Loss:  0.4559 \n",
            "Epoch10 | Loss:  0.3851 \n",
            "Epoch10 | Loss:  0.6629 \n",
            "Epoch10 | Loss:  0.3365 \n",
            "Epoch10 | Loss:  0.6381 \n",
            "Epoch10 | Loss:  1.0983 \n",
            "Epoch10 | Loss:  0.6216 \n",
            "Epoch10 | Loss:  0.5588 \n",
            "Epoch10 | Loss:  0.5899 \n",
            "Epoch10 | Loss:  0.4007 \n",
            "Epoch10 | Loss:  0.6077 \n",
            "Epoch10 | Loss:  0.5869 \n",
            "Epoch10 | Loss:  0.3591 \n",
            "Epoch10 | Loss:  0.5157 \n",
            "Epoch10 | Loss:  0.4186 \n",
            "Epoch10 | Loss:  0.4038 \n",
            "Epoch10 | Loss:  0.4430 \n",
            "Epoch10 | Loss:  0.4659 \n",
            "Epoch10 | Loss:  0.3218 \n",
            "Epoch10 | Loss:  0.3798 \n",
            "Epoch10 | Loss:  0.4439 \n",
            "Epoch10 | Loss:  0.5628 \n",
            "Epoch10 | Loss:  0.4605 \n",
            "Epoch10 | Loss:  0.3741 \n",
            "Epoch10 | Loss:  0.5792 \n",
            "Epoch10 | Loss:  0.4038 \n",
            "Epoch10 | Loss:  0.4855 \n",
            "Epoch10 | Loss:  0.4597 \n",
            "Epoch10 | Loss:  0.4463 \n",
            "Epoch10 | Loss:  0.6524 \n",
            "Epoch10 | Loss:  0.4829 \n",
            "Epoch10 | Loss:  0.4419 \n",
            "Epoch10 | Loss:  0.5010 \n",
            "Epoch10 | Loss:  0.5330 \n",
            "Epoch10 | Loss:  0.3865 \n",
            "Epoch10 | Loss:  0.7765 \n",
            "Epoch10 | Loss:  0.4459 \n",
            "Epoch10 | Loss:  0.4621 \n",
            "Epoch10 | Loss:  0.3546 \n",
            "Epoch10 | Loss:  0.4756 \n",
            "Epoch10 | Loss:  0.7199 \n",
            "Epoch10 | Loss:  0.4355 \n",
            "Epoch10 | Loss:  0.7277 \n",
            "Epoch10 | Loss:  0.7369 \n",
            "Epoch10 | Loss:  0.7740 \n",
            "Epoch10 | Loss:  0.6242 \n",
            "Epoch10 | Loss:  0.6461 \n",
            "Epoch10 | Loss:  0.5162 \n",
            "Epoch10 | Loss:  0.4014 \n",
            "Epoch10 | Loss:  0.8687 \n",
            "Epoch10 | Loss:  0.4911 \n",
            "Epoch10 | Loss:  0.4596 \n",
            "Epoch10 | Loss:  0.5787 \n",
            "Epoch10 | Loss:  0.6781 \n",
            "Epoch10 | Loss:  0.3574 \n",
            "Epoch10 | Loss:  0.3684 \n",
            "Epoch10 | Loss:  0.7619 \n",
            "Epoch10 | Loss:  0.4103 \n",
            "Epoch10 | Loss:  0.2838 \n",
            "Epoch10 | Loss:  0.5663 \n",
            "Epoch10 | Loss:  0.4840 \n",
            "Epoch10 | Loss:  0.2480 \n",
            "Epoch10 | Loss:  0.4952 \n",
            "Epoch10 | Loss:  0.6284 \n",
            "Epoch10 | Loss:  0.5866 \n",
            "Epoch10 | Loss:  0.5020 \n",
            "Epoch10 | Loss:  0.7065 \n",
            "Epoch10 | Loss:  0.4483 \n",
            "Epoch10 | Loss:  0.4678 \n",
            "Epoch10 | Loss:  0.4690 \n",
            "Epoch10 | Loss:  0.5306 \n",
            "Epoch10 | Loss:  0.5279 \n",
            "Epoch10 | Loss:  0.5527 \n",
            "Epoch10 | Loss:  0.4108 \n",
            "Epoch10 | Loss:  0.7588 \n",
            "Epoch10 | Loss:  0.6973 \n",
            "Epoch10 | Loss:  0.3789 \n",
            "Epoch10 | Loss:  0.5111 \n",
            "Epoch10 | Loss:  0.3508 \n",
            "Epoch10 | Loss:  0.7139 \n",
            "Epoch10 | Loss:  0.4347 \n",
            "Epoch10 | Loss:  0.6579 \n",
            "Epoch10 | Loss:  0.3926 \n",
            "Epoch10 | Loss:  0.2561 \n",
            "Epoch10 | Loss:  0.6166 \n",
            "Epoch10 | Loss:  0.2874 \n",
            "Epoch10 | Loss:  0.4684 \n",
            "Epoch10 | Loss:  0.5079 \n",
            "Epoch10 | Loss:  0.4678 \n",
            "Epoch10 | Loss:  0.4739 \n",
            "Epoch10 | Loss:  0.6616 \n",
            "Epoch10 | Loss:  0.7870 \n",
            "Epoch10 | Loss:  0.5894 \n",
            "Epoch10 | Loss:  0.4113 \n",
            "Epoch10 | Loss:  0.4812 \n",
            "Epoch10 | Loss:  0.4085 \n",
            "Epoch10 | Loss:  0.4862 \n",
            "Epoch10 | Loss:  0.7278 \n",
            "Epoch10 | Loss:  1.1076 \n",
            "Epoch10 | Loss:  0.5649 \n",
            "Epoch10 | Loss:  0.4617 \n",
            "Epoch10 | Loss:  0.5755 \n",
            "Epoch10 | Loss:  0.5975 \n",
            "Epoch10 | Loss:  0.2229 \n",
            "Epoch10 | Loss:  0.4506 \n",
            "Epoch10 | Loss:  0.5337 \n",
            "Epoch10 | Loss:  0.6646 \n",
            "Epoch10 | Loss:  0.4455 \n",
            "Epoch10 | Loss:  0.6225 \n",
            "Epoch10 | Loss:  0.5736 \n",
            "Epoch10 | Loss:  0.4675 \n",
            "Epoch10 | Loss:  0.3470 \n",
            "Epoch10 | Loss:  0.4989 \n",
            "Epoch10 | Loss:  0.4307 \n",
            "Epoch10 | Loss:  0.3792 \n",
            "Epoch10 | Loss:  0.7271 \n",
            "Epoch10 | Loss:  0.4444 \n",
            "Epoch10 | Loss:  0.4383 \n",
            "Epoch10 | Loss:  0.4420 \n",
            "Epoch10 | Loss:  0.5102 \n",
            "Epoch10 | Loss:  0.6589 \n",
            "Epoch10 | Loss:  0.3228 \n",
            "Epoch10 | Loss:  0.4340 \n",
            "Epoch10 | Loss:  0.5125 \n",
            "Epoch10 | Loss:  0.4996 \n",
            "Epoch10 | Loss:  0.6888 \n",
            "Epoch10 | Loss:  0.3452 \n",
            "Epoch10 | Loss:  0.6955 \n",
            "Epoch10 | Loss:  0.5837 \n",
            "Epoch10 | Loss:  0.5618 \n",
            "Epoch10 | Loss:  0.2471 \n",
            "Epoch10 | Loss:  0.4943 \n",
            "Epoch10 | Loss:  0.2106 \n",
            "Epoch10 | Loss:  0.5265 \n",
            "Epoch10 | Loss:  0.6079 \n",
            "Epoch10 | Loss:  0.3437 \n",
            "Epoch10 | Loss:  0.4561 \n",
            "Epoch10 | Loss:  0.6270 \n",
            "Epoch10 | Loss:  0.7185 \n",
            "Epoch10 | Loss:  0.8002 \n",
            "Epoch10 | Loss:  0.5806 \n",
            "Epoch10 | Loss:  0.4730 \n",
            "Epoch10 | Loss:  0.3601 \n",
            "Epoch10 | Loss:  0.4371 \n",
            "Epoch10 | Loss:  0.5817 \n",
            "Epoch10 | Loss:  0.4659 \n",
            "Epoch10 | Loss:  0.3548 \n",
            "Epoch10 | Loss:  0.4391 \n",
            "Epoch10 | Loss:  0.7095 \n"
          ]
        }
      ]
    }
  ]
}