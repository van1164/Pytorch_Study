{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/van1164/Pytorch_Study/blob/main/lab06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNBuWLpyR_d6",
        "outputId": "6dc8dd64-7608-41c4-dfe4-043488e65ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 72986764.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./cifar-10-python.tar.gz to ./\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Pad(4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./',\n",
        "                                             train=True,\n",
        "                                             transform = transform,\n",
        "                                             download =True)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(root = './',\n",
        "                                            train = False,\n",
        "                                            transform =transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = 100,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size =100,\n",
        "                                          shuffle =False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SKBhbGxMSYUv"
      },
      "outputs": [],
      "source": [
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride =1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.residual_fuction = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "\n",
        "    )\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "\n",
        "\n",
        "    if stride !=1 or in_channels != out_channels:\n",
        "      self.shortcut = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels,kernel_size=1,stride=stride,bias=False),\n",
        "        nn.BatchNorm2d(out_channels)\n",
        "      )\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.maxPool  = nn.MaxPool2d(4)\n",
        "    self.fc = nn.Linear(out_channels*8*8,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.residual_fuction(x)+self.shortcut(x)\n",
        "    x= self.relu(x)\n",
        "    return x\n",
        "model = BasicBlock(3,64)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FqMIVudMc5Xi"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        ouputs = model(images)\n",
        "        loss = criterion(ouputs,labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1)%100 ==0:\n",
        "            print(\"Epoch [{}/{}], step [{}/{}] Loss: {:4f}\".format(epoch+1,num_epochs,i+1,total_step,loss.item()))\n",
        "    \n",
        "    if (epoch+1)%20 == 0:\n",
        "        curr_lr /=3\n",
        "        update_lr(optimizer,curr_lr)\n",
        "\n",
        "def test():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total =0\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data,1)\n",
        "            total +=labels.size(0)\n",
        "            correct +=(predicted == labels).sum().item()\n",
        "\n",
        "        print('Accuracy of the model on the test images: {}%'.format(100*correct/total))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNm6C8Thlvbo"
      },
      "source": [
        "Batch\n",
        "Normalization\n",
        "외에\n",
        "아래의\n",
        "4\n",
        "개\n",
        "이상의\n",
        "Normalization\n",
        "방법에\n",
        "대\n",
        "해\n",
        "찾아보고\n",
        ",\n",
        "구현한\n",
        "결과를\n",
        "보이시오"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEFYw_dMlzi8"
      },
      "source": [
        "1. Batch Norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jboSv_F9dGbf"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],1)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],2)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],2)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNet(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "4q3whGUYg6w8",
        "outputId": "a63860a2-e1bd-418b-c12d-1c12e94a5f27"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ead2d514d3f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1379cee5c156>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TefTO-vl5VM"
      },
      "source": [
        "2. Layer Norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQvH-bQWl2sd"
      },
      "outputs": [],
      "source": [
        "class ResNetL(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.LayerNorm((self.in_channels,16,16)),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],1)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],2)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],2)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNetL(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykscws9znAlV"
      },
      "outputs": [],
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY0Q1-1xFfGC"
      },
      "source": [
        "InstanceNorm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-KRr5QdnBEb"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.InstanceNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],1)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],2)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],2)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNet(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "Ht7WoMwHs7E5",
        "outputId": "eaf7f49e-9174-407b-f9bb-d6eb84ef00e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], step [100/500] Loss: 1.834224\n",
            "Epoch [1/10], step [200/500] Loss: 1.522249\n",
            "Epoch [1/10], step [300/500] Loss: 1.548688\n",
            "Epoch [1/10], step [400/500] Loss: 1.430933\n",
            "Epoch [1/10], step [500/500] Loss: 1.299627\n",
            "Accuracy of the model on the test images: 51.44%\n",
            "Epoch [2/10], step [100/500] Loss: 1.859818\n",
            "Epoch [2/10], step [200/500] Loss: 1.523593\n",
            "Epoch [2/10], step [300/500] Loss: 1.477445\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ead2d514d3f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1379cee5c156>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyO3f5stFcE9"
      },
      "source": [
        "GroupNorm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SHOmIpcEU5y"
      },
      "outputs": [],
      "source": [
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.GroupNorm(64,64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],1)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],2)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],2)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],2)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNet(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "iRsv_HCcFZsc",
        "outputId": "222a8272-8862-4f7b-a733-416555911f53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], step [100/500] Loss: 1.653610\n",
            "Epoch [1/10], step [200/500] Loss: 1.376367\n",
            "Epoch [1/10], step [300/500] Loss: 1.764217\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-ead2d514d3f5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1379cee5c156>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMuQT9DbGBsO"
      },
      "source": [
        "ResNet34를 구현하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-9A9yfgFbO7"
      },
      "outputs": [],
      "source": [
        "class ResNet34(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "    self.conv1 =nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],3)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],4)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],6)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],3)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNet34(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bq0dlW6lQdN_",
        "outputId": "edbcc7df-7524-4a97-bf2e-36add2046f1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], step [100/500] Loss: 1.844864\n",
            "Epoch [1/10], step [200/500] Loss: 1.575526\n",
            "Epoch [1/10], step [300/500] Loss: 1.558331\n",
            "Epoch [1/10], step [400/500] Loss: 1.424734\n",
            "Epoch [1/10], step [500/500] Loss: 1.501102\n",
            "Accuracy of the model on the test images: 49.91%\n",
            "Epoch [2/10], step [100/500] Loss: 1.980172\n",
            "Epoch [2/10], step [200/500] Loss: 1.546011\n",
            "Epoch [2/10], step [300/500] Loss: 1.404390\n",
            "Epoch [2/10], step [400/500] Loss: 1.484022\n",
            "Epoch [2/10], step [500/500] Loss: 1.253393\n",
            "Accuracy of the model on the test images: 51.97%\n",
            "Epoch [3/10], step [100/500] Loss: 1.154403\n",
            "Epoch [3/10], step [200/500] Loss: 1.659832\n",
            "Epoch [3/10], step [300/500] Loss: 1.284458\n",
            "Epoch [3/10], step [400/500] Loss: 1.341085\n",
            "Epoch [3/10], step [500/500] Loss: 1.363340\n",
            "Accuracy of the model on the test images: 55.71%\n",
            "Epoch [4/10], step [100/500] Loss: 1.232064\n",
            "Epoch [4/10], step [200/500] Loss: 1.359948\n",
            "Epoch [4/10], step [300/500] Loss: 1.064928\n",
            "Epoch [4/10], step [400/500] Loss: 1.394545\n",
            "Epoch [4/10], step [500/500] Loss: 1.329339\n",
            "Accuracy of the model on the test images: 57.54%\n",
            "Epoch [5/10], step [100/500] Loss: 1.203462\n",
            "Epoch [5/10], step [200/500] Loss: 1.234548\n",
            "Epoch [5/10], step [300/500] Loss: 1.179896\n",
            "Epoch [5/10], step [400/500] Loss: 1.096885\n",
            "Epoch [5/10], step [500/500] Loss: 1.127815\n",
            "Accuracy of the model on the test images: 60.74%\n",
            "Epoch [6/10], step [100/500] Loss: 1.159091\n",
            "Epoch [6/10], step [200/500] Loss: 1.082028\n",
            "Epoch [6/10], step [300/500] Loss: 1.268781\n",
            "Epoch [6/10], step [400/500] Loss: 1.129362\n",
            "Epoch [6/10], step [500/500] Loss: 1.222349\n",
            "Accuracy of the model on the test images: 63.06%\n",
            "Epoch [7/10], step [100/500] Loss: 1.207668\n",
            "Epoch [7/10], step [200/500] Loss: 0.980359\n",
            "Epoch [7/10], step [300/500] Loss: 1.107276\n",
            "Epoch [7/10], step [400/500] Loss: 1.041149\n",
            "Epoch [7/10], step [500/500] Loss: 0.943301\n",
            "Accuracy of the model on the test images: 64.06%\n",
            "Epoch [8/10], step [100/500] Loss: 1.113749\n",
            "Epoch [8/10], step [200/500] Loss: 0.925964\n",
            "Epoch [8/10], step [300/500] Loss: 1.078328\n",
            "Epoch [8/10], step [400/500] Loss: 1.083056\n",
            "Epoch [8/10], step [500/500] Loss: 0.880954\n",
            "Accuracy of the model on the test images: 63.41%\n",
            "Epoch [9/10], step [100/500] Loss: 1.021387\n",
            "Epoch [9/10], step [200/500] Loss: 0.903596\n",
            "Epoch [9/10], step [300/500] Loss: 1.079215\n",
            "Epoch [9/10], step [400/500] Loss: 1.080542\n",
            "Epoch [9/10], step [500/500] Loss: 1.202197\n",
            "Accuracy of the model on the test images: 66.74%\n",
            "Epoch [10/10], step [100/500] Loss: 1.071856\n",
            "Epoch [10/10], step [200/500] Loss: 1.098305\n",
            "Epoch [10/10], step [300/500] Loss: 1.185046\n",
            "Epoch [10/10], step [400/500] Loss: 1.071267\n",
            "Epoch [10/10], step [500/500] Loss: 1.198684\n",
            "Accuracy of the model on the test images: 64.1%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-CPSSEQSZUT"
      },
      "source": [
        "50\n",
        "층\n",
        "이상의\n",
        "ResNet\n",
        "은\n",
        "매개변수\n",
        "사용을\n",
        "최소화\n",
        "하기\n",
        "위해\n",
        "BottleNeck\n",
        "을\n",
        "이용한다\n",
        ".\n",
        "BottleNeck\n",
        "을\n",
        "구현하고\n",
        ",\n",
        "이를\n",
        "이용하여\n",
        "ResNet50\n",
        "도\n",
        "구현하시\n",
        "오\n",
        "(\n",
        "구현\n",
        "결과를\n",
        "CIFAR10\n",
        "에\n",
        "학습\n",
        "/\n",
        "검증하시오\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbVwZ4PsXSt8"
      },
      "outputs": [],
      "source": [
        "class Bottleneck(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride =1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.residual_fuction = nn.Sequential(\n",
        "        nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=stride,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels,out_channels,kernel_size=3,stride=1,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(out_channels,out_channels*4,kernel_size=1,stride=1,padding=1,bias=False),\n",
        "        nn.BatchNorm2d(out_channels*4),\n",
        "        nn.ReLU(),\n",
        "        \n",
        "\n",
        "    )\n",
        "\n",
        "    self.shortcut = nn.Sequential()\n",
        "\n",
        "\n",
        "    if stride !=1 or in_channels != out_channels:\n",
        "      self.shortcut = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels*4,kernel_size=1,stride=stride,bias=False),\n",
        "        nn.BatchNorm2d(out_channels*4)\n",
        "      )\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.maxPool  = nn.MaxPool2d(4)\n",
        "    self.fc = nn.Linear(out_channels*8*8,10)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.residual_fuction(x)+self.shortcut(x)\n",
        "    x= self.relu(x)\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vkAhzSOQeyD"
      },
      "outputs": [],
      "source": [
        "class ResNet50(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "    self.conv1 =nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],3)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],4)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],6)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],3)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNet34(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG59Tlj2ca3Y",
        "outputId": "880827ec-7f9a-4b3f-fc7b-0121e290441b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], step [100/500] Loss: 1.945573\n",
            "Epoch [1/10], step [200/500] Loss: 1.832693\n",
            "Epoch [1/10], step [300/500] Loss: 1.617566\n",
            "Epoch [1/10], step [400/500] Loss: 1.399758\n",
            "Epoch [1/10], step [500/500] Loss: 1.515309\n",
            "Accuracy of the model on the test images: 48.32%\n",
            "Epoch [2/10], step [100/500] Loss: 1.826679\n",
            "Epoch [2/10], step [200/500] Loss: 1.614450\n",
            "Epoch [2/10], step [300/500] Loss: 1.482728\n",
            "Epoch [2/10], step [400/500] Loss: 1.376310\n",
            "Epoch [2/10], step [500/500] Loss: 1.424358\n",
            "Accuracy of the model on the test images: 49.34%\n",
            "Epoch [3/10], step [100/500] Loss: 1.308755\n",
            "Epoch [3/10], step [200/500] Loss: 1.338109\n",
            "Epoch [3/10], step [300/500] Loss: 1.572906\n",
            "Epoch [3/10], step [400/500] Loss: 1.106000\n",
            "Epoch [3/10], step [500/500] Loss: 1.188823\n",
            "Accuracy of the model on the test images: 56.62%\n",
            "Epoch [4/10], step [100/500] Loss: 1.194432\n",
            "Epoch [4/10], step [200/500] Loss: 1.124833\n",
            "Epoch [4/10], step [300/500] Loss: 1.251536\n",
            "Epoch [4/10], step [400/500] Loss: 1.256779\n",
            "Epoch [4/10], step [500/500] Loss: 1.246666\n",
            "Accuracy of the model on the test images: 56.08%\n",
            "Epoch [5/10], step [100/500] Loss: 1.189317\n",
            "Epoch [5/10], step [200/500] Loss: 1.137970\n",
            "Epoch [5/10], step [300/500] Loss: 1.527909\n",
            "Epoch [5/10], step [400/500] Loss: 1.334266\n",
            "Epoch [5/10], step [500/500] Loss: 1.235078\n",
            "Accuracy of the model on the test images: 60.53%\n",
            "Epoch [6/10], step [100/500] Loss: 1.055932\n",
            "Epoch [6/10], step [200/500] Loss: 0.976267\n",
            "Epoch [6/10], step [300/500] Loss: 1.219108\n",
            "Epoch [6/10], step [400/500] Loss: 1.214869\n",
            "Epoch [6/10], step [500/500] Loss: 1.127441\n",
            "Accuracy of the model on the test images: 61.96%\n",
            "Epoch [7/10], step [100/500] Loss: 1.227881\n",
            "Epoch [7/10], step [200/500] Loss: 1.228232\n",
            "Epoch [7/10], step [300/500] Loss: 1.097881\n",
            "Epoch [7/10], step [400/500] Loss: 0.892207\n",
            "Epoch [7/10], step [500/500] Loss: 1.339487\n",
            "Accuracy of the model on the test images: 63.67%\n",
            "Epoch [8/10], step [100/500] Loss: 1.305218\n",
            "Epoch [8/10], step [200/500] Loss: 1.079499\n",
            "Epoch [8/10], step [300/500] Loss: 1.109230\n",
            "Epoch [8/10], step [400/500] Loss: 1.141124\n",
            "Epoch [8/10], step [500/500] Loss: 1.022255\n",
            "Accuracy of the model on the test images: 62.99%\n",
            "Epoch [9/10], step [100/500] Loss: 0.904750\n",
            "Epoch [9/10], step [200/500] Loss: 1.195073\n",
            "Epoch [9/10], step [300/500] Loss: 0.956040\n",
            "Epoch [9/10], step [400/500] Loss: 1.182989\n",
            "Epoch [9/10], step [500/500] Loss: 1.060056\n",
            "Accuracy of the model on the test images: 65.53%\n",
            "Epoch [10/10], step [100/500] Loss: 0.980399\n",
            "Epoch [10/10], step [200/500] Loss: 0.879986\n",
            "Epoch [10/10], step [300/500] Loss: 1.090531\n",
            "Epoch [10/10], step [400/500] Loss: 0.964122\n",
            "Epoch [10/10], step [500/500] Loss: 1.136171\n",
            "Accuracy of the model on the test images: 63.13%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xavier_normal\n",
        "방법\n",
        ",\n",
        "Kaiming\n",
        "_ normal\n",
        "방법이\n",
        "무엇인지\n",
        "인터넷을\n",
        "통해\n",
        "알아보고\n",
        ",\n",
        "이\n",
        "방법\n",
        "들로\n",
        "가중치를\n",
        "초기화\n",
        "하여\n",
        "학습\n",
        "후\n",
        "결과를\n",
        "비교하시오"
      ],
      "metadata": {
        "id": "2sxE3lD9lRpf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3BrdpftKcc9-"
      },
      "outputs": [],
      "source": [
        "class ResNet34(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "    self.conv1 =nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],3)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],4)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],6)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],3)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "    \n",
        "    self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.xavier_uniform_(m.weight, gain=1)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNet34(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4tf9k6xmzU4",
        "outputId": "1bfcc9f9-35f2-46d5-949d-cc5ec8f2ead3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], step [100/500] Loss: 1.999456\n",
            "Epoch [1/10], step [200/500] Loss: 1.689527\n",
            "Epoch [1/10], step [300/500] Loss: 1.583928\n",
            "Epoch [1/10], step [400/500] Loss: 1.766895\n",
            "Epoch [1/10], step [500/500] Loss: 1.558497\n",
            "Accuracy of the model on the test images: 44.37%\n",
            "Epoch [2/10], step [100/500] Loss: 2.059259\n",
            "Epoch [2/10], step [200/500] Loss: 1.879462\n",
            "Epoch [2/10], step [300/500] Loss: 1.780872\n",
            "Epoch [2/10], step [400/500] Loss: 1.608795\n",
            "Epoch [2/10], step [500/500] Loss: 1.673478\n",
            "Accuracy of the model on the test images: 44.71%\n",
            "Epoch [3/10], step [100/500] Loss: 1.545110\n",
            "Epoch [3/10], step [200/500] Loss: 1.492278\n",
            "Epoch [3/10], step [300/500] Loss: 1.573160\n",
            "Epoch [3/10], step [400/500] Loss: 1.446603\n",
            "Epoch [3/10], step [500/500] Loss: 1.534905\n",
            "Accuracy of the model on the test images: 50.61%\n",
            "Epoch [4/10], step [100/500] Loss: 1.535505\n",
            "Epoch [4/10], step [200/500] Loss: 1.417613\n",
            "Epoch [4/10], step [300/500] Loss: 1.438448\n",
            "Epoch [4/10], step [400/500] Loss: 1.599498\n",
            "Epoch [4/10], step [500/500] Loss: 1.267443\n",
            "Accuracy of the model on the test images: 51.92%\n",
            "Epoch [5/10], step [100/500] Loss: 1.352255\n",
            "Epoch [5/10], step [200/500] Loss: 1.155979\n",
            "Epoch [5/10], step [300/500] Loss: 1.163851\n",
            "Epoch [5/10], step [400/500] Loss: 1.274507\n",
            "Epoch [5/10], step [500/500] Loss: 1.206759\n",
            "Accuracy of the model on the test images: 54.73%\n",
            "Epoch [6/10], step [100/500] Loss: 1.212550\n",
            "Epoch [6/10], step [200/500] Loss: 1.203529\n",
            "Epoch [6/10], step [300/500] Loss: 1.359328\n",
            "Epoch [6/10], step [400/500] Loss: 1.409808\n",
            "Epoch [6/10], step [500/500] Loss: 1.164108\n",
            "Accuracy of the model on the test images: 57.21%\n",
            "Epoch [7/10], step [100/500] Loss: 1.282805\n",
            "Epoch [7/10], step [200/500] Loss: 1.117787\n",
            "Epoch [7/10], step [300/500] Loss: 1.050736\n",
            "Epoch [7/10], step [400/500] Loss: 1.302621\n",
            "Epoch [7/10], step [500/500] Loss: 1.400763\n",
            "Accuracy of the model on the test images: 61.63%\n",
            "Epoch [8/10], step [100/500] Loss: 1.275994\n",
            "Epoch [8/10], step [200/500] Loss: 1.229836\n",
            "Epoch [8/10], step [300/500] Loss: 1.216074\n",
            "Epoch [8/10], step [400/500] Loss: 1.270951\n",
            "Epoch [8/10], step [500/500] Loss: 1.208355\n",
            "Accuracy of the model on the test images: 60.7%\n",
            "Epoch [9/10], step [100/500] Loss: 1.026816\n",
            "Epoch [9/10], step [200/500] Loss: 1.088853\n",
            "Epoch [9/10], step [300/500] Loss: 1.044157\n",
            "Epoch [9/10], step [400/500] Loss: 1.181174\n",
            "Epoch [9/10], step [500/500] Loss: 1.259522\n",
            "Accuracy of the model on the test images: 62.49%\n",
            "Epoch [10/10], step [100/500] Loss: 1.057577\n",
            "Epoch [10/10], step [200/500] Loss: 1.110055\n",
            "Epoch [10/10], step [300/500] Loss: 0.964278\n",
            "Epoch [10/10], step [400/500] Loss: 0.988535\n",
            "Epoch [10/10], step [500/500] Loss: 1.152110\n",
            "Accuracy of the model on the test images: 63.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet34(nn.Module):\n",
        "  def __init__(self, block, num_block, num_classes =10, init_weights =True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.in_channels=64\n",
        "    self.conv1 =nn.Sequential(\n",
        "      nn.Conv2d(3,64,kernel_size=7,stride=2,padding=3,bias=False),\n",
        "      nn.BatchNorm2d(64),\n",
        "      nn.ReLU(),\n",
        "      nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
        "    )\n",
        "    self.conv2_x = self._make_layer(block,64,num_block[0],3)\n",
        "    self.conv3_x = self._make_layer(block,128,num_block[1],4)\n",
        "    self.conv4_x = self._make_layer(block,256,num_block[2],6)\n",
        "    self.conv5_x = self._make_layer(block,512,num_block[3],3)\n",
        "\n",
        "    self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    self.fc = nn.Linear(512,num_classes)\n",
        "    \n",
        "    self._initialize_weights()\n",
        "\n",
        "  def _make_layer(self,block,out_channels,num_blocks,stride):\n",
        "    strides = [stride]+[1]*(num_blocks-1)\n",
        "    layer=[]\n",
        "    for stride in strides :\n",
        "      layer.append(block(self.in_channels,out_channels,stride))\n",
        "      self.in_channels = out_channels\n",
        "\n",
        "    return nn.Sequential(*layer)\n",
        "  def _initialize_weights(self):\n",
        "      for m in self.modules():\n",
        "          if isinstance(m, nn.Conv2d):\n",
        "              nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='relu')\n",
        "          elif isinstance(m, nn.BatchNorm2d):\n",
        "              nn.init.constant_(m.weight, 1)\n",
        "              nn.init.constant_(m.bias, 0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    output = self.conv1(x)\n",
        "    output = self.conv2_x(output)\n",
        "    x = self.conv3_x(output)\n",
        "    x = self.conv4_x(x)\n",
        "    x= self.conv5_x(x)\n",
        "    x = self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x= self.fc(x)\n",
        "    return x\n",
        "model = ResNet34(BasicBlock,[2,2,2,2])\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = learning_rate)\n",
        "def update_lr(optimzer, lr):\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr']=lr\n",
        "\n",
        "total_step = len(train_loader)\n",
        "curr_lr = learning_rate"
      ],
      "metadata": {
        "id": "HMVl6LUrnguh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(0,num_epochs):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1I_WqZQqEex",
        "outputId": "dd576848-fb0f-4bc8-b681-a424081dcc98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], step [100/500] Loss: 1.884543\n",
            "Epoch [1/10], step [200/500] Loss: 1.602218\n",
            "Epoch [1/10], step [300/500] Loss: 1.449387\n",
            "Epoch [1/10], step [400/500] Loss: 1.664315\n",
            "Epoch [1/10], step [500/500] Loss: 1.501775\n",
            "Accuracy of the model on the test images: 44.43%\n",
            "Epoch [2/10], step [100/500] Loss: 1.472238\n",
            "Epoch [2/10], step [200/500] Loss: 1.466878\n",
            "Epoch [2/10], step [300/500] Loss: 1.623445\n",
            "Epoch [2/10], step [400/500] Loss: 1.512827\n",
            "Epoch [2/10], step [500/500] Loss: 1.218242\n",
            "Accuracy of the model on the test images: 51.0%\n",
            "Epoch [3/10], step [100/500] Loss: 1.292556\n",
            "Epoch [3/10], step [200/500] Loss: 1.456913\n",
            "Epoch [3/10], step [300/500] Loss: 1.469619\n",
            "Epoch [3/10], step [400/500] Loss: 1.417600\n",
            "Epoch [3/10], step [500/500] Loss: 1.358003\n",
            "Accuracy of the model on the test images: 54.15%\n",
            "Epoch [4/10], step [100/500] Loss: 1.476742\n",
            "Epoch [4/10], step [200/500] Loss: 1.410805\n",
            "Epoch [4/10], step [300/500] Loss: 1.402039\n",
            "Epoch [4/10], step [400/500] Loss: 1.294550\n",
            "Epoch [4/10], step [500/500] Loss: 1.282803\n",
            "Accuracy of the model on the test images: 57.47%\n",
            "Epoch [5/10], step [100/500] Loss: 1.191651\n",
            "Epoch [5/10], step [200/500] Loss: 1.292876\n",
            "Epoch [5/10], step [300/500] Loss: 1.279927\n",
            "Epoch [5/10], step [400/500] Loss: 1.146049\n",
            "Epoch [5/10], step [500/500] Loss: 1.491230\n",
            "Accuracy of the model on the test images: 58.55%\n",
            "Epoch [6/10], step [100/500] Loss: 1.362757\n",
            "Epoch [6/10], step [200/500] Loss: 1.303931\n",
            "Epoch [6/10], step [300/500] Loss: 1.224372\n",
            "Epoch [6/10], step [400/500] Loss: 1.252586\n",
            "Epoch [6/10], step [500/500] Loss: 1.250096\n",
            "Accuracy of the model on the test images: 60.87%\n",
            "Epoch [7/10], step [100/500] Loss: 1.332240\n",
            "Epoch [7/10], step [200/500] Loss: 1.076484\n",
            "Epoch [7/10], step [300/500] Loss: 1.058080\n",
            "Epoch [7/10], step [400/500] Loss: 1.386145\n",
            "Epoch [7/10], step [500/500] Loss: 1.181221\n",
            "Accuracy of the model on the test images: 61.86%\n",
            "Epoch [8/10], step [100/500] Loss: 1.285394\n",
            "Epoch [8/10], step [200/500] Loss: 1.252764\n",
            "Epoch [8/10], step [300/500] Loss: 1.119482\n",
            "Epoch [8/10], step [400/500] Loss: 0.963272\n",
            "Epoch [8/10], step [500/500] Loss: 0.886888\n",
            "Accuracy of the model on the test images: 61.72%\n",
            "Epoch [9/10], step [100/500] Loss: 1.303944\n",
            "Epoch [9/10], step [200/500] Loss: 1.242824\n",
            "Epoch [9/10], step [300/500] Loss: 1.200895\n",
            "Epoch [9/10], step [400/500] Loss: 1.033203\n",
            "Epoch [9/10], step [500/500] Loss: 0.890589\n",
            "Accuracy of the model on the test images: 64.73%\n",
            "Epoch [10/10], step [100/500] Loss: 0.949824\n",
            "Epoch [10/10], step [200/500] Loss: 1.203695\n",
            "Epoch [10/10], step [300/500] Loss: 0.910153\n",
            "Epoch [10/10], step [400/500] Loss: 1.036501\n",
            "Epoch [10/10], step [500/500] Loss: 1.065275\n",
            "Accuracy of the model on the test images: 65.54%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNd1Lna7qFSJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxN31x4W4sqQNiWypm9SuL",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}